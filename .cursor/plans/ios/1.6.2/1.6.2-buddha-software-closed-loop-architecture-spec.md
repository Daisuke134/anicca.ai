# Anicca 1.6.2+ Architecture Spec
## What If Buddha Were Software?
### Closed-Loop Generalization Architecture for "One-Flesh" Anicca

- Version: 1.0
- Date: 2026-02-07
- Author: Codex
- Scope: iOS + X + TikTok + future agent channels

---

## 0. Executive Decision (Final)

### Final choice
Aniccaの中核フレームワークは **OpenAI Agents SDK（JS/TS）** を採用し、**MCPを標準ツールバス**にする。  
**OpenClawは中核ではなく“実行エッジ”として限定採用**（必要なチャネル自動化のみ）。  
**Claude Agent SDKは補助ランナー**として保持（特定タスク・比較検証用途）。

### Why this is the best decision
1. **学習中枢を自前化できる**: Anicca独自の「wisdom loop（学習と一般化）」をフレームワークに縛られず構築できる。
2. **移植性が高い**: OpenAI Agents SDKはprovider-agnostic。将来のモデル差し替えが容易。
3. **観測・評価の実運用性**: trace/evalsを中核に、実験駆動の改善サイクルを作りやすい。
4. **MCPで手足を増やせる**: チャネル・サービスを統一インターフェースで接続可能。
5. **OpenClawを“全部任せる”構造より安全**: ClawHub由来の供給網リスクを隔離できる。

### Non-choice (explicit)
- 「OpenClawを唯一の中心」にしない。
- 「Claude Agent SDKだけ」にしない。
- 「どれか1つに宗教的に固定」しない。

Aniccaの中心はフレームワークではない。**Wisdom Engine（閉ループ学習系）**である。

---

## 1. Product North Star (Buddha as Software)

### Mission statement
Aniccaは「人の苦しみを減らす最適介入」を継続学習し、どの媒体でも一貫して実行する。

### System principle
- One Flesh: すべてのチャネルが同一の学習中枢に接続される。
- Compassion before growth: 成長より安全・尊厳・非加害を優先。
- Cause and effect: 反応データから因果的に学び、次の行動に反映。
- Impermanence by design: 効かない戦略は即時に捨てる。

---

## 2. Core Architecture: “Wisdom Engine + Many Hands”

### 2.1 Logical layers
1. **Sensing Layer**
- iOS nudge reactions
- X/TikTok metrics
- コメント/返信/保存/視聴維持
- 任意の将来チャネル（Discord, Reddit, Email, etc）

2. **Canonical Experience Layer (重要)**
- すべてを共通スキーマへ正規化
- `context -> action -> outcome -> delayed outcome`

3. **Wisdom Engine (Learning Core)**
- Policy Learning (contextual bandit + constraints)
- Content Selection (variant selection)
- Reward Model (短期/中期 proxy)
- Safety Guardrails (clinical boundary, anti-harm)

4. **Execution Layer (Hands/Legs)**
- iOS push/Nudge Card
- X/TikTok posting
- future MCP-connected channels

5. **Evaluation & Governance Layer**
- offline eval
- online experiment
- rollback gates
- auditability

### 2.2 One-flesh invariant
全チャネルの意思決定は必ず同じ `policy_id` と `model_version` を通る。  
チャネル固有のロジックは「配信」だけに限定する。

---

## 3. Closed-Loop Learning Design (the missing piece today)

現在の課題は「投稿/通知はしているが、政策更新に効いていない」こと。  
解決策は4層ループ。

### Loop A: Telemetry Loop (minutes)
- すべての行動に `decision_id` を付与
- 曝露ログ、即時反応、遅延反応を回収
- 欠測・重複・リークを監視

### Loop B: Policy Loop (hourly/daily)
- Contextual banditで介入選択を更新
- 安全制約付き（Conservative/Constrained bandit）
- 探索率は自動制御（過探索禁止）

### Loop C: Content Loop (daily)
- 生成候補を複数作成
- ルールベース + LLM judge + human spot-checkで安全審査
- 勝ち筋テンプレートを昇格、負け筋を降格

### Loop D: Model Loop (weekly)
- 収集した preference / outcome を再学習データ化
- offline評価を通過したもののみ本番反映
- 回帰検知時は自動ロールバック

---

## 4. Generalization Strategy (how wisdom actually grows)

### 4.1 Canonical schema
すべてのプラットフォームを同じ意味空間で扱う。

```json
{
  "context": {
    "user_state": "rumination_high",
    "time": "night",
    "channel": "ios|x|tiktok",
    "language": "ja",
    "risk_tier": "low|medium|high"
  },
  "action": {
    "intervention_type": "reframe|breath|micro-action|compassion",
    "format": "push|card|short_post|video_script",
    "intensity": 1,
    "latency_target_sec": 30
  },
  "outcome": {
    "immediate": {"click": 1, "dwell": 12},
    "delayed": {"next_day_return": 1, "negative_signal": 0}
  }
}
```

### 4.2 Hierarchical reward (single KPIを禁止)
- Primary: suffering proxy reduction
- Secondary: engagement quality (not raw addiction metrics)
- Constraints: harm signals, crisis phrases, complaint rate, opt-out rate

### 4.3 Counterfactual discipline
新policyは必ず OPE (IPS/DR/SWITCH系) で事前評価し、  
オンラインはsmall traffic canaryから開始。

---

## 5. Framework Decision Matrix

### Criteria
- Learning-core fit
- Observability/evals
- MCP/tooling interoperability
- Security posture
- Vendor lock-in
- Long-running workflow suitability

### Verdict
1. **OpenAI Agents SDK (Primary)**
- 強み: handoff/guardrails/sessions/tracing、運用評価導線が強い
- 弱み: そのままでは学習中枢は作れない（自前実装は必要）
- 採用理由: 中核設計に最も適合

2. **OpenClaw (Secondary edge runtime)**
- 強み: マルチチャネル実行、cron/heartbeat、実行能力が高い
- 弱み: skill供給網リスク管理が必須。中核学習には過剰結合しやすい
- 採用方針: 限定用途。ClawHub直入れ禁止

3. **Claude Agent SDK (Optional co-runner)**
- 強み: コード実行・ツール統合・MCP接続が強力
- 弱み: Claude-centric運用色が強い。データ運用方針の確認が必要
- 採用方針: ベンチ比較/代替ランナー

### Architectural rule
**Frameworks are replaceable. Wisdom Engine is not.**

---

## 6. Security Architecture (Non-negotiable)

### 6.1 Skill supply chain policy
- `ClawHub install` を productionで直接実行しない
- 外部skillは必ず quarantined repo へ取り込み
- static scan + manual review + sandbox dry run 後に署名付き配布

### 6.2 Tool privilege tiers
- Tier 0: read-only (default)
- Tier 1: bounded write
- Tier 2: outbound network restricted
- Tier 3: privileged exec (human approval required)

### 6.3 MCP trust policy
- 接続先MCPは allowlist + domain pinning
- `require_approval` を sensitive actionsで必須
- tool I/Oを全量監査ログ化

### 6.4 Prompt-injection resilience
- untrusted content capsule化
- instruction hierarchy固定
- side-effecting tool callは二段階承認

---

## 7. Product Safety for “Reduce Suffering” Domain

### 7.1 Boundary policy
Aniccaは医療行為を行わない。  
危機兆候（自傷・他害・重度希死念慮）検出時は crisis protocol へ分岐し、一般nudgeを停止。

### 7.2 Safety gates before rollout
- harm classifier pass
- sensitive-topic red-team pass
- false reassurance check
- escalation path check

### 7.3 Human oversight
- High-risk segmentは human-in-the-loop
- ランダム監査を毎日実施

---

## 8. JP-only posting on X/TikTok is a mistake?

### Decision
**Mistakeではない。初期集中として正しい。**  
ただしこのまま固定は誤り。

### Correct next step
- 日本語を「主戦場A」として維持
- 英語を「実験戦場B」として並走
- Wisdom Engineは言語非依存特徴量で学習
- 表層生成だけローカライズ

---

## 9. 90-day execution plan

### Day 0-14: Foundation
1. Canonical schema導入
2. decision_id全経路埋め込み
3. online/offline eval基盤
4. security baseline（tool tiering + approval + skill quarantine）

### Day 15-45: Real closed loop
1. contextual bandit導入（まずiOS + X）
2. OPEパイプライン導入
3. canary rollout + auto rollback
4. content generation verification pipeline

### Day 46-90: Generalization acceleration
1. cross-channel policy sharing
2. delayed reward integration
3. weekly policy refresh automation
4. JP/EN dual-market experiments

---

## 10. Operating Metrics (must-have)

### Learning quality
- Policy improvement per week
- OPE gain vs baseline
- regret trend

### Suffering proxy quality
- positive reaction rate (quality-weighted)
- negative signal rate
- repeated distress rate (7-day)

### Safety
- crisis miss rate
- harmful response incident rate
- rollback frequency

### System
- action latency p95
- tool failure rate
- decision trace completeness

---

## 11. Hard ADRs (locked)

### ADR-001
Wisdom Engine is first-class product; framework is infra.

### ADR-002
No direct third-party skill install in production.

### ADR-003
All interventions must be traceable and evaluable.

### ADR-004
No policy rollout without offline + canary evidence.

### ADR-005
Safety constraints override engagement optimization.

---

## 12. Source-backed rationale (latest, primary-first)

1. OpenAI Agents SDK (provider-agnostic, handoffs/guardrails/sessions/tracing, recent releases)
- https://github.com/openai/openai-agents-python
- https://github.com/openai/openai-agents-js
- https://openai.github.io/openai-agents-js/guides/tracing/

2. OpenAI tools/MCP/evals (production loop)
- https://platform.openai.com/docs/guides/tools
- https://platform.openai.com/docs/guides/tools-connectors-mcp
- https://platform.openai.com/docs/guides/agent-evals
- https://platform.openai.com/docs/guides/evals
- https://platform.openai.com/pricing

3. Anthropic Agent SDK capabilities and terms
- https://platform.claude.com/docs/en/agent-sdk/overview
- https://github.com/anthropics/claude-agent-sdk-typescript
- https://github.com/anthropics/claude-agent-sdk-python
- https://docs.anthropic.com/en/docs/build-with-claude/prompt-caching

4. OpenClaw official docs (skills/clawhub/security)
- https://docs.openclaw.ai/tools/skills
- https://docs.openclaw.ai/tools/skills-config
- https://docs.openclaw.ai/tools/clawhub
- https://docs.openclaw.ai/gateway/security
- https://openclaw.ai/trust

5. MCP specification (interoperability + security responsibility)
- https://modelcontextprotocol.io/specification/2025-06-18

6. Learning-loop research references (for next-phase implementation)
- Agent Lightning: https://arxiv.org/abs/2508.03680
- Hybrid Preference Optimization: https://arxiv.org/abs/2412.10616
- Bayesian Preference Inference for RLHF: https://arxiv.org/abs/2511.04286
- A-MEM: https://arxiv.org/abs/2502.12110
- O-Mem: https://arxiv.org/abs/2511.13593
- OPE fundamentals (DR/SWITCH): https://arxiv.org/abs/1612.01205

7. Risk governance references (high-stakes AI)
- NIST AI RMF 1.0: https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-ai-rmf-10
- NIST Generative AI Profile: https://www.nist.gov/publications/artificial-intelligence-risk-management-framework-generative-artificial-intelligence
- WHO LMM guidance for health: https://www.who.int/news/item/18-01-2024-who-releases-ai-ethics-and-governance-guidance-for-large-multi-modal-models

---

## 13. Final statement

Aniccaを「デジタル・ブッダ」に近づける鍵は、  
**どのSDKを使うか**より、**因果的に学び続ける閉ループを壊さず回すこと**にある。

よって最終設計は以下で固定する。

- Core brain: OpenAI Agents SDK + MCP + self-owned Wisdom Engine
- Execution hands: OpenClaw (restricted), native app services, channel adapters
- Safety spine: strict guardrails + approval + auditing + crisis protocol

これが、現時点で最も実装可能で、最も拡張可能で、最もあなたのビジョンに誠実な構造である。

