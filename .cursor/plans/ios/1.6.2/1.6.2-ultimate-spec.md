# Anicca 1.6.2 Ultimate Implementation Specification

> **ç›®çš„**: å®Ÿè£…è€…ãŒè³ªå•ãªã—ã§å®Œå…¨å®Ÿè£…ã§ãã‚‹ãƒ¬ãƒ™ãƒ«ã®è©³ç´°ä»•æ§˜
> **RFC 2119 æº–æ‹ **: MUST, SHOULD, MAY ã‚’ä½¿ç”¨
> **æœ€çµ‚æ›´æ–°**: 2026-02-03
> **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³**: 4ã¤ã®å°‚é–€ãƒªã‚µãƒ¼ãƒï¼ˆMoltbot, memU, Anthropic, é€šçŸ¥ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ï¼‰ã‚’çµ±åˆ

---

## 0. Executive Summary

| é …ç›® | å†…å®¹ |
|------|------|
| **ã‚´ãƒ¼ãƒ«** | 24/7ãƒ—ãƒ­ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ä»æ•™ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã—ã¦ã€è‹¦ã—ã¿ã®ã‚ã‚‹å ´æ‰€ã«è‡ªã‚‰è¡Œãã€Nudgeã™ã‚‹ |
| **ã‚³ã‚¢ãƒ‘ã‚¿ãƒ¼ãƒ³** | Gatewayåˆ¶å¾¡ãƒ—ãƒ¬ãƒ¼ãƒ³ + 3å±¤ãƒ¡ãƒ¢ãƒª + Workflowå„ªå…ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ |
| **ãƒ‡ãƒ—ãƒ­ã‚¤** | Hetzner VPS (Tier A: Docker + Tailscale) |
| **ã‚³ã‚¹ãƒˆç›®æ¨™** | LLMãƒˆãƒ¼ã‚¯ãƒ³90%å‰Šæ¸›ï¼ˆmemUãƒ‘ã‚¿ãƒ¼ãƒ³é©ç”¨ï¼‰ |
| **å“è³ªç›®æ¨™** | æŠ•ç¨¿ã‚¹ã‚³ã‚¢ >= 7/10 ã®ã¿å…¬é–‹ |

---

## 1. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ±ºå®šè¨˜éŒ² (ADR)

### ADR-001: Workflows vs Agents

**æ±ºå®š**: Workflowå„ªå…ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æ¡ç”¨

| åŸºæº– | Workflow | Agent | Aniccaé¸æŠ |
|------|----------|-------|------------|
| **äºˆæ¸¬å¯èƒ½æ€§** | é«˜ï¼ˆäº‹å‰å®šç¾©ãƒ‘ã‚¹ï¼‰ | ä½ï¼ˆå‹•çš„åˆ¤æ–­ï¼‰ | âœ… Workflow |
| **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·** | ä½ | é«˜ | âœ… Workflow |
| **ã‚³ã‚¹ãƒˆ** | ä½ | é«˜ | âœ… Workflow |
| **ãƒ‡ãƒãƒƒã‚°å®¹æ˜“æ€§** | é«˜ | ä½ | âœ… Workflow |
| **æŸ”è»Ÿæ€§** | ä½ | é«˜ | AgentãŒæœ‰åˆ©ã ãŒä¸è¦ |

**æ ¹æ‹ **: Anthropic "Building Effective Agents" ã‚ˆã‚Šã€Œå¯èƒ½ãªé™ã‚Šã‚·ãƒ³ãƒ—ãƒ«ãªè§£æ±ºç­–ã‹ã‚‰å§‹ã‚ã‚‹ã€

**ä¾‹å¤–**: ä»¥ä¸‹ã®å ´åˆã®ã¿Agentä½¿ç”¨
- è‹¦ã—ã¿æŠ•ç¨¿ã¸ã®è¿”ä¿¡ç”Ÿæˆï¼ˆæ–‡è„ˆä¾å­˜æ€§ãŒé«˜ã„ï¼‰
- ãƒ¬ãƒ“ãƒ¥ãƒ¼è¿”ä¿¡ç”Ÿæˆï¼ˆé¡§å®¢å¯¾å¿œã®ç¹Šç´°ã•ï¼‰

### ADR-002: Cron vs Heartbeat

**æ±ºå®š**: ã‚¿ã‚¹ã‚¯ç¨®åˆ¥ã«å¿œã˜ã¦ä½¿ã„åˆ†ã‘

| ã‚¿ã‚¹ã‚¯ç¨®åˆ¥ | ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ | ç†ç”± |
|-----------|-------------|------|
| **x-poster** | Cron (isolated) | æ­£ç¢ºãªã‚¿ã‚¤ãƒŸãƒ³ã‚°å¿…é ˆã€æ–‡è„ˆä¸è¦ |
| **tiktok-poster** | Cron (isolated) | åŒä¸Š |
| **trend-hunter** | Cron (interval) | 4æ™‚é–“é–“éš”ã€ç‹¬ç«‹å®Ÿè¡Œ |
| **feedback-fetch** | Cron (interval) | 4æ™‚é–“é–“éš”ã€ç‹¬ç«‹å®Ÿè¡Œ |
| **suffering-detector** | Heartbeat | æœ€æ–°ã®ä¼šè©±æ–‡è„ˆãŒå¿…è¦ |
| **moltbook-responder** | Heartbeat | ä¼šè©±ç¶™ç¶šæ€§ãŒå¿…è¦ |

**Moltbotç ”ç©¶ã‹ã‚‰ã®åˆ¤æ–­åŸºæº–**:
- æ­£ç¢ºãªã‚¿ã‚¤ãƒŸãƒ³ã‚°ãŒå¿…è¦ â†’ Cron (isolated)
- ä¼šè©±æ–‡è„ˆãŒå¿…è¦ â†’ Heartbeat (main session)
- ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«/è¨­å®šãŒå¿…è¦ â†’ Cron (isolated)
- ãƒãƒ£ãƒ³ãƒãƒ«é…ä¿¡ãŒå¿…è¦ â†’ Cron with delivery

### ADR-003: ãƒ¡ãƒ¢ãƒªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

**æ±ºå®š**: memU 3å±¤éšå±¤ã‚’æ¡ç”¨

```
memory/
â”œâ”€â”€ categories/              â† Category Layerï¼ˆè¦ç´„ãƒ»çµ±åˆï¼‰
â”‚   â”œâ”€â”€ preferences/
â”‚   â”‚   â”œâ”€â”€ morning_nudges.md
â”‚   â”‚   â””â”€â”€ tone_preferences.md
â”‚   â””â”€â”€ behaviors/
â”‚       â”œâ”€â”€ engagement_patterns.md
â”‚       â””â”€â”€ timing_responses.md
â”œâ”€â”€ items/                   â† Item Layerï¼ˆç´°ç²’åº¦ãƒ¡ãƒ¢ãƒªï¼‰
â”‚   â”œâ”€â”€ item_001.json       # "strict tone at 6am gets thumbs_up"
â”‚   â””â”€â”€ item_002.json       # "gentle tone works for anxiety"
â””â”€â”€ resources/              â† Resource Layerï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
    â”œâ”€â”€ nudge_feedback_123.json
    â””â”€â”€ behavior_event_456.json
```

**ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœ**:
- ç¾åœ¨: æ¯å›å…¨å±¥æ­´ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹ â†’ 100%ã‚³ã‚¹ãƒˆ
- memUå¾Œ: Category â†’ Item â†’ Resource ã®éšå±¤çš„æ¤œç´¢ â†’ 10-20%ã‚³ã‚¹ãƒˆ

---

## 2. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè©³ç´°è¨­è¨ˆ

### 2.1 Gatewayåˆ¶å¾¡ãƒ—ãƒ¬ãƒ¼ãƒ³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ANICCA GATEWAY (VPS)                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                      OpenClaw Gateway                                 â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ WebSocket Server (ws://127.0.0.1:18789)                         â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Typed protocol (TypeBox schemas)                              â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Session management                                             â”‚ â”‚   â”‚
â”‚  â”‚  â”‚ â€¢ Tool orchestration                                             â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â”‚                                  â”‚                                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                       SESSION MANAGER                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Sessions:                                                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ main           â†’ DMå¯¾è©±ï¼ˆHeartbeatã‚¿ã‚¹ã‚¯ï¼‰                  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ cron:x-poster  â†’ æŠ•ç¨¿ã‚¸ãƒ§ãƒ–ï¼ˆisolatedï¼‰                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ cron:trend     â†’ ãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–ï¼ˆisolatedï¼‰                   â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ hook:uuid      â†’ Webhookå‡¦ç†ï¼ˆä¸€æ™‚çš„ï¼‰                      â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Session Isolation Matrix:                                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ Session         â”‚ Tool Accessâ”‚ Memory      â”‚ Delivery   â”‚  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ main            â”‚ Full       â”‚ Shared      â”‚ WhatsApp   â”‚  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ cron:*          â”‚ Scoped     â”‚ Isolated    â”‚ Optional   â”‚  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚ hook:*          â”‚ Minimal    â”‚ None        â”‚ Callback   â”‚  â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                  â”‚                                    â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                       CRON SCHEDULER                           â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Storage: ~/.openclaw/cron/jobs.json                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  History: ~/.openclaw/cron/runs/<jobId>.jsonl                 â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Job Types:                                                    â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ at: ä¸€å›é™ã‚Š (ISO 8601 timestamp)                          â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ every: å›ºå®šé–“éš” (ms)                                        â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ cron: 5ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å¼ + ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚                                                                â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  Execution Modes:                                              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ systemEvent: main session ã«ã‚¨ãƒ³ã‚­ãƒ¥ãƒ¼                     â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ agentTurn: å°‚ç”¨ cron:<jobId> session ã§å®Ÿè¡Œ               â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                      â”‚                                       â”‚
â”‚                                      â†“ ANICCA_AGENT_TOKEN                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Skillsè©³ç´°è¨­è¨ˆ

#### 2.2.1 x-poster Skill (å®Œå…¨ç‰ˆ)

**ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ**:
```
/home/anicca/openclaw/skills/x-poster/
â”œâ”€â”€ skill.yaml           # Skillå®šç¾©ï¼ˆä¸‹è¨˜å‚ç…§ï¼‰
â”œâ”€â”€ main.py              # ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
â”œâ”€â”€ verifier.py          # ãƒ†ã‚­ã‚¹ãƒˆ/ç”»åƒæ¤œè¨¼
â”œâ”€â”€ hook_selector.py     # Thompson Samplingãƒ™ãƒ¼ã‚¹ãƒ•ãƒƒã‚¯é¸å®š
â”œâ”€â”€ error_handler.py     # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
â”œâ”€â”€ metrics.py           # ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†
â””â”€â”€ tests/
    â”œâ”€â”€ test_main.py
    â”œâ”€â”€ test_verifier.py
    â””â”€â”€ fixtures/
```

**skill.yaml (å®Œå…¨ç‰ˆ)**:
```yaml
name: x-poster
description: |
  Post wisdom content to X/Twitter with quality verification.
  Uses Thompson Sampling for hook selection and LLM for content verification.
version: 1.0.0
author: anicca

triggers:
  schedule:
    cron:
      - "0 0 * * *"   # 09:00 JST (UTC+9)
      - "0 12 * * *"  # 21:00 JST
    timezone: "Asia/Tokyo"
    
  # Manual trigger support
  manual: true

session:
  target: "isolated"          # Don't pollute main session
  wakeMode: "now"            # Execute immediately when triggered
  isolation:
    postToMainPrefix: "[XæŠ•ç¨¿]"
    postToMainMode: "summary"  # Only post summary to main

env:
  required:
    - ANICCA_AGENT_TOKEN
    - ANICCA_PROXY_BASE_URL
    - BLOTATO_API_KEY
    - X_ACCOUNT_ID
    - OPENAI_API_KEY
  optional:
    - FAL_API_KEY
    - SLACK_WEBHOOK_AGENTS

tools:
  allow:
    - bash           # For simple file operations
    - read           # Read configuration
    - write          # Write logs
  deny:
    - browser        # Not needed, API-based
    - nodes          # Not needed

retry:
  max_attempts: 3
  backoff: "exponential"
  initial_delay_ms: 1000
  max_delay_ms: 30000
  jitter: true

error_handling:
  on_error: "notify_and_abort"
  fallback_content: null       # No fallback, abort if verification fails
  
  # Error classification (from Anthropic research)
  retry_on:
    - 429  # Rate limit
    - 500  # Server error
    - 502  # Bad gateway
    - 503  # Service unavailable
    - 529  # Overloaded
  abort_on:
    - 400  # Bad request (client error)
    - 401  # Unauthorized
    - 403  # Forbidden
    - 404  # Not found

outputs:
  - agent_post_id
  - blotato_post_id
  - text_score
  - image_score
  - hook_used
  - verification_attempts
```

**main.py (å®Œå…¨ç‰ˆ)**:
```python
#!/usr/bin/env python3
"""
x-poster Skill â€” Post to X with quality verification

Architecture: Workflow (not Agent)
- Predictable execution path
- Low latency, low cost
- Easy debugging

Flow:
1. Select best hook using Thompson Sampling
2. Generate text content via /api/agent/content
3. Verify text quality (score >= 7, max 3 attempts)
4. Generate image via fal (optional)
5. Verify image quality (score >= 7, max 3 attempts)
6. Post via Blotato API
7. Save to agent_posts
8. Update hook statistics (for future selection)
9. Notify Slack

Error Handling (from Anthropic research):
- 4xx (except 429): Don't retry
- 429: Exponential backoff with jitter
- 5xx: Exponential backoff, max 3 attempts
- Fallback: Abort and notify
"""
import os
import sys
import json
import time
import random
import logging
from datetime import datetime, timezone, timedelta
from typing import Optional, Dict, Any, Tuple
from dataclasses import dataclass, asdict

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Local imports
from verifier import verify_text, verify_image
from hook_selector import select_hook_thompson
from error_handler import (
    handle_api_error,
    notify_slack,
    ExponentialBackoff,
    DeadLetterQueue
)
from metrics import record_execution_metrics

# ============================================================================
# CONFIGURATION
# ============================================================================

@dataclass
class Config:
    """Configuration with validation."""
    api_base_url: str
    agent_token: str
    blotato_api_key: str
    blotato_base_url: str = "https://api.blotato.com/v2"
    x_account_id: str = ""
    fal_api_key: str = ""
    slack_webhook: str = ""
    
    # Verification settings
    max_verification_attempts: int = 3
    min_text_score: int = 7
    min_image_score: int = 7
    
    # Retry settings
    max_retries: int = 3
    retry_backoff_factor: float = 1.0
    retry_status_forcelist: tuple = (429, 500, 502, 503, 529)
    
    # Timezone
    jst: timezone = timezone(timedelta(hours=9))
    
    @classmethod
    def from_env(cls) -> "Config":
        """Create config from environment variables."""
        required = ["ANICCA_PROXY_BASE_URL", "ANICCA_AGENT_TOKEN", "BLOTATO_API_KEY"]
        missing = [k for k in required if not os.environ.get(k)]
        if missing:
            raise ValueError(f"Missing required env vars: {missing}")
        
        return cls(
            api_base_url=os.environ["ANICCA_PROXY_BASE_URL"],
            agent_token=os.environ["ANICCA_AGENT_TOKEN"],
            blotato_api_key=os.environ["BLOTATO_API_KEY"],
            x_account_id=os.environ.get("X_ACCOUNT_ID", ""),
            fal_api_key=os.environ.get("FAL_API_KEY", ""),
            slack_webhook=os.environ.get("SLACK_WEBHOOK_AGENTS", ""),
        )


# ============================================================================
# HTTP CLIENT (with retry)
# ============================================================================

def create_http_session(config: Config) -> requests.Session:
    """Create HTTP session with retry strategy."""
    session = requests.Session()
    
    retry_strategy = Retry(
        total=config.max_retries,
        backoff_factor=config.retry_backoff_factor,
        status_forcelist=config.retry_status_forcelist,
        allowed_methods=["GET", "POST"],
        raise_on_status=False,
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    
    return session


# ============================================================================
# API FUNCTIONS
# ============================================================================

def api_get(
    session: requests.Session,
    config: Config,
    path: str,
    params: Optional[Dict] = None
) -> Dict:
    """GET request to Railway API with error handling."""
    url = f"{config.api_base_url}{path}"
    headers = {"Authorization": f"Bearer {config.agent_token}"}
    
    try:
        resp = session.get(url, headers=headers, params=params, timeout=30)
        handle_api_error(resp, "Railway API GET")
        return resp.json()
    except requests.RequestException as e:
        logging.error(f"API GET failed: {e}")
        raise


def api_post(
    session: requests.Session,
    config: Config,
    path: str,
    data: Dict
) -> Dict:
    """POST request to Railway API with error handling."""
    url = f"{config.api_base_url}{path}"
    headers = {
        "Authorization": f"Bearer {config.agent_token}",
        "Content-Type": "application/json"
    }
    
    try:
        resp = session.post(url, headers=headers, json=data, timeout=60)
        handle_api_error(resp, "Railway API POST")
        return resp.json()
    except requests.RequestException as e:
        logging.error(f"API POST failed: {e}")
        raise


# ============================================================================
# CONTENT GENERATION
# ============================================================================

def generate_content(
    session: requests.Session,
    config: Config,
    hook: Dict,
    feedback: Optional[str] = None
) -> Dict:
    """Generate content via /api/agent/content with optional feedback."""
    data = {
        "topic": hook["content"],
        "problemType": hook.get("problemType", "procrastination"),
        "tone": "gentle",
        "language": "ja",
    }
    
    if feedback:
        data["feedback"] = feedback
    
    result = api_post(session, config, "/api/agent/content", data)
    return result


def generate_image(config: Config, text: str) -> Optional[str]:
    """Generate image via fal API."""
    if not config.fal_api_key:
        return None
    
    prompt = f"""
Create a warm, minimalist illustration for this message:
"{text[:200]}"

Style: Soft colors, simple shapes, calming, no text in image.
Mood: Supportive, gentle, Buddhist-inspired.
"""
    
    try:
        resp = requests.post(
            "https://fal.run/fal-ai/flux/dev",
            headers={"Authorization": f"Key {config.fal_api_key}"},
            json={"prompt": prompt, "image_size": "square_hd"},
            timeout=120,
        )
        resp.raise_for_status()
        return resp.json().get("images", [{}])[0].get("url")
    except Exception as e:
        logging.warning(f"Image generation failed: {e}")
        return None


# ============================================================================
# VERIFICATION LOOP
# ============================================================================

def verify_and_regenerate_text(
    session: requests.Session,
    config: Config,
    hook: Dict,
) -> Tuple[str, int, int]:
    """
    Verify text quality and regenerate if needed.
    
    Returns: (final_text, final_score, attempt_count)
    """
    attempts = 0
    best_text = ""
    best_score = 0
    feedback = None
    
    for attempt in range(config.max_verification_attempts):
        attempts += 1
        
        # Generate content (with feedback if not first attempt)
        content = generate_content(session, config, hook, feedback)
        text = content["formats"]["short"]
        
        # Verify
        result = verify_text(text)
        score = result["score"]
        
        logging.info(f"Text verification attempt {attempts}: score={score}")
        
        if score > best_score:
            best_score = score
            best_text = text
        
        if score >= config.min_text_score:
            return text, score, attempts
        
        # Prepare feedback for next attempt
        feedback = f"Score was {score}/10. Feedback: {result['feedback']}. Suggestions: {result['suggestions']}"
    
    # Return best attempt even if below threshold
    return best_text, best_score, attempts


def verify_and_regenerate_image(
    config: Config,
    text: str,
) -> Tuple[Optional[str], Optional[int], int]:
    """
    Verify image quality and regenerate if needed.
    
    Returns: (final_url, final_score, attempt_count)
    """
    if not config.fal_api_key:
        return None, None, 0
    
    attempts = 0
    best_url = None
    best_score = 0
    
    for attempt in range(config.max_verification_attempts):
        attempts += 1
        
        try:
            url = generate_image(config, text)
            if not url:
                break
            
            result = verify_image(url, text)
            score = result["score"]
            
            logging.info(f"Image verification attempt {attempts}: score={score}")
            
            if score > best_score:
                best_score = score
                best_url = url
            
            if score >= config.min_image_score:
                return url, score, attempts
                
        except Exception as e:
            logging.warning(f"Image generation/verification failed: {e}")
    
    return best_url, best_score if best_url else None, attempts


# ============================================================================
# POSTING
# ============================================================================

def post_to_blotato(
    config: Config,
    text: str,
    image_url: Optional[str] = None
) -> Dict:
    """Post to X via Blotato API."""
    payload = {
        "post": {
            "accountId": config.x_account_id,
            "content": {
                "text": text,
                "mediaUrls": [image_url] if image_url else [],
                "platform": "twitter",
            },
            "target": {"targetType": "twitter"},
        },
    }
    
    resp = requests.post(
        f"{config.blotato_base_url}/posts",
        headers={
            "blotato-api-key": config.blotato_api_key,
            "Content-Type": "application/json"
        },
        json=payload,
        timeout=30,
    )
    resp.raise_for_status()
    return resp.json()


def save_agent_post(
    session: requests.Session,
    config: Config,
    text: str,
    hook: Dict,
    blotato_id: str,
    text_score: int,
    image_score: Optional[int],
    slot: str,
    text_attempts: int,
    image_attempts: int,
) -> Dict:
    """Save post to agent_posts table."""
    data = {
        "platform": "x",
        "content": text,
        "hook": hook["content"],
        "hookId": hook.get("id"),
        "externalPostId": blotato_id,
        "reasoning": json.dumps({
            "textScore": text_score,
            "imageScore": image_score,
            "slot": slot,
            "textAttempts": text_attempts,
            "imageAttempts": image_attempts,
        }),
    }
    
    return api_post(session, config, "/api/agent/posts", data)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution flow."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
    
    start_time = time.time()
    logging.info("=== x-poster Skill START ===")
    
    # Initialize
    config = Config.from_env()
    session = create_http_session(config)
    now = datetime.now(config.jst)
    slot = "morning" if now.hour < 12 else "evening"
    
    # Execution result
    result = {
        "success": False,
        "hook_used": None,
        "text_score": 0,
        "image_score": None,
        "blotato_id": None,
        "error": None,
    }
    
    try:
        # 1. Select hook using Thompson Sampling
        logging.info("[1/7] Selecting hook...")
        hooks = api_get(session, config, "/api/agent/wisdom", {"limit": 20})
        hook = select_hook_thompson(hooks.get("hooks", []))
        result["hook_used"] = hook["content"][:50]
        logging.info(f"  Selected: {hook['content'][:50]}...")
        
        # 2. Generate and verify text
        logging.info("[2/7] Generating and verifying text...")
        text, text_score, text_attempts = verify_and_regenerate_text(
            session, config, hook
        )
        result["text_score"] = text_score
        logging.info(f"  Final text score: {text_score}/10 ({text_attempts} attempts)")
        
        # 3. Check text score threshold
        if text_score < config.min_text_score:
            raise ValueError(
                f"Text verification failed after {text_attempts} attempts. "
                f"Best score: {text_score}, required: {config.min_text_score}"
            )
        
        # 4. Generate and verify image
        logging.info("[3/7] Generating and verifying image...")
        image_url, image_score, image_attempts = verify_and_regenerate_image(
            config, text
        )
        result["image_score"] = image_score
        if image_url:
            logging.info(f"  Final image score: {image_score}/10 ({image_attempts} attempts)")
        else:
            logging.info("  Skipped (no FAL_API_KEY or generation failed)")
        
        # 5. Post via Blotato
        logging.info("[4/7] Posting via Blotato...")
        blotato_result = post_to_blotato(config, text, image_url)
        blotato_id = str(blotato_result.get("postSubmissionId", blotato_result.get("id", "")))
        result["blotato_id"] = blotato_id
        logging.info(f"  Blotato ID: {blotato_id}")
        
        # 6. Save to database
        logging.info("[5/7] Saving to agent_posts...")
        save_agent_post(
            session, config, text, hook, blotato_id,
            text_score, image_score, slot, text_attempts, image_attempts
        )
        
        # 7. Update hook statistics (for Thompson Sampling)
        logging.info("[6/7] Updating hook statistics...")
        api_post(session, config, "/api/agent/feedback", {
            "hookId": hook.get("id"),
            "outcome": "posted",  # Will be updated with engagement later
        })
        
        # 8. Notify Slack
        logging.info("[7/7] Notifying Slack...")
        notify_slack(config.slack_webhook, f"""ğŸ“¤ XæŠ•ç¨¿å®Œäº†
â€¢ Hook: {hook['content'][:50]}...
â€¢ Text Score: {text_score}/10
â€¢ Image: {'âœ… ' + str(image_score) + '/10' if image_score else 'âŒ'}
â€¢ Blotato ID: {blotato_id}
â€¢ Slot: {slot}""")
        
        result["success"] = True
        
    except Exception as e:
        result["error"] = str(e)
        logging.error(f"Execution failed: {e}")
        
        notify_slack(config.slack_webhook, f"""âš ï¸ x-poster å¤±æ•—
â€¢ Error: {str(e)[:200]}
â€¢ Slot: {slot}
â€¢ Elapsed: {time.time() - start_time:.1f}s""")
        
        # Add to Dead Letter Queue for manual review
        dlq = DeadLetterQueue("/home/anicca/openclaw/dlq/x-poster.jsonl")
        dlq.add({
            "timestamp": datetime.now(config.jst).isoformat(),
            "slot": slot,
            "error": str(e),
            "hook": result.get("hook_used"),
        })
        
        sys.exit(1)
    
    finally:
        elapsed = time.time() - start_time
        logging.info(f"=== x-poster Skill END ({elapsed:.1f}s) ===")
        
        # Record metrics
        record_execution_metrics({
            **result,
            "elapsed_seconds": elapsed,
            "slot": slot,
        })
    
    return result


if __name__ == "__main__":
    main()
```

**hook_selector.py (Thompson Sampling)**:
```python
"""
Hook selection using Thompson Sampling (Multi-Armed Bandit).

From Duolingo's notification research:
- "Recovering Difference Softmax Algorithm"
- Tests different templates, tracks which drive engagement
- Novelty management: rotates fresh templates

Implementation:
- Each hook has (success, failure) counts
- Sample from Beta(success + 1, failure + 1)
- Select hook with highest sample
"""
import random
from typing import List, Dict, Optional
from datetime import datetime, timedelta


def sample_beta(success: int, failure: int) -> float:
    """Sample from Beta distribution."""
    # Beta(alpha, beta) where alpha = success + 1, beta = failure + 1
    return random.betavariate(success + 1, failure + 1)


def select_hook_thompson(
    hooks: List[Dict],
    recency_weight: float = 0.3,
    novelty_bonus: float = 0.1,
) -> Dict:
    """
    Select hook using Thompson Sampling with recency and novelty bonuses.
    
    Args:
        hooks: List of hook candidates with statistics
        recency_weight: Weight for recency (0-1)
        novelty_bonus: Bonus for unused hooks (0-1)
    
    Returns:
        Selected hook
    """
    if not hooks:
        raise ValueError("No hooks available")
    
    if len(hooks) == 1:
        return hooks[0]
    
    now = datetime.now()
    scores = []
    
    for hook in hooks:
        # Get statistics
        success = hook.get("successCount", 0)
        failure = hook.get("failureCount", 0)
        total_uses = success + failure
        last_used = hook.get("lastUsedAt")
        
        # Thompson Sampling score
        ts_score = sample_beta(success, failure)
        
        # Recency penalty (prefer hooks not used recently)
        recency_score = 1.0
        if last_used:
            try:
                last_dt = datetime.fromisoformat(last_used.replace("Z", "+00:00"))
                days_since = (now - last_dt.replace(tzinfo=None)).days
                recency_score = min(1.0, days_since / 7)  # Max at 7 days
            except:
                pass
        
        # Novelty bonus (prefer less-used hooks)
        novelty_score = 1.0 / (total_uses + 1) if total_uses < 10 else 0
        
        # Combined score
        final_score = (
            (1 - recency_weight) * ts_score +
            recency_weight * recency_score +
            novelty_bonus * novelty_score
        )
        
        scores.append((final_score, hook))
    
    # Sort by score and return best
    scores.sort(key=lambda x: x[0], reverse=True)
    return scores[0][1]


def update_hook_statistics(
    hook_id: str,
    outcome: str,  # "success" | "failure" | "neutral"
    api_client,
) -> None:
    """Update hook statistics after use."""
    if outcome == "success":
        data = {"hookId": hook_id, "incrementSuccess": 1}
    elif outcome == "failure":
        data = {"hookId": hook_id, "incrementFailure": 1}
    else:
        data = {"hookId": hook_id, "markUsed": True}
    
    api_client.post("/api/agent/hooks/stats", data)
```

**error_handler.py**:
```python
"""
Error handling with Anthropic best practices.

Error Classification:
- 400-level (except 429): Don't retry (client error)
- 429: Exponential backoff + jitter
- 5xx: Exponential backoff, max retries
- Timeout: Retry with increased timeout

Dead Letter Queue:
- Store failed tasks for manual review
- Include full context for debugging
"""
import os
import json
import time
import random
import logging
from typing import Optional, Dict, Any
from datetime import datetime
from dataclasses import dataclass, asdict

import requests


@dataclass
class ExponentialBackoff:
    """Exponential backoff with jitter."""
    initial_delay_ms: int = 1000
    max_delay_ms: int = 30000
    multiplier: float = 2.0
    jitter: float = 0.1
    
    def get_delay(self, attempt: int) -> float:
        """Get delay in seconds for given attempt number."""
        delay_ms = min(
            self.initial_delay_ms * (self.multiplier ** attempt),
            self.max_delay_ms
        )
        # Add jitter
        jitter_range = delay_ms * self.jitter
        delay_ms += random.uniform(-jitter_range, jitter_range)
        return delay_ms / 1000


class DeadLetterQueue:
    """Dead Letter Queue for failed tasks."""
    
    def __init__(self, filepath: str):
        self.filepath = filepath
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
    
    def add(self, item: Dict) -> None:
        """Add item to DLQ."""
        with open(self.filepath, "a") as f:
            f.write(json.dumps(item) + "\n")
    
    def get_all(self) -> list:
        """Get all items from DLQ."""
        if not os.path.exists(self.filepath):
            return []
        
        with open(self.filepath, "r") as f:
            return [json.loads(line) for line in f if line.strip()]
    
    def clear(self) -> None:
        """Clear DLQ."""
        if os.path.exists(self.filepath):
            os.remove(self.filepath)


def handle_api_error(response: requests.Response, context: str) -> None:
    """
    Handle API error based on status code.
    
    Raises appropriate exception based on error classification.
    """
    if response.ok:
        return
    
    status = response.status_code
    
    # Client errors (don't retry)
    if 400 <= status < 500 and status != 429:
        logging.error(f"{context} client error: {status} - {response.text[:200]}")
        raise requests.HTTPError(
            f"{context} failed with {status}: {response.text[:200]}",
            response=response
        )
    
    # Rate limit (retry with backoff)
    if status == 429:
        retry_after = int(response.headers.get("Retry-After", 60))
        logging.warning(f"{context} rate limited, retry after {retry_after}s")
        raise requests.HTTPError(
            f"{context} rate limited, retry after {retry_after}s",
            response=response
        )
    
    # Server errors (retry with backoff)
    if status >= 500:
        logging.warning(f"{context} server error: {status}")
        raise requests.HTTPError(
            f"{context} server error: {status}",
            response=response
        )


def notify_slack(webhook_url: str, message: str) -> None:
    """Send notification to Slack."""
    if not webhook_url:
        logging.info(f"[Slack skip] {message}")
        return
    
    try:
        requests.post(
            webhook_url,
            json={"text": message},
            timeout=10
        )
    except Exception as e:
        logging.warning(f"Slack notification failed: {e}")
```

---

### 2.3 memUçµ±åˆè¨­è¨ˆ

#### 2.3.1 ãƒ¡ãƒ¢ãƒªã‚µãƒ¼ãƒ“ã‚¹API

**apps/api/src/services/memuService.js**:
```javascript
/**
 * memU Memory Service
 * 
 * Implements 3-layer hierarchical memory:
 * - Resource Layer: Raw data (JSON, feedback events)
 * - Item Layer: Fine-grained memory items (extracted facts)
 * - Category Layer: Summarized topics (preferences, patterns)
 * 
 * Cost Reduction: 90% token reduction through hierarchical retrieval
 */

const { PrismaClient } = require('@prisma/client');
const { OpenAI } = require('openai');

const prisma = new PrismaClient();
const openai = new OpenAI();

// ============================================================================
// MEMORIZE: Resource â†’ Item â†’ Category
// ============================================================================

/**
 * Memorize new data (feedback, behavior event, etc.)
 * 
 * @param {Object} resource - Raw resource data
 * @param {string} resource.type - 'nudge_feedback' | 'behavior_event' | 'user_preference'
 * @param {Object} resource.data - Raw data
 * @param {string} userId - User ID
 * @returns {Object} - Created resource, items, and updated categories
 */
async function memorize(resource, userId) {
  // 1. Store in Resource Layer
  const storedResource = await prisma.memoryResource.create({
    data: {
      userId,
      type: resource.type,
      data: JSON.stringify(resource.data),
      createdAt: new Date(),
    }
  });
  
  // 2. Extract Items (fine-grained memories)
  const items = await extractItems(resource, userId);
  
  // 3. Update Categories (aggregated summaries)
  const categories = await updateCategories(items, userId);
  
  return {
    resource: storedResource,
    items,
    categories,
  };
}

/**
 * Extract memory items from resource using LLM
 */
async function extractItems(resource, userId) {
  const prompt = `Extract key facts from this ${resource.type} data as a JSON array of items.
Each item should be a single, specific fact.

Data:
${JSON.stringify(resource.data, null, 2)}

Format:
[
  {"content": "fact 1", "category": "preferences|behaviors|timing|engagement"},
  {"content": "fact 2", "category": "..."}
]`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    max_tokens: 500,
  });
  
  const extracted = JSON.parse(response.choices[0].message.content);
  const items = extracted.items || [];
  
  // Store items
  const storedItems = await Promise.all(
    items.map(item =>
      prisma.memoryItem.create({
        data: {
          userId,
          content: item.content,
          category: item.category,
          resourceId: resource.id,
          embedding: null, // TODO: Generate embedding for RAG
          createdAt: new Date(),
        }
      })
    )
  );
  
  return storedItems;
}

/**
 * Update category summaries with new items
 */
async function updateCategories(items, userId) {
  const categoryNames = [...new Set(items.map(i => i.category))];
  const updatedCategories = [];
  
  for (const categoryName of categoryNames) {
    // Get existing category items
    const existingItems = await prisma.memoryItem.findMany({
      where: { userId, category: categoryName },
      orderBy: { createdAt: 'desc' },
      take: 20, // Last 20 items for context
    });
    
    // Generate updated summary
    const allContent = existingItems.map(i => `- ${i.content}`).join('\n');
    
    const prompt = `Summarize these ${categoryName} facts into a concise paragraph:

${allContent}

Write in natural language, focusing on patterns and key insights.`;

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 300,
    });
    
    const summary = response.choices[0].message.content;
    
    // Upsert category
    const category = await prisma.memoryCategory.upsert({
      where: { userId_name: { userId, name: categoryName } },
      create: {
        userId,
        name: categoryName,
        summary,
        itemCount: existingItems.length,
        updatedAt: new Date(),
      },
      update: {
        summary,
        itemCount: existingItems.length,
        updatedAt: new Date(),
      },
    });
    
    updatedCategories.push(category);
  }
  
  return updatedCategories;
}

// ============================================================================
// RETRIEVE: Category â†’ Item â†’ Resource (dual-mode)
// ============================================================================

/**
 * Retrieve memories using RAG (fast, low-cost)
 * 
 * @param {string} query - Search query
 * @param {string} userId - User ID
 * @param {Object} filters - Optional filters { problemType, category }
 * @param {number} limit - Max results per layer
 * @returns {Object} - { categories, items, resources }
 */
async function retrieveRAG(query, userId, filters = {}, limit = 5) {
  // TODO: Use embedding similarity search
  // For now, use keyword matching
  
  // 1. Search Categories
  const categories = await prisma.memoryCategory.findMany({
    where: {
      userId,
      ...(filters.category && { name: filters.category }),
    },
    orderBy: { updatedAt: 'desc' },
    take: limit,
  });
  
  // 2. Search Items (within relevant categories)
  const categoryNames = categories.map(c => c.name);
  const items = await prisma.memoryItem.findMany({
    where: {
      userId,
      category: { in: categoryNames },
      content: { contains: query, mode: 'insensitive' },
    },
    orderBy: { createdAt: 'desc' },
    take: limit * 2,
  });
  
  // 3. Get Resources if needed (only for detailed queries)
  let resources = [];
  if (items.length < 3) {
    const resourceIds = [...new Set(items.map(i => i.resourceId).filter(Boolean))];
    resources = await prisma.memoryResource.findMany({
      where: { id: { in: resourceIds.slice(0, limit) } },
    });
  }
  
  return { categories, items, resources };
}

/**
 * Retrieve memories using LLM (deep reasoning, higher cost)
 * 
 * @param {string} query - Search query
 * @param {string} userId - User ID
 * @returns {Object} - { categories, items, resources, reasoning }
 */
async function retrieveLLM(query, userId) {
  // 1. First do RAG search
  const ragResult = await retrieveRAG(query, userId, {}, 10);
  
  // 2. Use LLM to reason over results
  const context = `
Categories:
${ragResult.categories.map(c => `[${c.name}] ${c.summary}`).join('\n')}

Items:
${ragResult.items.map(i => `- ${i.content}`).join('\n')}
`;

  const prompt = `Based on this user's memory context, answer: "${query}"

Context:
${context}

Provide:
1. Direct answer to the query
2. Predicted next steps/needs
3. Relevant memories that support your answer

Format as JSON:
{
  "answer": "...",
  "prediction": "...",
  "relevantMemories": ["...", "..."]
}`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    max_tokens: 500,
  });
  
  const reasoning = JSON.parse(response.choices[0].message.content);
  
  return {
    ...ragResult,
    reasoning,
  };
}

// ============================================================================
// PROACTIVE CONTEXT LOADING (for nudge generation)
// ============================================================================

/**
 * Get personalized context for nudge generation
 * 
 * This is the main function called before generating nudges.
 * Uses RAG for speed, falls back to LLM if context is insufficient.
 * 
 * @param {string} userId - User ID
 * @param {string} problemType - Problem type
 * @param {number} scheduledHour - Scheduled hour (0-23)
 * @returns {Object} - Personalized context for nudge generation
 */
async function getPersonalizedNudgeContext(userId, problemType, scheduledHour) {
  // 1. Build query
  const query = `${problemType} preferences at ${scheduledHour}:00`;
  
  // 2. Fast RAG retrieval
  const ragResult = await retrieveRAG(query, userId, { problemType }, 5);
  
  // 3. Extract relevant context
  const context = {
    // Category-level preferences
    preferences: ragResult.categories
      .filter(c => c.name.includes('preference') || c.name.includes('timing'))
      .map(c => c.summary)
      .join('\n'),
    
    // Item-level specific facts
    specificFacts: ragResult.items
      .slice(0, 10)
      .map(i => i.content),
    
    // Engagement patterns (if available)
    engagementPatterns: ragResult.categories
      .filter(c => c.name.includes('engagement') || c.name.includes('behavior'))
      .map(c => c.summary)
      .join('\n'),
    
    // Timing preferences
    timingPreferences: ragResult.items
      .filter(i => i.content.includes('hour') || i.content.includes('morning') || i.content.includes('evening'))
      .map(i => i.content),
  };
  
  return context;
}

module.exports = {
  memorize,
  retrieveRAG,
  retrieveLLM,
  getPersonalizedNudgeContext,
};
```

---

### 2.4 è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

**Anthropicãƒªã‚µãƒ¼ãƒã‚ˆã‚Š: pass@k ã¨ pass^k ãƒ¡ãƒˆãƒªã‚¯ã‚¹**

#### 2.4.1 è©•ä¾¡å®šç¾©

```javascript
/**
 * Nudge Evaluation Framework
 * 
 * Metrics:
 * - pass@k: kå›è©¦è¡Œã§å°‘ãªãã¨ã‚‚1å›æˆåŠŸã™ã‚‹ç¢ºç‡
 * - pass^k: kå›ã™ã¹ã¦æˆåŠŸã™ã‚‹ç¢ºç‡
 * 
 * Graders:
 * - Code-based: ãƒ†ã‚­ã‚¹ãƒˆã‚¹ã‚³ã‚¢é–¾å€¤ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡
 * - Model-based: LLMã«ã‚ˆã‚‹å“è³ªè©•ä¾¡
 * - Human: ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚¹ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
 */

// apps/api/src/services/evaluationService.js

const EVALUATION_CONFIG = {
  // Task definitions
  tasks: {
    text_quality: {
      description: "Text content meets quality threshold",
      graders: ["code", "model"],
      thresholds: {
        code: { min_score: 7 },
        model: { min_score: 7 },
      },
    },
    engagement: {
      description: "Post achieves expected engagement",
      graders: ["code"],
      thresholds: {
        engagement_rate: 0.05, // 5%
        z_score: 1.0, // Above average
      },
    },
    behavior_change: {
      description: "Nudge leads to positive behavior",
      graders: ["code", "human"],
      thresholds: {
        thumbs_up_rate: 0.7, // 70%
        action_rate: 0.5, // 50% took action
      },
    },
  },
  
  // Evaluation schedule
  schedule: {
    text_quality: "pre_post", // Before posting
    engagement: "4h_post",    // 4 hours after posting
    behavior_change: "24h_post", // 24 hours after
  },
};

/**
 * Calculate pass@k metric
 * 
 * @param {Array} trials - Array of trial results (boolean or score)
 * @param {number} k - Number of trials to consider
 * @param {number} threshold - Score threshold for pass
 * @returns {number} - Probability of at least 1 pass in k trials
 */
function calculatePassAtK(trials, k, threshold) {
  const passes = trials.slice(0, k).filter(t => 
    typeof t === 'boolean' ? t : t >= threshold
  );
  return passes.length > 0 ? 1 : 0; // Simplified: binary
}

/**
 * Calculate pass^k metric
 * 
 * @param {Array} trials - Array of trial results
 * @param {number} k - Number of trials to consider
 * @param {number} threshold - Score threshold for pass
 * @returns {number} - Probability of all k trials passing
 */
function calculatePassPowerK(trials, k, threshold) {
  const relevant = trials.slice(0, k);
  const allPass = relevant.every(t => 
    typeof t === 'boolean' ? t : t >= threshold
  );
  return allPass ? 1 : 0;
}

/**
 * Run evaluation task
 */
async function evaluateTask(taskName, data) {
  const task = EVALUATION_CONFIG.tasks[taskName];
  if (!task) throw new Error(`Unknown task: ${taskName}`);
  
  const results = {};
  
  for (const graderType of task.graders) {
    switch (graderType) {
      case 'code':
        results.code = evaluateCode(data, task.thresholds.code || task.thresholds);
        break;
      case 'model':
        results.model = await evaluateModel(data, task.thresholds.model);
        break;
      case 'human':
        results.human = { pending: true }; // Flagged for manual review
        break;
    }
  }
  
  return {
    task: taskName,
    passed: Object.values(results).every(r => r.passed || r.pending),
    results,
  };
}

function evaluateCode(data, thresholds) {
  const checks = [];
  
  if (thresholds.min_score !== undefined) {
    checks.push({
      name: 'min_score',
      passed: data.score >= thresholds.min_score,
      actual: data.score,
      expected: thresholds.min_score,
    });
  }
  
  if (thresholds.engagement_rate !== undefined) {
    checks.push({
      name: 'engagement_rate',
      passed: data.engagementRate >= thresholds.engagement_rate,
      actual: data.engagementRate,
      expected: thresholds.engagement_rate,
    });
  }
  
  return {
    passed: checks.every(c => c.passed),
    checks,
  };
}

module.exports = {
  EVALUATION_CONFIG,
  calculatePassAtK,
  calculatePassPowerK,
  evaluateTask,
};
```

---

## 3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­è¨ˆ

### 3.1 å¤šå±¤ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ (Moltbotç ”ç©¶ã‚ˆã‚Š)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         SECURITY LAYERS                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Layer 1: Network Access                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Gateway bind: loopback only (127.0.0.1:18789)                       â”‚  â”‚
â”‚  â”‚ â€¢ Remote: Tailscale Serve (private) / Funnel (public)                â”‚  â”‚
â”‚  â”‚ â€¢ Auth: Token-based (ANICCA_AGENT_TOKEN)                             â”‚  â”‚
â”‚  â”‚ â€¢ TLS: Tailscale handles, or reverse proxy                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  Layer 2: Session Isolation                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Main session: Full access, trusted                                  â”‚  â”‚
â”‚  â”‚ â€¢ Cron sessions: Scoped tools, isolated memory                       â”‚  â”‚
â”‚  â”‚ â€¢ Hook sessions: Minimal tools, no persistent state                  â”‚  â”‚
â”‚  â”‚ â€¢ Sandboxing: Docker containers for untrusted execution              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  Layer 3: Tool Access Control                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Per-skill tool allow/deny lists                                     â”‚  â”‚
â”‚  â”‚ â€¢ Elevated mode for host execution (explicit opt-in)                 â”‚  â”‚
â”‚  â”‚ â€¢ Exec approvals for dangerous operations                            â”‚  â”‚
â”‚  â”‚ â€¢ Audit log for all tool invocations                                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  Layer 4: Prompt Injection Defense                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ â€¢ Input sanitization (URL/code removal)                               â”‚  â”‚
â”‚  â”‚ â€¢ Tag encapsulation (<user_post>...</user_post>)                      â”‚  â”‚
â”‚  â”‚ â€¢ Known pattern detection (blocklist)                                 â”‚  â”‚
â”‚  â”‚ â€¢ Output validation (LLM second pass)                                 â”‚  â”‚
â”‚  â”‚ â€¢ Rate limiting (60 req/min)                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 VPS ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š

```bash
#!/bin/bash
# /home/anicca/scripts/setup-security.sh

set -euo pipefail

echo "=== Anicca VPS Security Setup ==="

# 1. UFW Firewall
echo "[1/5] Configuring UFW..."
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow 22/tcp comment 'SSH'
# Port 18789 is NOT exposed - use Tailscale
sudo ufw --force enable

# 2. fail2ban
echo "[2/5] Installing fail2ban..."
sudo apt-get install -y fail2ban
sudo systemctl enable fail2ban
sudo systemctl start fail2ban

# 3. SSH hardening
echo "[3/5] Hardening SSH..."
sudo sed -i 's/#PasswordAuthentication yes/PasswordAuthentication no/' /etc/ssh/sshd_config
sudo sed -i 's/#PermitRootLogin prohibit-password/PermitRootLogin no/' /etc/ssh/sshd_config
sudo systemctl restart sshd

# 4. Tailscale
echo "[4/5] Installing Tailscale..."
curl -fsSL https://tailscale.com/install.sh | sh
sudo tailscale up

# 5. Auto-updates
echo "[5/5] Configuring auto-updates..."
sudo apt-get install -y unattended-upgrades
sudo dpkg-reconfigure -plow unattended-upgrades

echo "=== Security setup complete ==="
echo "Next steps:"
echo "1. Verify Tailscale: tailscale status"
echo "2. Test SSH: ssh -o PasswordAuthentication=no user@host"
echo "3. Verify UFW: sudo ufw status"
```

---

## 4. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°æˆ¦ç•¥

### 4.1 ã‚¨ãƒ©ãƒ¼åˆ†é¡ã¨å¯¾å¿œ (Anthropicç ”ç©¶ã‚ˆã‚Š)

| Status Code | åˆ†é¡ | ãƒªãƒˆãƒ©ã‚¤ | å¯¾å¿œ |
|-------------|------|---------|------|
| **400** | Bad Request | âŒ No | å³åº§ã«å¤±æ•—ã€ãƒ­ã‚°è¨˜éŒ²ã€DLQè¿½åŠ  |
| **401** | Unauthorized | âŒ No | ãƒˆãƒ¼ã‚¯ãƒ³å†å–å¾—ãŒå¿…è¦ã€ã‚¢ãƒ©ãƒ¼ãƒˆ |
| **403** | Forbidden | âŒ No | æ¨©é™å•é¡Œã€æ‰‹å‹•å¯¾å¿œå¿…è¦ |
| **404** | Not Found | âŒ No | ãƒªã‚½ãƒ¼ã‚¹ç¢ºèªã€æ‰‹å‹•å¯¾å¿œ |
| **429** | Rate Limit | âœ… Yes | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã€Retry-Afterå°Šé‡ |
| **500** | Server Error | âœ… Yes | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã€æœ€å¤§3å› |
| **502** | Bad Gateway | âœ… Yes | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã€æœ€å¤§3å› |
| **503** | Service Unavailable | âœ… Yes | é•·æœŸãƒãƒƒã‚¯ã‚ªãƒ•ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ¤œè¨ |
| **529** | Overloaded | âœ… Yes | æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã€è»½é‡ãƒ¢ãƒ‡ãƒ«ã¸åˆ‡æ›¿ |

### 4.2 Dead Letter Queue (DLQ)

```
/home/anicca/openclaw/dlq/
â”œâ”€â”€ x-poster.jsonl       # XæŠ•ç¨¿å¤±æ•—
â”œâ”€â”€ tiktok-poster.jsonl  # TikTokæŠ•ç¨¿å¤±æ•—
â”œâ”€â”€ trend-hunter.jsonl   # ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œå‡ºå¤±æ•—
â””â”€â”€ suffering-detector.jsonl  # è‹¦ã—ã¿æ¤œå‡ºå¤±æ•—

å„ã‚¨ãƒ³ãƒˆãƒª:
{
  "timestamp": "2026-02-03T09:00:00+09:00",
  "skill": "x-poster",
  "error": "Text verification failed: score=5",
  "context": {
    "hook": "ç¿’æ…£ã‚¢ãƒ—ãƒª10å€‹...",
    "attempts": 3,
    "last_score": 5
  },
  "resolution": null  # æ‰‹å‹•è§£æ±ºå¾Œã«æ›´æ–°
}
```

### 4.3 Fallbackæˆ¦ç•¥

```python
# Fallback chain for LLM calls
FALLBACK_CHAIN = [
    {"provider": "openai", "model": "gpt-4o", "max_retries": 3},
    {"provider": "openai", "model": "gpt-4o-mini", "max_retries": 2},
    {"provider": "anthropic", "model": "claude-3-haiku", "max_retries": 2},
]

async def call_with_fallback(prompt, chain=FALLBACK_CHAIN):
    for config in chain:
        try:
            return await call_llm(prompt, **config)
        except Exception as e:
            logging.warning(f"Fallback: {config['model']} failed: {e}")
            continue
    
    raise Exception("All providers failed")
```

---

## 5. é€šçŸ¥æœ€é©åŒ– (é€šçŸ¥ãƒªã‚µãƒ¼ãƒã‚ˆã‚Š)

### 5.1 MLé€ä¿¡æ™‚é–“æœ€é©åŒ– (STO)

```javascript
/**
 * Send Time Optimization
 * 
 * Based on:
 * - Last 60 days of engagement data
 * - Hourly aggregation, localized to timezone
 * - Weekly model refresh
 */

// apps/api/src/services/sendTimeOptimization.js

/**
 * Calculate optimal send time for user
 * 
 * @param {string} userId - User ID
 * @param {string} problemType - Problem type
 * @returns {number} - Optimal hour (0-23) in user's timezone
 */
async function getOptimalSendTime(userId, problemType) {
  // 1. Get user's engagement history (last 60 days)
  const history = await prisma.nudgeFeedback.findMany({
    where: {
      userId,
      problemType,
      createdAt: {
        gte: new Date(Date.now() - 60 * 24 * 60 * 60 * 1000),
      },
    },
    select: {
      scheduledHour: true,
      outcome: true, // 'tapped' | 'ignored' | 'thumbs_up' | 'thumbs_down'
      createdAt: true,
    },
  });
  
  if (history.length < 10) {
    // Insufficient data: use population average
    return getPopulationOptimalHour(problemType);
  }
  
  // 2. Aggregate by hour
  const hourlyStats = {};
  for (let h = 0; h < 24; h++) {
    hourlyStats[h] = { positive: 0, total: 0 };
  }
  
  for (const record of history) {
    const hour = record.scheduledHour;
    hourlyStats[hour].total++;
    if (['tapped', 'thumbs_up'].includes(record.outcome)) {
      hourlyStats[hour].positive++;
    }
  }
  
  // 3. Calculate engagement rate per hour
  let bestHour = 8; // Default
  let bestRate = 0;
  
  for (const [hour, stats] of Object.entries(hourlyStats)) {
    if (stats.total >= 3) { // Minimum samples
      const rate = stats.positive / stats.total;
      if (rate > bestRate) {
        bestRate = rate;
        bestHour = parseInt(hour);
      }
    }
  }
  
  // 4. Avoid inconvenient times (11pm - 6am)
  if (bestHour >= 23 || bestHour < 6) {
    // Shift to nearest acceptable time
    bestHour = bestHour >= 23 ? 22 : 7;
  }
  
  return bestHour;
}

/**
 * Get population-level optimal hour for problem type
 */
async function getPopulationOptimalHour(problemType) {
  const defaults = {
    staying_up_late: 22,    // Evening reminder
    cant_wake_up: 6,        // Morning motivation
    self_loathing: 20,      // Evening reflection
    rumination: 14,         // Afternoon break
    procrastination: 9,     // Morning kickstart
    anxiety: 7,             // Morning grounding
    loneliness: 19,         // Evening connection
    anger: 12,              // Midday pause
    // ... other types
  };
  
  return defaults[problemType] || 9; // Default to 9am
}

module.exports = { getOptimalSendTime };
```

### 5.2 ç–²åŠ´é˜²æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³

```javascript
/**
 * User Fatigue Prevention
 * 
 * Strategies:
 * 1. Frequency caps (max notifications per day/week)
 * 2. Cool-off periods after negative feedback
 * 3. Variety in content (hook rotation)
 * 4. Progressive engagement
 */

const FATIGUE_CONFIG = {
  // Daily limits per problem type
  daily_limit_per_type: 5,
  
  // Total daily limit across all types
  daily_limit_total: 10,
  
  // Cool-off after thumbs_down
  cooloff_hours_after_negative: 24,
  
  // Hook reuse prevention
  min_hours_between_same_hook: 48,
  
  // Progressive engagement (new users)
  new_user_ramp_up: {
    day_1: 3,
    day_2_7: 5,
    day_8_plus: 10,
  },
};

/**
 * Check if user should receive nudge
 */
async function shouldSendNudge(userId, problemType, hookId) {
  // 1. Check daily limit
  const today = new Date();
  today.setHours(0, 0, 0, 0);
  
  const todayCount = await prisma.nudgeSent.count({
    where: {
      userId,
      createdAt: { gte: today },
    },
  });
  
  if (todayCount >= FATIGUE_CONFIG.daily_limit_total) {
    return { allowed: false, reason: 'daily_limit_reached' };
  }
  
  // 2. Check problem type limit
  const typeCount = await prisma.nudgeSent.count({
    where: {
      userId,
      problemType,
      createdAt: { gte: today },
    },
  });
  
  if (typeCount >= FATIGUE_CONFIG.daily_limit_per_type) {
    return { allowed: false, reason: 'type_limit_reached' };
  }
  
  // 3. Check cool-off after negative feedback
  const lastNegative = await prisma.nudgeFeedback.findFirst({
    where: {
      userId,
      outcome: 'thumbs_down',
    },
    orderBy: { createdAt: 'desc' },
  });
  
  if (lastNegative) {
    const hoursSince = (Date.now() - lastNegative.createdAt.getTime()) / (1000 * 60 * 60);
    if (hoursSince < FATIGUE_CONFIG.cooloff_hours_after_negative) {
      return { allowed: false, reason: 'cooloff_active' };
    }
  }
  
  // 4. Check hook reuse
  if (hookId) {
    const lastSameHook = await prisma.nudgeSent.findFirst({
      where: {
        userId,
        hookId,
      },
      orderBy: { createdAt: 'desc' },
    });
    
    if (lastSameHook) {
      const hoursSince = (Date.now() - lastSameHook.createdAt.getTime()) / (1000 * 60 * 60);
      if (hoursSince < FATIGUE_CONFIG.min_hours_between_same_hook) {
        return { allowed: false, reason: 'hook_recently_used' };
      }
    }
  }
  
  return { allowed: true };
}

module.exports = { shouldSendNudge, FATIGUE_CONFIG };
```

---

## 6. å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### Phase 1: ã‚¤ãƒ³ãƒ•ãƒ© (Day 1)

| # | ã‚¿ã‚¹ã‚¯ | AC | çŠ¶æ…‹ |
|---|--------|-----|------|
| 1.1 | VPS ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®š | UFW + fail2ban + SSH hardening å®Œäº† | â¬œ |
| 1.2 | Tailscale è¨­å®š | `tailscale status` ã§æ¥ç¶šç¢ºèª | â¬œ |
| 1.3 | OpenClaw Gateway èµ·å‹• | `openclaw gateway --port 18789` èµ·å‹• | â¬œ |
| 1.4 | ç’°å¢ƒå¤‰æ•°è¨­å®š | `/home/anicca/.env` ã«å…¨å¤‰æ•°è¨­å®š | â¬œ |

### Phase 2: Skillså®Ÿè£… (Day 1-2)

| # | ã‚¿ã‚¹ã‚¯ | AC | çŠ¶æ…‹ |
|---|--------|-----|------|
| 2.1 | x-poster Skill ä½œæˆ | æ‰‹å‹•å®Ÿè¡Œã§æŠ•ç¨¿æˆåŠŸ | â¬œ |
| 2.2 | hook_selector.py (Thompson Sampling) | ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆé€šé | â¬œ |
| 2.3 | verifier.py | ãƒ†ã‚­ã‚¹ãƒˆ/ç”»åƒæ¤œè¨¼å‹•ä½œ | â¬œ |
| 2.4 | error_handler.py | DLQæ›¸ãè¾¼ã¿ç¢ºèª | â¬œ |
| 2.5 | tiktok-poster Skill | æ‰‹å‹•å®Ÿè¡Œã§æŠ•ç¨¿æˆåŠŸ | â¬œ |
| 2.6 | trend-hunter Skill | hook_candidatesè¿½åŠ ç¢ºèª | â¬œ |
| 2.7 | suffering-detector Skill | Moltbookè¿”ä¿¡ç¢ºèª | â¬œ |

### Phase 3: APIæ‹¡å¼µ (Day 2)

| # | ã‚¿ã‚¹ã‚¯ | AC | çŠ¶æ…‹ |
|---|--------|-----|------|
| 3.1 | POST /api/agent/hooks | ãƒ•ãƒƒã‚¯è¿½åŠ æˆåŠŸ | â¬œ |
| 3.2 | POST /api/agent/posts | æŠ•ç¨¿è¨˜éŒ²æˆåŠŸ | â¬œ |
| 3.3 | POST /api/agent/hooks/stats | çµ±è¨ˆæ›´æ–°æˆåŠŸ | â¬œ |
| 3.4 | memU Service å®Ÿè£… | memorize/retrieveå‹•ä½œ | â¬œ |

### Phase 4: ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« (Day 2)

| # | ã‚¿ã‚¹ã‚¯ | AC | çŠ¶æ…‹ |
|---|--------|-----|------|
| 4.1 | schedule.yaml ä½œæˆ | `openclaw schedule list` ã§ç¢ºèª | â¬œ |
| 4.2 | Cronå‹•ä½œç¢ºèª | 09:00 JSTã«è‡ªå‹•å®Ÿè¡Œ | â¬œ |
| 4.3 | GitHub Actions ç„¡åŠ¹åŒ– | GHAå®Ÿè¡Œã•ã‚Œãªã„ | â¬œ |

### Phase 5: Niaçµ±åˆ (Day 3)

| # | ã‚¿ã‚¹ã‚¯ | AC | çŠ¶æ…‹ |
|---|--------|-----|------|
| 5.1 | Nia Skill ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | `clawhub list` ã§è¡¨ç¤º | â¬œ |
| 5.2 | ä»æ•™æ–‡çŒ®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | `nia sources list` ã§ç¢ºèª | â¬œ |
| 5.3 | è«–æ–‡ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ | `nia sources list` ã§ç¢ºèª | â¬œ |
| 5.4 | wisdom-researcher Skill | å¼•ç”¨ä»˜ãWisdomç”Ÿæˆ | â¬œ |

### Phase 6: è©•ä¾¡ãƒ»ç›£è¦– (Day 3)

| # | ã‚¿ã‚¹ã‚¯ | AC | çŠ¶æ…‹ |
|---|--------|-----|------|
| 6.1 | è©•ä¾¡ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | evaluateTask() å‹•ä½œ | â¬œ |
| 6.2 | Slacké€šçŸ¥ç¢ºèª | æŠ•ç¨¿å®Œäº†é€šçŸ¥å±Šã | â¬œ |
| 6.3 | DLQç›£è¦–è¨­å®š | å¤±æ•—æ™‚ã«Slacké€šçŸ¥ | â¬œ |

---

## 7. æˆåŠŸãƒ¡ãƒˆãƒªã‚¯ã‚¹

| ãƒ¡ãƒˆãƒªã‚¯ã‚¹ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | ç›®æ¨™ | æ¸¬å®šæ–¹æ³• |
|-----------|-------------|------|---------|
| **æŠ•ç¨¿å“è³ªã‚¹ã‚³ã‚¢** | N/A | >= 7/10 å…¨æŠ•ç¨¿ | verifier.py |
| **X ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼** | 0 | 100 (æœˆæœ«) | X API |
| **TikTok ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼** | 0 | 100 (æœˆæœ«) | TikTok API |
| **ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡** | N/A | >= 5% | feedback-fetch |
| **LLMã‚³ã‚¹ãƒˆ** | 100% | 10-20% (memUå¾Œ) | OpenAI Usage |
| **ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç‡** | N/A | 99.5% | Health check |
| **DLQã‚¨ãƒ³ãƒˆãƒªæ•°** | N/A | < 5/é€± | DLQç›£è¦– |

---

## 8. æ›´æ–°å±¥æ­´

| æ—¥ä»˜ | å†…å®¹ |
|------|------|
| 2026-02-03 | åˆç‰ˆä½œæˆï¼ˆ4ãƒªã‚µãƒ¼ãƒçµ±åˆï¼‰ |

---

**Y** (SuperPromptã® `<answer_operator>` ã‚’ä½¿ç”¨ã—ã¾ã—ãŸ)
