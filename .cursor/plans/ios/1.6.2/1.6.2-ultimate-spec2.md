
### 2.2 SkillsË©≥Á¥∞Ë®≠Ë®à

#### 2.2.0 SkillsÊ¶ÇË¶Å

**1.6.2 Skill‰∏ÄË¶ß**:

| Skill | Á®ÆÈ°û | ‰Ωï„Çí„Åô„Çã„Åã | „Éà„É™„Ç¨„Éº |
|-------|------|-----------|---------|
| `x-poster` | „Çπ„Çø„É≥„Éâ„Ç¢„É≠„É≥ | X„Å´„Ç≥„É≥„ÉÜ„É≥„ÉÑÊäïÁ®øÔºàËøî‰ø°„Å™„ÅóÔºâ | Cron 9:00, 21:00 JST |
| `tiktok-poster` | „Çπ„Çø„É≥„Éâ„Ç¢„É≠„É≥ | TikTok„Å´ÈùôÊ≠¢ÁîªÊäïÁ®øÔºàÂãïÁîª„Å™„ÅóÔºâ | Cron 20:00 JST |
| `app-nudge-sender` | „Çπ„Çø„É≥„Éâ„Ç¢„É≠„É≥ | App PushÈÄöÁü•ÈÄÅ‰ø°ÔºàRailway Cron„Åã„ÇâÁßªË°åÔºâ | Cron + memUÊúÄÈÅ©Âåñ |
| `trend-hunter` | „Çπ„Çø„É≥„Éâ„Ç¢„É≠„É≥ | „Éà„É¨„É≥„ÉâÁõ£Ë¶ñ„ÄÅhookÂÄôË£úËøΩÂä† | Cron 4ÊôÇÈñì„Åî„Å® |
| `feedback-fetch` | „Çπ„Çø„É≥„Éâ„Ç¢„É≠„É≥ | „Ç®„É≥„Ç≤„Éº„Ç∏„É°„É≥„ÉàÂèñÂæó | Cron 4ÊôÇÈñì„Åî„Å® |
| `suffering-detector` | „Çπ„Çø„É≥„Éâ„Ç¢„É≠„É≥ | Ëã¶„Åó„ÅøÊ§úÂá∫‚ÜíMoltbookËøî‰ø°/App Nudge | Heartbeat |
| `hook-selector` | „Éò„É´„Éë„Éº | Thompson Sampling„ÅßhookÈÅ∏Êäû | ‰ªñSkill„Åã„ÇâÂëº„Å∞„Çå„Çã |
| `content-verifier` | „Éò„É´„Éë„Éº | ÂìÅË≥™„Çπ„Ç≥„Ç¢Âà§ÂÆöÔºà0-5„ÄÅÈñæÂÄ§3Ôºâ | ‰ªñSkill„Åã„ÇâÂëº„Å∞„Çå„Çã |
| `wisdom-researcher` | „Éò„É´„Éë„Éº | NiaÁµåÁî±„Åß‰ªèÊïô/ÂøÉÁêÜÂ≠¶„Åã„ÇâÂºïÁî® | ‰ªñSkill„Åã„ÇâÂëº„Å∞„Çå„Çã |
| `memu-manager` | „Éò„É´„Éë„Éº | 3Â±§„É°„É¢„É™‰øùÂ≠ò/Ê§úÁ¥¢ | ‰ªñSkill„Åã„ÇâÂëº„Å∞„Çå„Çã |
| `steipete/slack` | „Éò„É´„Éë„Éº(clawhub) | SlackÈÄöÁü• | ‰ªñSkill„Åã„ÇâÂëº„Å∞„Çå„Çã |

**suffering-detector ÂÆüË£ÖÈ†ÜÂ∫è**:

| Phase | „Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É† | Ê§úÂá∫ | Ëøî‰ø°/Nudge | Ë™¨Êòé |
|-------|-----------------|------|-----------|------|
| 1 | Moltbook | ‚úÖ | ‚úÖ Ëøî‰ø° | ÂÆâÂÖ®„Å™Áí∞Â¢É„Åß„Éï„É´ÂÆüË£Ö„Éª„ÉÜ„Çπ„Éà |
| 2 | X | ‚úÖ | ‚ùå ‚Üí App Nudge | Ê§úÂá∫„ÅÆ„Åø„ÄÅXËøî‰ø°„ÅØ„Åó„Å™„ÅÑ |

**clawhub Skill„Ç§„É≥„Çπ„Éà„Éº„É´**:

```bash
# steipete/slack „Çí„Ç§„É≥„Çπ„Éà„Éº„É´
clawhub install steipete-slack

# openclaw.json „Å´Ë®≠ÂÆöËøΩÂä†
{
  "skills": {
    "entries": {
      "steipete-slack": {
        "enabled": true,
        "env": {
          "SLACK_WEBHOOK_URL": "${SLACK_WEBHOOK_AGENTS}"
        }
      }
    }
  }
}
```

**Before/AfterÔºà„Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÁßªË°åÔºâ**:

| Ê©üËÉΩ | Before | After |
|------|--------|-------|
| App Nudge | Railway Cron ‚Üí API | OpenClaw `app-nudge-sender` Skill |
| XÊäïÁ®ø | GitHub ActionsÔºàÊâãÂãïÔºâ | OpenClaw `x-poster` SkillÔºàËá™ÂãïÔºâ |
| TikTok | „Å™„Åó | OpenClaw `tiktok-poster` Skill |
| SlackÈÄöÁü• | „Å™„Åó | `steipete/slack` (clawhub) |

---

#### 2.2.1 x-poster Skill (ÂÆåÂÖ®Áâà)

**„Éï„Ç°„Ç§„É´ÊßãÊàê**:
```
/home/anicca/openclaw/skills/x-poster/
‚îú‚îÄ‚îÄ skill.yaml           # SkillÂÆöÁæ©Ôºà‰∏ãË®òÂèÇÁÖßÔºâ
‚îú‚îÄ‚îÄ main.py              # „É°„Ç§„É≥„É≠„Ç∏„ÉÉ„ÇØ
‚îú‚îÄ‚îÄ verifier.py          # „ÉÜ„Ç≠„Çπ„Éà/ÁîªÂÉèÊ§úË®º
‚îú‚îÄ‚îÄ hook_selector.py     # Thompson Sampling„Éô„Éº„Çπ„Éï„ÉÉ„ÇØÈÅ∏ÂÆö
‚îú‚îÄ‚îÄ error_handler.py     # „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞
‚îú‚îÄ‚îÄ metrics.py           # „É°„Éà„É™„ÇØ„ÇπÂèéÈõÜ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ test_main.py
    ‚îú‚îÄ‚îÄ test_verifier.py
    ‚îî‚îÄ‚îÄ fixtures/
```

**skill.yaml (ÂÆåÂÖ®Áâà)**:
```yaml
name: x-poster
description: |
  Post wisdom content to X/Twitter with quality verification.
  Uses Thompson Sampling for hook selection and LLM for content verification.
version: 1.0.0
author: anicca

triggers:
  schedule:
    cron:
      - "0 0 * * *"   # 09:00 JST (UTC+9)
      - "0 12 * * *"  # 21:00 JST
    timezone: "Asia/Tokyo"
    
  # Manual trigger support
  manual: true

session:
  target: "isolated"          # Don't pollute main session
  wakeMode: "now"            # Execute immediately when triggered
  isolation:
    postToMainPrefix: "[XÊäïÁ®ø]"
    postToMainMode: "summary"  # Only post summary to main

env:
  required:
    - ANICCA_AGENT_TOKEN
    - ANICCA_PROXY_BASE_URL
    - BLOTATO_API_KEY
    - X_ACCOUNT_ID
    - OPENAI_API_KEY
  optional:
    - FAL_API_KEY
    - SLACK_WEBHOOK_AGENTS

tools:
  allow:
    - bash           # For simple file operations
    - read           # Read configuration
    - write          # Write logs
  deny:
    - browser        # Not needed, API-based
    - nodes          # Not needed

retry:
  max_attempts: 3
  backoff: "exponential"
  initial_delay_ms: 1000
  max_delay_ms: 30000
  jitter: true

error_handling:
  on_error: "notify_and_abort"
  fallback_content: null       # No fallback, abort if verification fails
  
  # Error classification (from Anthropic research)
  retry_on:
    - 429  # Rate limit
    - 500  # Server error
    - 502  # Bad gateway
    - 503  # Service unavailable
    - 529  # Overloaded
  abort_on:
    - 400  # Bad request (client error)
    - 401  # Unauthorized
    - 403  # Forbidden
    - 404  # Not found

outputs:
  - agent_post_id
  - blotato_post_id
  - text_score
  - image_score
  - hook_used
  - verification_attempts
```

**main.py (ÂÆåÂÖ®Áâà)**:
```python
#!/usr/bin/env python3
"""
x-poster Skill ‚Äî Post to X with quality verification

Architecture: Workflow (not Agent)
- Predictable execution path
- Low latency, low cost
- Easy debugging

Flow:
1. Select best hook using Thompson Sampling
2. Generate text content via /api/agent/content
3. Verify text quality (score >= 7, max 3 attempts)
4. Generate image via fal (optional)
5. Verify image quality (score >= 7, max 3 attempts)
6. Post via Blotato API
7. Save to agent_posts
8. Update hook statistics (for future selection)
9. Notify Slack

Error Handling (from Anthropic research):
- 4xx (except 429): Don't retry
- 429: Exponential backoff with jitter
- 5xx: Exponential backoff, max 3 attempts
- Fallback: Abort and notify
"""
import os
import sys
import json
import time
import random
import logging
from datetime import datetime, timezone, timedelta
from typing import Optional, Dict, Any, Tuple
from dataclasses import dataclass, asdict

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Local imports
from verifier import verify_text, verify_image
from hook_selector import select_hook_thompson
from error_handler import (
    handle_api_error,
    notify_slack,
    ExponentialBackoff,
    DeadLetterQueue
)
from metrics import record_execution_metrics

# ============================================================================
# CONFIGURATION
# ============================================================================

@dataclass
class Config:
    """Configuration with validation."""
    api_base_url: str
    agent_token: str
    blotato_api_key: str
    blotato_base_url: str = "https://api.blotato.com/v2"
    x_account_id: str = ""
    fal_api_key: str = ""
    slack_webhook: str = ""
    
    # Verification settings (0-5 scale, threshold 3)
    max_verification_attempts: int = 3
    min_text_score: int = 3   # 0-5 scale, 3+ = pass
    min_image_score: int = 3  # 0-5 scale, 3+ = pass
    
    # Retry settings
    max_retries: int = 3
    retry_backoff_factor: float = 1.0
    retry_status_forcelist: tuple = (429, 500, 502, 503, 529)
    
    # Timezone
    jst: timezone = timezone(timedelta(hours=9))
    
    @classmethod
    def from_env(cls) -> "Config":
        """Create config from environment variables."""
        required = ["ANICCA_PROXY_BASE_URL", "ANICCA_AGENT_TOKEN", "BLOTATO_API_KEY"]
        missing = [k for k in required if not os.environ.get(k)]
        if missing:
            raise ValueError(f"Missing required env vars: {missing}")
        
        return cls(
            api_base_url=os.environ["ANICCA_PROXY_BASE_URL"],
            agent_token=os.environ["ANICCA_AGENT_TOKEN"],
            blotato_api_key=os.environ["BLOTATO_API_KEY"],
            x_account_id=os.environ.get("X_ACCOUNT_ID", ""),
            fal_api_key=os.environ.get("FAL_API_KEY", ""),
            slack_webhook=os.environ.get("SLACK_WEBHOOK_AGENTS", ""),
        )


# ============================================================================
# HTTP CLIENT (with retry)
# ============================================================================

def create_http_session(config: Config) -> requests.Session:
    """Create HTTP session with retry strategy."""
    session = requests.Session()
    
    retry_strategy = Retry(
        total=config.max_retries,
        backoff_factor=config.retry_backoff_factor,
        status_forcelist=config.retry_status_forcelist,
        allowed_methods=["GET", "POST"],
        raise_on_status=False,
    )
    
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("https://", adapter)
    session.mount("http://", adapter)
    
    return session


# ============================================================================
# API FUNCTIONS
# ============================================================================

def api_get(
    session: requests.Session,
    config: Config,
    path: str,
    params: Optional[Dict] = None
) -> Dict:
    """GET request to Railway API with error handling."""
    url = f"{config.api_base_url}{path}"
    headers = {"Authorization": f"Bearer {config.agent_token}"}
    
    try:
        resp = session.get(url, headers=headers, params=params, timeout=30)
        handle_api_error(resp, "Railway API GET")
        return resp.json()
    except requests.RequestException as e:
        logging.error(f"API GET failed: {e}")
        raise


def api_post(
    session: requests.Session,
    config: Config,
    path: str,
    data: Dict
) -> Dict:
    """POST request to Railway API with error handling."""
    url = f"{config.api_base_url}{path}"
    headers = {
        "Authorization": f"Bearer {config.agent_token}",
        "Content-Type": "application/json"
    }
    
    try:
        resp = session.post(url, headers=headers, json=data, timeout=60)
        handle_api_error(resp, "Railway API POST")
        return resp.json()
    except requests.RequestException as e:
        logging.error(f"API POST failed: {e}")
        raise


# ============================================================================
# CONTENT GENERATION
# ============================================================================

def generate_content(
    session: requests.Session,
    config: Config,
    hook: Dict,
    feedback: Optional[str] = None
) -> Dict:
    """Generate content via /api/agent/content with optional feedback."""
    data = {
        "topic": hook["content"],
        "problemType": hook.get("problemType", "procrastination"),
        "tone": "gentle",
        "language": "ja",
    }
    
    if feedback:
        data["feedback"] = feedback
    
    result = api_post(session, config, "/api/agent/content", data)
    return result


def generate_image(config: Config, text: str) -> Optional[str]:
    """Generate image via fal API."""
    if not config.fal_api_key:
        return None
    
    prompt = f"""
Create a warm, minimalist illustration for this message:
"{text[:200]}"

Style: Soft colors, simple shapes, calming, no text in image.
Mood: Supportive, gentle, Buddhist-inspired.
"""
    
    try:
        resp = requests.post(
            "https://fal.run/fal-ai/flux/dev",
            headers={"Authorization": f"Key {config.fal_api_key}"},
            json={"prompt": prompt, "image_size": "square_hd"},
            timeout=120,
        )
        resp.raise_for_status()
        return resp.json().get("images", [{}])[0].get("url")
    except Exception as e:
        logging.warning(f"Image generation failed: {e}")
        return None


# ============================================================================
# VERIFICATION LOOP
# ============================================================================

def verify_and_regenerate_text(
    session: requests.Session,
    config: Config,
    hook: Dict,
) -> Tuple[str, int, int]:
    """
    Verify text quality and regenerate if needed.
    
    Returns: (final_text, final_score, attempt_count)
    """
    attempts = 0
    best_text = ""
    best_score = 0
    feedback = None
    
    for attempt in range(config.max_verification_attempts):
        attempts += 1
        
        # Generate content (with feedback if not first attempt)
        content = generate_content(session, config, hook, feedback)
        text = content["formats"]["short"]
        
        # Verify
        result = verify_text(text)
        score = result["score"]
        
        logging.info(f"Text verification attempt {attempts}: score={score}/5")

        if score > best_score:
            best_score = score
            best_text = text

        if score >= config.min_text_score:
            return text, score, attempts

        # Prepare feedback for next attempt (0-5 scale)
        feedback = f"Score was {score}/5. Feedback: {result['feedback']}. Suggestions: {result['suggestions']}"
    
    # Return best attempt even if below threshold
    return best_text, best_score, attempts


def verify_and_regenerate_image(
    config: Config,
    text: str,
) -> Tuple[Optional[str], Optional[int], int]:
    """
    Verify image quality and regenerate if needed.
    
    Returns: (final_url, final_score, attempt_count)
    """
    if not config.fal_api_key:
        return None, None, 0
    
    attempts = 0
    best_url = None
    best_score = 0
    
    for attempt in range(config.max_verification_attempts):
        attempts += 1
        
        try:
            url = generate_image(config, text)
            if not url:
                break
            
            result = verify_image(url, text)
            score = result["score"]
            
            logging.info(f"Image verification attempt {attempts}: score={score}/5")
            
            if score > best_score:
                best_score = score
                best_url = url
            
            if score >= config.min_image_score:
                return url, score, attempts
                
        except Exception as e:
            logging.warning(f"Image generation/verification failed: {e}")
    
    return best_url, best_score if best_url else None, attempts


# ============================================================================
# POSTING
# ============================================================================

def post_to_blotato(
    config: Config,
    text: str,
    image_url: Optional[str] = None
) -> Dict:
    """Post to X via Blotato API."""
    payload = {
        "post": {
            "accountId": config.x_account_id,
            "content": {
                "text": text,
                "mediaUrls": [image_url] if image_url else [],
                "platform": "twitter",
            },
            "target": {"targetType": "twitter"},
        },
    }
    
    resp = requests.post(
        f"{config.blotato_base_url}/posts",
        headers={
            "blotato-api-key": config.blotato_api_key,
            "Content-Type": "application/json"
        },
        json=payload,
        timeout=30,
    )
    resp.raise_for_status()
    return resp.json()


def save_agent_post(
    session: requests.Session,
    config: Config,
    text: str,
    hook: Dict,
    blotato_id: str,
    text_score: int,
    image_score: Optional[int],
    slot: str,
    text_attempts: int,
    image_attempts: int,
) -> Dict:
    """Save post to agent_posts table."""
    data = {
        "platform": "x",
        "content": text,
        "hook": hook["content"],
        "hookId": hook.get("id"),
        "externalPostId": blotato_id,
        "reasoning": json.dumps({
            "textScore": text_score,
            "imageScore": image_score,
            "slot": slot,
            "textAttempts": text_attempts,
            "imageAttempts": image_attempts,
        }),
    }
    
    return api_post(session, config, "/api/agent/posts", data)


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """Main execution flow."""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
    
    start_time = time.time()
    logging.info("=== x-poster Skill START ===")
    
    # Initialize
    config = Config.from_env()
    session = create_http_session(config)
    now = datetime.now(config.jst)
    slot = "morning" if now.hour < 12 else "evening"
    
    # Execution result
    result = {
        "success": False,
        "hook_used": None,
        "text_score": 0,
        "image_score": None,
        "blotato_id": None,
        "error": None,
    }
    
    try:
        # 1. Select hook using Thompson Sampling
        logging.info("[1/7] Selecting hook...")
        hooks = api_get(session, config, "/api/agent/wisdom", {"limit": 20})
        hook = select_hook_thompson(hooks.get("hooks", []))
        result["hook_used"] = hook["content"][:50]
        logging.info(f"  Selected: {hook['content'][:50]}...")
        
        # 2. Generate and verify text
        logging.info("[2/7] Generating and verifying text...")
        text, text_score, text_attempts = verify_and_regenerate_text(
            session, config, hook
        )
        result["text_score"] = text_score
        logging.info(f"  Final text score: {text_score}/5 ({text_attempts} attempts)")
        
        # 3. Check text score threshold
        if text_score < config.min_text_score:
            raise ValueError(
                f"Text verification failed after {text_attempts} attempts. "
                f"Best score: {text_score}, required: {config.min_text_score}"
            )
        
        # 4. Generate and verify image
        logging.info("[3/7] Generating and verifying image...")
        image_url, image_score, image_attempts = verify_and_regenerate_image(
            config, text
        )
        result["image_score"] = image_score
        if image_url:
            logging.info(f"  Final image score: {image_score}/5 ({image_attempts} attempts)")
        else:
            logging.info("  Skipped (no FAL_API_KEY or generation failed)")
        
        # 5. Post via Blotato
        logging.info("[4/7] Posting via Blotato...")
        blotato_result = post_to_blotato(config, text, image_url)
        blotato_id = str(blotato_result.get("postSubmissionId", blotato_result.get("id", "")))
        result["blotato_id"] = blotato_id
        logging.info(f"  Blotato ID: {blotato_id}")
        
        # 6. Save to database
        logging.info("[5/7] Saving to agent_posts...")
        save_agent_post(
            session, config, text, hook, blotato_id,
            text_score, image_score, slot, text_attempts, image_attempts
        )
        
        # 7. Update hook statistics (for Thompson Sampling)
        logging.info("[6/7] Updating hook statistics...")
        api_post(session, config, "/api/agent/feedback", {
            "hookId": hook.get("id"),
            "outcome": "posted",  # Will be updated with engagement later
        })
        
        # 8. Notify Slack
        logging.info("[7/7] Notifying Slack...")
        notify_slack(config.slack_webhook, f"""üì§ XÊäïÁ®øÂÆå‰∫Ü
‚Ä¢ Hook: {hook['content'][:50]}...
‚Ä¢ Text Score: {text_score}/5
‚Ä¢ Image: {'‚úÖ ' + str(image_score) + '/5' if image_score else '‚ùå'}
‚Ä¢ Blotato ID: {blotato_id}
‚Ä¢ Slot: {slot}""")
        
        result["success"] = True
        
    except Exception as e:
        result["error"] = str(e)
        logging.error(f"Execution failed: {e}")
        
        notify_slack(config.slack_webhook, f"""‚ö†Ô∏è x-poster Â§±Êïó
‚Ä¢ Error: {str(e)[:200]}
‚Ä¢ Slot: {slot}
‚Ä¢ Elapsed: {time.time() - start_time:.1f}s""")
        
        # Add to Dead Letter Queue for manual review
        dlq = DeadLetterQueue("/home/anicca/openclaw/dlq/x-poster.jsonl")
        dlq.add({
            "timestamp": datetime.now(config.jst).isoformat(),
            "slot": slot,
            "error": str(e),
            "hook": result.get("hook_used"),
        })
        
        sys.exit(1)
    
    finally:
        elapsed = time.time() - start_time
        logging.info(f"=== x-poster Skill END ({elapsed:.1f}s) ===")
        
        # Record metrics
        record_execution_metrics({
            **result,
            "elapsed_seconds": elapsed,
            "slot": slot,
        })
    
    return result


if __name__ == "__main__":
    main()
```

**hook_selector.py (Thompson Sampling with Best Practices)**:
```python
"""
Hook selection using Thompson Sampling (Multi-Armed Bandit).

Best Practices Applied (from research):
1. Weak Initialization + Dynamic Prior - È°û‰ººhook„ÅÆÂÆüÁ∏æ„ÇíÂàùÊúüÊé®ÂÆö„Å´‰ΩøÁî®
2. Discounted Thompson Sampling - Âè§„ÅÑ„Éá„Éº„Çø„ÇíÊåáÊï∞Ê∏õË°∞ÔºàŒ≥=0.95/ÈÄ±Ôºâ
3. Novelty Bonus - Êñ∞Ë¶èhook„Å´0.1„Éú„Éº„Éä„Çπ„ÄÅ10Âõû‰ΩøÁî®ÂæåÂâäÈô§
4. Recency Bonus - 7Êó•‰ª•‰∏äÊú™‰ΩøÁî®hook„Å´ÈÅ∏ÊäûÁ¢∫Áéá‰∏äÊòá

References:
- Chapelle & Li (2011) "Empirical Evaluation of Thompson Sampling"
- Raj & Kalyani (2017) "Discounted Thompson Sampling"
- DuolingoÁ†îÁ©∂ "Recovering Difference Softmax Algorithm"
"""
import random
import math
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass


@dataclass
class TSConfig:
    """Thompson Sampling configuration."""
    discount_factor: float = 0.95       # Œ≥: Weekly discount (0.95^week)
    novelty_bonus: float = 0.1          # Bonus for hooks with <10 uses
    novelty_threshold: int = 10         # Uses before novelty bonus removed
    recency_weight: float = 0.3         # Weight for recency in final score
    recency_max_days: int = 7           # Days for max recency bonus
    lookback_days: int = 90             # Only consider last 90 days of data
    min_prior_samples: int = 3          # Min samples for dynamic prior


def sample_beta(alpha: float, beta: float) -> float:
    """Sample from Beta distribution with safety bounds."""
    # Ensure valid parameters (>0)
    alpha = max(0.001, alpha)
    beta = max(0.001, beta)
    return random.betavariate(alpha, beta)


def calculate_discounted_counts(
    history: List[Dict],
    discount_factor: float,
    lookback_days: int,
) -> Tuple[float, float]:
    """
    Calculate discounted success/failure counts.

    Discounted TS formula:
    Œ± = 1 + Œ£(Œ≥^t * success_t)
    Œ≤ = 1 + Œ£(Œ≥^t * failure_t)

    Where t = weeks since event, Œ≥ = discount_factor
    """
    now = datetime.now()
    cutoff = now - timedelta(days=lookback_days)

    alpha = 1.0  # Prior
    beta = 1.0   # Prior

    for event in history:
        event_date = event.get("date")
        if not event_date:
            continue

        try:
            if isinstance(event_date, str):
                event_dt = datetime.fromisoformat(event_date.replace("Z", "+00:00"))
            else:
                event_dt = event_date

            # Skip events older than lookback period
            if event_dt.replace(tzinfo=None) < cutoff:
                continue

            # Calculate weeks since event
            weeks_since = (now - event_dt.replace(tzinfo=None)).days / 7
            discount = discount_factor ** weeks_since

            if event.get("outcome") == "success":
                alpha += discount
            elif event.get("outcome") == "failure":
                beta += discount
        except:
            continue

    return alpha, beta


def get_dynamic_prior(
    hook: Dict,
    all_hooks: List[Dict],
    config: TSConfig,
) -> Tuple[float, float]:
    """
    Calculate dynamic prior based on similar hooks' performance.

    For new hooks, use weighted average of similar hooks' statistics
    instead of uniform prior (1, 1).
    """
    problem_type = hook.get("problemType")

    # Find similar hooks (same problemType)
    similar_hooks = [
        h for h in all_hooks
        if h.get("problemType") == problem_type
        and h.get("id") != hook.get("id")
        and (h.get("successCount", 0) + h.get("failureCount", 0)) >= config.min_prior_samples
    ]

    if not similar_hooks:
        return 1.0, 1.0  # Default uniform prior

    # Calculate weighted average success rate
    total_success = sum(h.get("successCount", 0) for h in similar_hooks)
    total_failure = sum(h.get("failureCount", 0) for h in similar_hooks)
    total = total_success + total_failure

    if total == 0:
        return 1.0, 1.0

    # Use success rate to set weak prior (scale of 2)
    success_rate = total_success / total
    alpha = 1 + success_rate * 2
    beta = 1 + (1 - success_rate) * 2

    return alpha, beta


def select_hook_thompson(
    hooks: List[Dict],
    config: Optional[TSConfig] = None,
) -> Dict:
    """
    Select hook using Discounted Thompson Sampling.

    Algorithm:
    1. For each hook, calculate discounted Œ±, Œ≤ from history
    2. Apply dynamic prior for new hooks
    3. Sample from Beta(Œ±, Œ≤)
    4. Add novelty bonus for <10 uses
    5. Add recency bonus for >7 days unused
    6. Select hook with highest combined score

    Args:
        hooks: List of hook candidates with statistics and history
        config: TSConfig for tuning (defaults provided)

    Returns:
        Selected hook
    """
    if not hooks:
        raise ValueError("No hooks available")

    if len(hooks) == 1:
        return hooks[0]

    config = config or TSConfig()
    now = datetime.now()
    scores = []

    for hook in hooks:
        # Get statistics
        success = hook.get("successCount", 0)
        failure = hook.get("failureCount", 0)
        total_uses = success + failure
        last_used = hook.get("lastUsedAt")
        history = hook.get("history", [])

        # 1. Calculate discounted counts (if history available)
        if history:
            alpha, beta = calculate_discounted_counts(
                history,
                config.discount_factor,
                config.lookback_days
            )
        else:
            # 2. Use dynamic prior for new/low-data hooks
            if total_uses < config.min_prior_samples:
                base_alpha, base_beta = get_dynamic_prior(hook, hooks, config)
            else:
                base_alpha, base_beta = 1.0, 1.0

            alpha = base_alpha + success
            beta = base_beta + failure

        # 3. Thompson Sampling score
        ts_score = sample_beta(alpha, beta)

        # 4. Novelty bonus (prefer less-used hooks, removed after threshold)
        novelty_score = 0.0
        if total_uses < config.novelty_threshold:
            novelty_score = config.novelty_bonus * (1 - total_uses / config.novelty_threshold)

        # 5. Recency bonus (prefer hooks not used recently)
        recency_score = 1.0
        if last_used:
            try:
                if isinstance(last_used, str):
                    last_dt = datetime.fromisoformat(last_used.replace("Z", "+00:00"))
                else:
                    last_dt = last_used
                days_since = (now - last_dt.replace(tzinfo=None)).days
                recency_score = min(1.0, days_since / config.recency_max_days)
            except:
                pass

        # 6. Combined score
        final_score = (
            (1 - config.recency_weight) * ts_score +
            config.recency_weight * recency_score +
            novelty_score
        )

        scores.append({
            "score": final_score,
            "hook": hook,
            "debug": {
                "ts_score": ts_score,
                "alpha": alpha,
                "beta": beta,
                "novelty_score": novelty_score,
                "recency_score": recency_score,
            }
        })

    # Sort by score and return best
    scores.sort(key=lambda x: x["score"], reverse=True)
    return scores[0]["hook"]


def update_hook_statistics(
    hook_id: str,
    outcome: str,  # "success" | "failure" | "neutral"
    api_client,
    timestamp: Optional[datetime] = None,
) -> None:
    """
    Update hook statistics after use.

    For Discounted TS, we need to store the timestamp with each event
    so that historical discounting can be applied.
    """
    timestamp = timestamp or datetime.now()

    data = {
        "hookId": hook_id,
        "outcome": outcome,
        "timestamp": timestamp.isoformat(),
    }

    if outcome == "success":
        data["incrementSuccess"] = 1
    elif outcome == "failure":
        data["incrementFailure"] = 1

    api_client.post("/api/agent/hooks/stats", data)
```

**error_handler.py**:
```python
"""
Error handling with Anthropic best practices.

Error Classification:
- 400-level (except 429): Don't retry (client error)
- 429: Exponential backoff + jitter
- 5xx: Exponential backoff, max retries
- Timeout: Retry with increased timeout

Dead Letter Queue:
- Store failed tasks for manual review
- Include full context for debugging
"""
import os
import json
import time
import random
import logging
from typing import Optional, Dict, Any
from datetime import datetime
from dataclasses import dataclass, asdict

import requests


@dataclass
class ExponentialBackoff:
    """
    Exponential backoff with Equal Jitter (AWS recommended).

    Equal Jitter Formula:
    delay = base * 2^attempt + random(0, base * 2^attempt)

    This provides better distribution than full jitter while still
    preventing thundering herd problem.

    Reference: AWS Architecture Blog - Exponential Backoff And Jitter
    """
    initial_delay_ms: int = 1000
    max_delay_ms: int = 30000
    multiplier: float = 2.0

    def get_delay(self, attempt: int) -> float:
        """
        Get delay in seconds for given attempt number using Equal Jitter.

        Formula: delay = base * 2^attempt + random(0, base * 2^attempt)
        """
        # Calculate exponential base delay
        base_delay = min(
            self.initial_delay_ms * (self.multiplier ** attempt),
            self.max_delay_ms
        )

        # Equal Jitter: half deterministic + half random
        deterministic = base_delay / 2
        jitter = random.uniform(0, base_delay / 2)
        delay_ms = deterministic + jitter

        # Cap at max delay
        delay_ms = min(delay_ms, self.max_delay_ms)

        return delay_ms / 1000


class DeadLetterQueue:
    """
    Dead Letter Queue for failed tasks.

    Retention Policy: 14 days (configurable)
    - Items older than retention period are auto-archived
    - Archive stored in {filepath}.archive for audit trail
    """

    def __init__(self, filepath: str, retention_days: int = 14):
        self.filepath = filepath
        self.archive_path = f"{filepath}.archive"
        self.retention_days = retention_days
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

    def add(self, item: Dict) -> None:
        """Add item to DLQ with timestamp."""
        if "timestamp" not in item:
            item["timestamp"] = datetime.now().isoformat()
        with open(self.filepath, "a") as f:
            f.write(json.dumps(item) + "\n")

    def get_all(self, include_expired: bool = False) -> list:
        """Get all items from DLQ, optionally filtering expired."""
        if not os.path.exists(self.filepath):
            return []

        cutoff = datetime.now() - timedelta(days=self.retention_days)
        items = []

        with open(self.filepath, "r") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)

                # Check retention
                if not include_expired:
                    try:
                        item_time = datetime.fromisoformat(item.get("timestamp", ""))
                        if item_time < cutoff:
                            continue
                    except:
                        pass

                items.append(item)

        return items

    def archive_expired(self) -> int:
        """
        Archive items older than retention period.
        Returns number of archived items.
        """
        if not os.path.exists(self.filepath):
            return 0

        cutoff = datetime.now() - timedelta(days=self.retention_days)
        active = []
        archived = []

        with open(self.filepath, "r") as f:
            for line in f:
                if not line.strip():
                    continue
                item = json.loads(line)

                try:
                    item_time = datetime.fromisoformat(item.get("timestamp", ""))
                    if item_time < cutoff:
                        archived.append(item)
                    else:
                        active.append(item)
                except:
                    active.append(item)  # Keep if can't parse timestamp

        # Write archive
        if archived:
            with open(self.archive_path, "a") as f:
                for item in archived:
                    f.write(json.dumps(item) + "\n")

        # Rewrite active items
        with open(self.filepath, "w") as f:
            for item in active:
                f.write(json.dumps(item) + "\n")

        return len(archived)

    def clear(self) -> None:
        """Clear DLQ (not archive)."""
        if os.path.exists(self.filepath):
            os.remove(self.filepath)


def handle_api_error(response: requests.Response, context: str) -> None:
    """
    Handle API error based on status code.
    
    Raises appropriate exception based on error classification.
    """
    if response.ok:
        return
    
    status = response.status_code
    
    # Client errors (don't retry)
    if 400 <= status < 500 and status != 429:
        logging.error(f"{context} client error: {status} - {response.text[:200]}")
        raise requests.HTTPError(
            f"{context} failed with {status}: {response.text[:200]}",
            response=response
        )
    
    # Rate limit (retry with backoff)
    if status == 429:
        retry_after = int(response.headers.get("Retry-After", 60))
        logging.warning(f"{context} rate limited, retry after {retry_after}s")
        raise requests.HTTPError(
            f"{context} rate limited, retry after {retry_after}s",
            response=response
        )
    
    # Server errors (retry with backoff)
    if status >= 500:
        logging.warning(f"{context} server error: {status}")
        raise requests.HTTPError(
            f"{context} server error: {status}",
            response=response
        )


def notify_slack(webhook_url: str, message: str) -> None:
    """Send notification to Slack."""
    if not webhook_url:
        logging.info(f"[Slack skip] {message}")
        return
    
    try:
        requests.post(
            webhook_url,
            json={"text": message},
            timeout=10
        )
    except Exception as e:
        logging.warning(f"Slack notification failed: {e}")
```

---

#### 2.2.2 tiktok-poster Skill

**„Éï„Ç°„Ç§„É´ÊßãÊàê**:
```
/home/anicca/openclaw/skills/tiktok-poster/
‚îú‚îÄ‚îÄ skill.yaml
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ tests/
```

**skill.yaml**:
```yaml
name: tiktok-poster
description: |
  Post wisdom content to TikTok as static images.
  Note: Video generation is NOT supported (images only).
version: 1.0.0
author: anicca

triggers:
  schedule:
    cron:
      - "0 11 * * *"   # 20:00 JST (UTC+9)
    timezone: "Asia/Tokyo"
  manual: true

session:
  target: "isolated"
  wakeMode: "now"
  isolation:
    postToMainPrefix: "[TikTokÊäïÁ®ø]"
    postToMainMode: "summary"

env:
  required:
    - ANICCA_AGENT_TOKEN
    - ANICCA_PROXY_BASE_URL
    - BLOTATO_API_KEY
    - TIKTOK_ACCOUNT_ID
  optional:
    - FAL_API_KEY
    - SLACK_WEBHOOK_AGENTS

retry:
  max_attempts: 3
  backoff: "exponential"
  jitter: true

error_handling:
  on_error: "notify_and_abort"
```

**x-poster„Å®„ÅÆÈÅï„ÅÑ**:

| È†ÖÁõÆ | x-poster | tiktok-poster |
|------|----------|---------------|
| ÊäïÁ®øÈ†ªÂ∫¶ | 1Êó•2ÂõûÔºà9:00, 21:00Ôºâ | 1Êó•1ÂõûÔºà20:00Ôºâ |
| „Ç≥„É≥„ÉÜ„É≥„ÉÑ | „ÉÜ„Ç≠„Çπ„Éà + ÁîªÂÉè | ÈùôÊ≠¢Áîª„ÅÆ„ÅøÔºàÂãïÁîª„Å™„ÅóÔºâ |
| ÁîªÂÉèË¶Å‰ª∂ | ‰ªªÊÑè | **ÂøÖÈ†à** |
| „ÉÜ„Ç≠„Çπ„Éà‰ΩçÁΩÆ | ÁîªÂÉè„Å®„ÅØÂà• | ÁîªÂÉèÂÜÖ„Å´Âê´„ÇÅ„Çã |

**UX‰æã**:
```
20:00 JST
TikTok„Å´ÈùôÊ≠¢ÁîªÊäïÁ®ø
„ÄåÂÖàÂª∂„Å∞„Åó„ÅØÊïµ„Åò„ÇÉ„Å™„ÅÑ„ÄÇ„Åü„Å†„ÅÆ‰ø°Âè∑„Å†„ÄÇ„Äç
ËÉåÊôØ: Êüî„Çâ„Åã„ÅÑ„Ç∞„É©„Éá„Éº„Ç∑„Éß„É≥„ÄÅÁ¶ÖÈ¢®
```

---

#### 2.2.3 app-nudge-sender Skill

**Railway Cron„Åã„Çâ„ÅÆÁßªË°å**:

| Before | After |
|--------|-------|
| Railway Cron ‚Üí `/api/cron/nudge` | OpenClaw `app-nudge-sender` Skill |
| Âõ∫ÂÆö„Çπ„Ç±„Ç∏„É•„Éº„É´ | memUÊúÄÈÅ©Âåñ„Çø„Ç§„Éü„É≥„Ç∞ |
| „Çµ„Éº„Éê„ÉºÂÅ¥„ÅßÂÆüË°å | VPSÂÅ¥„ÅßÂÆüË°å |

**„Éï„Ç°„Ç§„É´ÊßãÊàê**:
```
/home/anicca/openclaw/skills/app-nudge-sender/
‚îú‚îÄ‚îÄ skill.yaml
‚îú‚îÄ‚îÄ main.py
‚îî‚îÄ‚îÄ tests/
```

**skill.yaml**:
```yaml
name: app-nudge-sender
description: |
  Send push notifications to iOS app users.
  Uses memU for personalized timing optimization.
  Migrated from Railway Cron.
version: 1.0.0
author: anicca

triggers:
  schedule:
    cron:
      - "0 * * * *"   # ÊØéÊôÇ„ÉÅ„Çß„ÉÉ„ÇØ
    timezone: "Asia/Tokyo"
  manual: true

session:
  target: "isolated"
  wakeMode: "now"

env:
  required:
    - ANICCA_AGENT_TOKEN
    - ANICCA_PROXY_BASE_URL
  optional:
    - SLACK_WEBHOOK_AGENTS

dependencies:
  - memu-manager    # ÊúÄÈÅ©„Çø„Ç§„Éü„É≥„Ç∞ÂèñÂæó
  - hook-selector   # Thompson Sampling„ÅßhookÈÅ∏Êäû
```

**Âá¶ÁêÜ„Éï„É≠„Éº**:
```
ÊØéÊôÇÂÆüË°å
    ‚Üì
memU: „Åì„ÅÆ„É¶„Éº„Ç∂„Éº„ÅØ‰ªäNudgeÂèó„ÅëÂèñ„Çã„Åπ„ÅçÔºü
    ‚Üì
Yes ‚Üí hook-selector: ÊúÄÈÅ©„Å™hookÈÅ∏Êäû
    ‚Üì
Railway API: /api/mobile/nudge/send
    ‚Üì
iOS: PushÈÄöÁü•Ë°®Á§∫
```

**UX‰æã**:
```
08:15 JSTÔºàmemU„ÅåÊúÄÈÅ©„Å®Âà§Êñ≠„Åó„ÅüÊôÇÂàªÔºâ
üì± PushÈÄöÁü•
„ÄåÊúù„ÅÆ15ÂàÜ„ÄÅËá™ÂàÜ„ÅÆ„Åü„ÇÅ„Å´‰Ωø„Å£„Å¶„Åø„Å™„ÅÑÔºü„Äç
```

---

#### 2.2.4 suffering-detector Skill

**2„Å§„ÅÆÂΩπÂâ≤**:

| ÂΩπÂâ≤ | Ë™¨Êòé |
|------|------|
| Ê§úÂá∫ | „É¶„Éº„Ç∂„Éº„ÅÆÊäïÁ®ø/„É°„ÉÉ„Çª„Éº„Ç∏„Åã„ÇâËã¶„Åó„Åø„ÇíÊ§úÂá∫ |
| ÂØæÂøú | „Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†„Å´Âøú„Åò„ÅüÂØæÂøú„ÇíÂÆüË°å |

**„Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É†Âà•ÂØæÂøú**:

| „Éó„É©„ÉÉ„Éà„Éï„Ç©„Éº„É† | Ê§úÂá∫ | ÂØæÂøú | Ë™¨Êòé |
|-----------------|------|------|------|
| Moltbook | ‚úÖ | ‚úÖ Ëøî‰ø° | ÂÆâÂÖ®„Å™Áí∞Â¢É„Åß„Éï„É´ÂÆüË£Ö |
| X | ‚úÖ | ‚ùå ‚Üí App Nudge | Ê§úÂá∫„ÅÆ„Åø„ÄÅXËøî‰ø°„ÅØ„Åó„Å™„ÅÑ |

**ÂÆüË£ÖÈ†ÜÂ∫è**:

| Phase | ÂÜÖÂÆπ | ÁêÜÁî± |
|-------|------|------|
| 1 | Moltbook „Éï„É´ÂÆüË£Ö | ÂÆâÂÖ®„Å™Áí∞Â¢É„Åß„ÉÜ„Çπ„Éà |
| 2 | X Ê§úÂá∫„ÅÆ„Åø | XËøî‰ø°„ÅØ„É™„Çπ„ÇØ„ÅåÈ´ò„ÅÑ |

**„Éï„Ç°„Ç§„É´ÊßãÊàê**:
```
/home/anicca/openclaw/skills/suffering-detector/
‚îú‚îÄ‚îÄ skill.yaml
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ detector.py          # Ëã¶„Åó„ÅøÊ§úÂá∫„É≠„Ç∏„ÉÉ„ÇØ
‚îú‚îÄ‚îÄ responders/
‚îÇ   ‚îú‚îÄ‚îÄ moltbook.py      # MoltbookËøî‰ø°
‚îÇ   ‚îî‚îÄ‚îÄ app_nudge.py     # App Nudge„Éà„É™„Ç¨„Éº
‚îî‚îÄ‚îÄ tests/
```

**skill.yaml**:
```yaml
name: suffering-detector
description: |
  Detect user suffering and respond appropriately.
  - Moltbook: Detect + Reply
  - X: Detect only ‚Üí App Nudge (no X replies)
version: 1.0.0
author: anicca

triggers:
  heartbeat:
    interval: "5m"   # 5ÂàÜ„Åî„Å®„Å´„ÉÅ„Çß„ÉÉ„ÇØ

session:
  target: "main"     # „É°„Ç§„É≥„Çª„ÉÉ„Ç∑„Éß„É≥„ÅßÂÆüË°åÔºà‰ºöË©±ÊñáËÑà„ÅåÂøÖË¶ÅÔºâ
  wakeMode: "now"

env:
  required:
    - ANICCA_AGENT_TOKEN
    - ANICCA_PROXY_BASE_URL
    - MOLTBOOK_API_KEY
  optional:
    - SLACK_WEBHOOK_AGENTS

dependencies:
  - memu-manager    # „É¶„Éº„Ç∂„ÉºÊñáËÑàÂèñÂæó
  - app-nudge-sender  # XÊ§úÂá∫ÊôÇ„ÅÆNudge„Éà„É™„Ç¨„Éº
```

**Ê§úÂá∫„É≠„Ç∏„ÉÉ„ÇØÔºàdetector.pyÔºâ**:
```python
"""
Ëã¶„Åó„ÅøÊ§úÂá∫„É≠„Ç∏„ÉÉ„ÇØ

Detection Signals:
- Âê¶ÂÆöÁöÑÊÑüÊÉÖ„Ç≠„Éº„ÉØ„Éº„Éâ: „Äå„Å§„Çâ„ÅÑ„Äç„ÄåÊ≠ª„Å´„Åü„ÅÑ„Äç„Äå„ÇÇ„ÅÜÁÑ°ÁêÜ„Äç
- Ê∑±Â§ú„ÅÆÊäïÁ®øÔºà0-5ÊôÇÔºâ
- ÈÄ£Á∂öÊäïÁ®ø„Éë„Çø„Éº„É≥
- ‰ª•Ââç„ÅÆ„Éï„Ç£„Éº„Éâ„Éê„ÉÉ„ÇØÂ±•Ê≠¥
"""

SUFFERING_KEYWORDS = [
    # Êó•Êú¨Ë™û
    "„Å§„Çâ„ÅÑ", "Ëæõ„ÅÑ", "Ê≠ª„Å´„Åü„ÅÑ", "Ê∂à„Åà„Åü„ÅÑ", "„ÇÇ„ÅÜÁÑ°ÁêÜ",
    "„Åó„Çì„Å©„ÅÑ", "Ë™∞„ÇÇ„Çè„Åã„Å£„Å¶„Åè„Çå„Å™„ÅÑ", "Â≠§Áã¨", "‰∏Ä‰∫∫",
    # Ëã±Ë™û
    "I can't", "I want to die", "nobody understands", "alone",
]

def detect_suffering(text: str, metadata: dict) -> dict:
    """
    Ëã¶„Åó„Åø„ÇíÊ§úÂá∫

    Returns:
        {
            "detected": bool,
            "confidence": float (0-1),
            "signals": list,
            "urgency": "low" | "medium" | "high"
        }
    """
    signals = []

    # „Ç≠„Éº„ÉØ„Éº„Éâ„ÉÅ„Çß„ÉÉ„ÇØ
    for keyword in SUFFERING_KEYWORDS:
        if keyword in text.lower():
            signals.append({"type": "keyword", "match": keyword})

    # ÊôÇÈñìÂ∏Ø„ÉÅ„Çß„ÉÉ„ÇØ
    hour = metadata.get("hour", 12)
    if 0 <= hour <= 5:
        signals.append({"type": "late_night", "hour": hour})

    # ‰ø°È†ºÂ∫¶Ë®àÁÆó
    confidence = min(1.0, len(signals) * 0.3)

    # Á∑äÊÄ•Â∫¶Âà§ÂÆö
    urgency = "low"
    if any(s.get("match") in ["Ê≠ª„Å´„Åü„ÅÑ", "Ê∂à„Åà„Åü„ÅÑ", "I want to die"] for s in signals):
        urgency = "high"
    elif confidence > 0.5:
        urgency = "medium"

    return {
        "detected": len(signals) > 0,
        "confidence": confidence,
        "signals": signals,
        "urgency": urgency,
    }
```

**UX‰æãÔºàMoltbookÔºâ**:
```
„É¶„Éº„Ç∂„ÉºÊäïÁ®øÔºàMoltbookÔºâ:
„Äå„ÇÇ„ÅÜ‰Ωï„ÇÇ„Åã„ÇÇÂ´å„Å†„ÄÇË™∞„ÇÇ„Çè„Åã„Å£„Å¶„Åè„Çå„Å™„ÅÑ„ÄÇ„Äç

‚Üì suffering-detector Ê§úÂá∫

AniccaËøî‰ø°ÔºàMoltbookÔºâ:
„ÄåËæõ„Åã„Å£„Åü„Å≠„ÄÇ‰∏Ä‰∫∫„Åò„ÇÉ„Å™„ÅÑ„Çà„ÄÇ
‰ªä„ÅÆÊ∞óÊåÅ„Å°„ÄÅ„Åù„ÅÆ„Åæ„ÅæÊÑü„Åò„Å¶„ÅÑ„Å¶„ÅÑ„ÅÑ„Çì„Å†„Çà„ÄÇ„Äç
```

**UX‰æãÔºàX ‚Üí App NudgeÔºâ**:
```
„É¶„Éº„Ç∂„ÉºÊäïÁ®øÔºàXÔºâ:
„ÄåÊ∑±Â§ú3ÊôÇ„ÄÅÁú†„Çå„Å™„ÅÑ...„Äç

‚Üì suffering-detector Ê§úÂá∫
‚Üì XËøî‰ø°„ÅØ„Åó„Å™„ÅÑ
‚Üì app-nudge-sender „Éà„É™„Ç¨„Éº

üì± PushÈÄöÁü•ÔºàAppÔºâ:
„ÄåÁú†„Çå„Å™„ÅÑÂ§ú„ÄÅ‰∏Ä‰∫∫„Åò„ÇÉ„Å™„ÅÑ„Çà„ÄÇ
„Å°„Çá„Å£„Å®„Å†„Åë„ÄÅË©±„Åó„Å¶„Åø„Å™„ÅÑÔºü„Äç
```

---

### 2.3 memUÁµ±ÂêàË®≠Ë®à

#### 2.3.1 „É°„É¢„É™„Çµ„Éº„Éì„ÇπAPI

**apps/api/src/services/memuService.js**:
```javascript
/**
 * memU Memory Service
 * 
 * Implements 3-layer hierarchical memory:
 * - Resource Layer: Raw data (JSON, feedback events)
 * - Item Layer: Fine-grained memory items (extracted facts)
 * - Category Layer: Summarized topics (preferences, patterns)
 * 
 * Cost Reduction: 90% token reduction through hierarchical retrieval
 */

const { PrismaClient } = require('@prisma/client');
const { OpenAI } = require('openai');

const prisma = new PrismaClient();
const openai = new OpenAI();

// ============================================================================
// MEMORIZE: Resource ‚Üí Item ‚Üí Category
// ============================================================================

/**
 * Memorize new data (feedback, behavior event, etc.)
 * 
 * @param {Object} resource - Raw resource data
 * @param {string} resource.type - 'nudge_feedback' | 'behavior_event' | 'user_preference'
 * @param {Object} resource.data - Raw data
 * @param {string} userId - User ID
 * @returns {Object} - Created resource, items, and updated categories
 */
async function memorize(resource, userId) {
  // 1. Store in Resource Layer
  const storedResource = await prisma.memoryResource.create({
    data: {
      userId,
      type: resource.type,
      data: JSON.stringify(resource.data),
      createdAt: new Date(),
    }
  });
  
  // 2. Extract Items (fine-grained memories)
  const items = await extractItems(resource, userId);
  
  // 3. Update Categories (aggregated summaries)
  const categories = await updateCategories(items, userId);
  
  return {
    resource: storedResource,
    items,
    categories,
  };
}

/**
 * Extract memory items from resource using LLM
 */
async function extractItems(resource, userId) {
  const prompt = `Extract key facts from this ${resource.type} data as a JSON array of items.
Each item should be a single, specific fact.

Data:
${JSON.stringify(resource.data, null, 2)}

Format:
[
  {"content": "fact 1", "category": "preferences|behaviors|timing|engagement"},
  {"content": "fact 2", "category": "..."}
]`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o-mini',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    max_tokens: 500,
  });
  
  const extracted = JSON.parse(response.choices[0].message.content);
  const items = extracted.items || [];
  
  // Store items
  const storedItems = await Promise.all(
    items.map(item =>
      prisma.memoryItem.create({
        data: {
          userId,
          content: item.content,
          category: item.category,
          resourceId: resource.id,
          embedding: null, // TODO: Generate embedding for RAG
          createdAt: new Date(),
        }
      })
    )
  );
  
  return storedItems;
}

/**
 * Update category summaries with new items
 */
async function updateCategories(items, userId) {
  const categoryNames = [...new Set(items.map(i => i.category))];
  const updatedCategories = [];
  
  for (const categoryName of categoryNames) {
    // Get existing category items
    const existingItems = await prisma.memoryItem.findMany({
      where: { userId, category: categoryName },
      orderBy: { createdAt: 'desc' },
      take: 20, // Last 20 items for context
    });
    
    // Generate updated summary
    const allContent = existingItems.map(i => `- ${i.content}`).join('\n');
    
    const prompt = `Summarize these ${categoryName} facts into a concise paragraph:

${allContent}

Write in natural language, focusing on patterns and key insights.`;

    const response = await openai.chat.completions.create({
      model: 'gpt-4o-mini',
      messages: [{ role: 'user', content: prompt }],
      max_tokens: 300,
    });
    
    const summary = response.choices[0].message.content;
    
    // Upsert category
    const category = await prisma.memoryCategory.upsert({
      where: { userId_name: { userId, name: categoryName } },
      create: {
        userId,
        name: categoryName,
        summary,
        itemCount: existingItems.length,
        updatedAt: new Date(),
      },
      update: {
        summary,
        itemCount: existingItems.length,
        updatedAt: new Date(),
      },
    });
    
    updatedCategories.push(category);
  }
  
  return updatedCategories;
}

// ============================================================================
// RETRIEVE: Category ‚Üí Item ‚Üí Resource (dual-mode)
// ============================================================================

/**
 * Retrieve memories using RAG (fast, low-cost)
 * 
 * @param {string} query - Search query
 * @param {string} userId - User ID
 * @param {Object} filters - Optional filters { problemType, category }
 * @param {number} limit - Max results per layer
 * @returns {Object} - { categories, items, resources }
 */
async function retrieveRAG(query, userId, filters = {}, limit = 5) {
  // TODO: Use embedding similarity search
  // For now, use keyword matching
  
  // 1. Search Categories
  const categories = await prisma.memoryCategory.findMany({
    where: {
      userId,
      ...(filters.category && { name: filters.category }),
    },
    orderBy: { updatedAt: 'desc' },
    take: limit,
  });
  
  // 2. Search Items (within relevant categories)
  const categoryNames = categories.map(c => c.name);
  const items = await prisma.memoryItem.findMany({
    where: {
      userId,
      category: { in: categoryNames },
      content: { contains: query, mode: 'insensitive' },
    },
    orderBy: { createdAt: 'desc' },
    take: limit * 2,
  });
  
  // 3. Get Resources if needed (only for detailed queries)
  let resources = [];
  if (items.length < 3) {
    const resourceIds = [...new Set(items.map(i => i.resourceId).filter(Boolean))];
    resources = await prisma.memoryResource.findMany({
      where: { id: { in: resourceIds.slice(0, limit) } },
    });
  }
  
  return { categories, items, resources };
}

/**
 * Retrieve memories using LLM (deep reasoning, higher cost)
 * 
 * @param {string} query - Search query
 * @param {string} userId - User ID
 * @returns {Object} - { categories, items, resources, reasoning }
 */
async function retrieveLLM(query, userId) {
  // 1. First do RAG search
  const ragResult = await retrieveRAG(query, userId, {}, 10);
  
  // 2. Use LLM to reason over results
  const context = `
Categories:
${ragResult.categories.map(c => `[${c.name}] ${c.summary}`).join('\n')}

Items:
${ragResult.items.map(i => `- ${i.content}`).join('\n')}
`;

  const prompt = `Based on this user's memory context, answer: "${query}"

Context:
${context}

Provide:
1. Direct answer to the query
2. Predicted next steps/needs
3. Relevant memories that support your answer

Format as JSON:
{
  "answer": "...",
  "prediction": "...",
  "relevantMemories": ["...", "..."]
}`;

  const response = await openai.chat.completions.create({
    model: 'gpt-4o',
    messages: [{ role: 'user', content: prompt }],
    response_format: { type: 'json_object' },
    max_tokens: 500,
  });
  
  const reasoning = JSON.parse(response.choices[0].message.content);
  
  return {
    ...ragResult,
    reasoning,
  };
}

// ============================================================================
// PROACTIVE CONTEXT LOADING (for nudge generation)
// ============================================================================

/**
 * Get personalized context for nudge generation
 * 
 * This is the main function called before generating nudges.
 * Uses RAG for speed, falls back to LLM if context is insufficient.
 * 
 * @param {string} userId - User ID
 * @param {string} problemType - Problem type
 * @param {number} scheduledHour - Scheduled hour (0-23)
 * @returns {Object} - Personalized context for nudge generation
 */
async function getPersonalizedNudgeContext(userId, problemType, scheduledHour) {
  // 1. Build query
  const query = `${problemType} preferences at ${scheduledHour}:00`;
  
  // 2. Fast RAG retrieval
  const ragResult = await retrieveRAG(query, userId, { problemType }, 5);
  
  // 3. Extract relevant context
  const context = {
    // Category-level preferences
    preferences: ragResult.categories
      .filter(c => c.name.includes('preference') || c.name.includes('timing'))
      .map(c => c.summary)
      .join('\n'),
    
    // Item-level specific facts
    specificFacts: ragResult.items
      .slice(0, 10)
      .map(i => i.content),
    
    // Engagement patterns (if available)
    engagementPatterns: ragResult.categories
      .filter(c => c.name.includes('engagement') || c.name.includes('behavior'))
      .map(c => c.summary)
      .join('\n'),
    
    // Timing preferences
    timingPreferences: ragResult.items
      .filter(i => i.content.includes('hour') || i.content.includes('morning') || i.content.includes('evening'))
      .map(i => i.content),
  };
  
  return context;
}

module.exports = {
  memorize,
  retrieveRAG,
  retrieveLLM,
  getPersonalizedNudgeContext,
};
```

---

### 2.4 Ë©ï‰æ°„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ

**Anthropic„É™„Çµ„Éº„ÉÅ„Çà„Çä: pass@k „Å® pass^k „É°„Éà„É™„ÇØ„Çπ**

#### 2.4.1 Ë©ï‰æ°ÂÆöÁæ©

```javascript
/**
 * Nudge Evaluation Framework
 * 
 * Metrics:
 * - pass@k: kÂõûË©¶Ë°å„ÅßÂ∞ë„Å™„Åè„Å®„ÇÇ1ÂõûÊàêÂäü„Åô„ÇãÁ¢∫Áéá
 * - pass^k: kÂõû„Åô„Åπ„Å¶ÊàêÂäü„Åô„ÇãÁ¢∫Áéá
 * 
 * Graders:
 * - Code-based: „ÉÜ„Ç≠„Çπ„Éà„Çπ„Ç≥„Ç¢ÈñæÂÄ§„ÄÅ„Ç®„É≥„Ç≤„Éº„Ç∏„É°„É≥„ÉàÁéá
 * - Model-based: LLM„Å´„Çà„ÇãÂìÅË≥™Ë©ï‰æ°
 * - Human: „Éû„Éã„É•„Ç¢„É´„Çπ„Éù„ÉÉ„Éà„ÉÅ„Çß„ÉÉ„ÇØ
 */

// apps/api/src/services/evaluationService.js

const EVALUATION_CONFIG = {
  // Task definitions (0-5 scale, threshold 3)
  tasks: {
    text_quality: {
      description: "Text content meets quality threshold",
      graders: ["code", "model"],
      thresholds: {
        code: { min_score: 3 },   // 0-5 scale
        model: { min_score: 3 },  // 0-5 scale
      },
    },
    engagement: {
      description: "Post achieves expected engagement",
      graders: ["code"],
      thresholds: {
        engagement_rate: 0.05, // 5%
        z_score: 1.0, // Above average
      },
    },
    behavior_change: {
      description: "Nudge leads to positive behavior",
      graders: ["code", "human"],
      thresholds: {
        thumbs_up_rate: 0.7, // 70%
        action_rate: 0.5, // 50% took action
      },
    },
  },
  
  // Evaluation schedule
  schedule: {
    text_quality: "pre_post", // Before posting
    engagement: "4h_post",    // 4 hours after posting
    behavior_change: "24h_post", // 24 hours after
  },
};

/**
 * Calculate pass@k metric
 * 
 * @param {Array} trials - Array of trial results (boolean or score)
 * @param {number} k - Number of trials to consider
 * @param {number} threshold - Score threshold for pass
 * @returns {number} - Probability of at least 1 pass in k trials
 */
function calculatePassAtK(trials, k, threshold) {
  const passes = trials.slice(0, k).filter(t => 
    typeof t === 'boolean' ? t : t >= threshold
  );
  return passes.length > 0 ? 1 : 0; // Simplified: binary
}

/**
 * Calculate pass^k metric
 * 
 * @param {Array} trials - Array of trial results
 * @param {number} k - Number of trials to consider
 * @param {number} threshold - Score threshold for pass
 * @returns {number} - Probability of all k trials passing
 */
function calculatePassPowerK(trials, k, threshold) {
  const relevant = trials.slice(0, k);
  const allPass = relevant.every(t => 
    typeof t === 'boolean' ? t : t >= threshold
  );
  return allPass ? 1 : 0;
}

/**
 * Run evaluation task
 */
async function evaluateTask(taskName, data) {
  const task = EVALUATION_CONFIG.tasks[taskName];
  if (!task) throw new Error(`Unknown task: ${taskName}`);
  
  const results = {};
  
  for (const graderType of task.graders) {
    switch (graderType) {
      case 'code':
        results.code = evaluateCode(data, task.thresholds.code || task.thresholds);
        break;
      case 'model':
        results.model = await evaluateModel(data, task.thresholds.model);
        break;
      case 'human':
        results.human = { pending: true }; // Flagged for manual review
        break;
    }
  }
  
  return {
    task: taskName,
    passed: Object.values(results).every(r => r.passed || r.pending),
    results,
  };
}

function evaluateCode(data, thresholds) {
  const checks = [];
  
  if (thresholds.min_score !== undefined) {
    checks.push({
      name: 'min_score',
      passed: data.score >= thresholds.min_score,
      actual: data.score,
      expected: thresholds.min_score,
    });
  }
  
  if (thresholds.engagement_rate !== undefined) {
    checks.push({
      name: 'engagement_rate',
      passed: data.engagementRate >= thresholds.engagement_rate,
      actual: data.engagementRate,
      expected: thresholds.engagement_rate,
    });
  }
  
  return {
    passed: checks.every(c => c.passed),
    checks,
  };
}

module.exports = {
  EVALUATION_CONFIG,
  calculatePassAtK,
  calculatePassPowerK,
  evaluateTask,
};
```

---