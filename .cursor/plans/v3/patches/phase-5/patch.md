# Anicca v0.3 ãƒ•ã‚§ãƒ¼ã‚º5 æ“¬ä¼¼ãƒ‘ãƒƒãƒ

## æ¦‚è¦
- å¯¾è±¡ãƒ•ã‚§ãƒ¼ã‚º: 5ï¼ˆiOS UI: Talk / Sessionï¼‰
- å¯¾è±¡ã‚¿ã‚¹ã‚¯: `5.1`ã€œ`5.5`
- å‡ºåŠ›ç‰©: **ã“ã® `patch.md` ã®ã¿**ï¼ˆã‚³ãƒ¼ãƒ‰ã¯ã¾ã è§¦ã‚‰ãªã„å‰æï¼‰

## å¯¾è±¡ã‚¿ã‚¹ã‚¯ï¼ˆtodolist.md ã‹ã‚‰ï¼‰
- `5.1 TalkView/FeelingCardæ§‹ç¯‰`
- `5.2 QuoteCardé€£æº`
- `5.3 SessionView/Orb/EMA UI`
- `5.4 VoiceSessionControlleræ‹¡å¼µ`
- `5.5 Realtimeãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/ãƒ„ãƒ¼ãƒ«å®šç¾©æ›´æ–°`

## å‚ç…§ä»•æ§˜ï¼ˆv3ï¼‰
- `.cursor/plans/v3/todolist.md`ï¼ˆãƒ•ã‚§ãƒ¼ã‚º5ï¼‰
- `.cursor/plans/v3/v3-ui.md`ï¼ˆTalk / Session / Orb / EMAï¼‰
- `.cursor/plans/v3/v3-ux.md`ï¼ˆãƒˆãƒ¼ãƒ³ï¼‰
- `.cursor/plans/v3/prompts-v3.md`ï¼ˆRealtime tools schema / ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–¹é‡ï¼‰
- `.cursor/plans/v3/migration-patch-v3.md`ï¼ˆ1.2: VoiceSessionControlleræ‹¡å¼µã®æ–¹é‡ï¼‰
- `.cursor/plans/v3/tech-ema-v3.md`ï¼ˆEMA: UI/é–¾å€¤/é€ä¿¡ä»•æ§˜ï¼‰
- `.cursor/plans/v3/file-structure-v3.md`ï¼ˆViews/Talk, Views/Session ã®é…ç½®ï¼‰
- æ—¢å­˜ã‚³ãƒ¼ãƒ‰:
  - `aniccaios/aniccaios/VoiceSessionController.swift`
  - `aniccaios/aniccaios/SessionView.swift`ï¼ˆç¾çŠ¶ã¯ Talk ã‚¿ãƒ–ç›¸å½“ã¨ã—ã¦ä½¿ã‚ã‚Œã¦ã„ã‚‹ï¼‰
  - `aniccaios/aniccaios/Services/NetworkSessionManager.swift`
  - `aniccaios/aniccaios/Resources/Prompts/*`

## å‚ç…§ã—ãŸå…¬å¼URLä¸€è¦§ï¼ˆå¦„æƒ³ç¦æ­¢ã®ãŸã‚ã®ä¸€æ¬¡æƒ…å ±ï¼‰
> æœ¬ãƒ•ã‚§ãƒ¼ã‚ºã¯ Realtime ã®ã‚¤ãƒ™ãƒ³ãƒˆåãƒ»payload å½¢ãŒç ´ç¶»ã™ã‚‹ã¨æˆç«‹ã—ãªã„ãŸã‚ã€**å…¬å¼API Referenceã‚’æ ¹æ‹ ã¨ã—ã¦å›ºå®š**ã™ã‚‹ã€‚

### OpenAIï¼ˆRealtime / Events / Toolsï¼‰
- `https://platform.openai.com/docs/guides/realtime-conversations`ï¼ˆRealtime conversations / ãƒ•ãƒ­ãƒ¼ / function calling ã® Realtime ç‰ˆï¼‰
- `https://platform.openai.com/docs/api-reference/realtime-client-events/session/update`ï¼ˆ`session.update` ã®å—ç†payloadï¼‰
- `https://platform.openai.com/docs/api-reference/realtime-client-events/response/create`ï¼ˆ`response.create`ï¼‰
- `https://platform.openai.com/docs/api-reference/realtime-server-events`ï¼ˆ`output_audio_buffer.started/stopped`ãƒ»`input_audio_buffer.speech_started/stopped`ãƒ»`response.done`ãƒ»`response.function_call_arguments.*` ç­‰ï¼‰
- `https://platform.openai.com/docs/guides/function-calling`ï¼ˆStrict mode / JSON schema ã®è¦ä»¶ï¼‰
- `https://platform.openai.com/docs/guides/tools`ï¼ˆtools æ¦‚è¦³ï¼‰

## é‡è¦ãªä»•æ§˜ãƒ¡ãƒ¢ï¼ˆv3-ui / tech-ema ã‹ã‚‰æŠœç²‹ã—ã¦å›ºå®šï¼‰
- Talk ã‚¿ãƒ–:
  - Quote ã‚«ãƒ¼ãƒ‰ + Feeling 4ã‚«ãƒ¼ãƒ‰ï¼ˆ3å‹•çš„ + `Something else` å›ºå®šï¼‰
  - ã‚«ãƒ¼ãƒ‰ã‚¿ãƒƒãƒ—ã§ `SessionView(topic: ...)` ã« push é·ç§»ï¼ˆ`Talk to Anicca` ãƒœã‚¿ãƒ³ã¯ç½®ã‹ãªã„ï¼‰
- Session:
  - ä¸Šéƒ¨pill: `Talking about <topic>`
  - é’ã‚ªãƒ¼ãƒ–: **breathï¼ˆå¸¸æ™‚ï¼‰ + ãƒã‚¤ã‚¯RMSé€£å‹•ï¼ˆå¿…é ˆã€0.9â€“1.1ã€å¹³æ»‘åŒ– 0.7:0.3ï¼‰**
  - çŠ¶æ…‹ãƒ†ã‚­ã‚¹ãƒˆ: `Anicca is listeningâ€¦ / speakingâ€¦`ï¼ˆRealtime çŠ¶æ…‹ã«åˆã‚ã›ã¦æ›´æ–°ï¼‰
  - ä¸‹éƒ¨: mic ãƒˆã‚°ãƒ«ï¼ˆå·¦ï¼‰ + Endï¼ˆå³ã€èµ¤ä¸¸ï¼‰
- EMA:
  - End/Back æ™‚ã«è¡¨ç¤º
  - ã‚»ãƒƒã‚·ãƒ§ãƒ³ç¶™ç¶š **5ç§’ä»¥ä¸Šã®ã¿**è¡¨ç¤ºã€‚æœªæº€ã¯ `emaBetter=null` æ‰±ã„ã§é€ä¿¡
  - è³ªå•: `Did you feel a bit better?` / `ã•ã£ãã‚ˆã‚Šæ¥½ã«ãªã£ãŸï¼Ÿ`
  - Yes/No/Skipï¼ˆSkip/ã‚¹ãƒ¯ã‚¤ãƒ—dismiss ã¯ `null`ï¼‰

## ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã®å¤‰æ›´æ¦‚è¦ï¼ˆãƒ•ã‚§ãƒ¼ã‚º5ï¼‰

### 1) Talk UI ã‚’ `Views/Talk/*` ã¨ã—ã¦æ–°è¨­ï¼ˆ5.1, 5.2ï¼‰
- `Views/Talk/TalkView.swift`: Quote + Feeling cardsï¼ˆpush ã§ Sessionï¼‰
- `Views/Talk/FeelingCard.swift`: v3-ui ã®ã‚«ãƒ¼ãƒ‰æ§‹é€ ã‚’å…±é€šåŒ–
- `Views/Talk/QuoteCard.swift`: QuoteProvider ã‹ã‚‰æ—¥æ›¿ã‚ã‚Šè¡¨ç¤ºï¼ˆä¾å­˜: ãƒ•ã‚§ãƒ¼ã‚º3.5ï¼‰
- `Views/Talk/FeelingTopic.swift`: Talk/Session å…±é€šã® topic åˆ—æŒ™

### 2) Session UI ã‚’ v3-ui ã«åˆã‚ã›ã¦åˆ·æ–°ï¼ˆ5.3ï¼‰
- `Views/Session/SessionView.swift`: pill / Orb / status / mic + end / EMA sheet
- `Views/Session/OrbView.swift`: AVAudioEngine ã® input tap ã§ RMSâ†’æ­£è¦åŒ–â†’å¹³æ»‘åŒ–â†’scale
- `Views/Session/EMAModal.swift`: tech-ema-v3 ã® UI/é–¾å€¤ã«æº–æ‹ 

### 3) Realtime payload/ã‚¤ãƒ™ãƒ³ãƒˆ/ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’å…¬å¼ä»•æ§˜ã¸å¯„ã›ã‚‹ï¼ˆ5.4, 5.5ï¼‰
- `VoiceSessionController.swift`:
  - `session.update` ã‚’ **å…¬å¼ã® `audio.{input,output}` / `output_modalities` å½¢å¼**ã¸ç§»è¡Œ
  - v3-ui ã®çŠ¶æ…‹è¡¨ç¤ºç”¨ã« `isModelSpeaking/isUserSpeaking` ã‚’ Publish
  - Realtime function calling ã‚’å—ã‘ãŸã‚‰ï¼ˆ`response.done` å†…ã® `function_call` itemï¼‰:
    - iOSâ†’`POST /tools/<name>` ã¸è»¢é€
    - `conversation.item.create`ï¼ˆ`function_call_output`ï¼‰ã§ Realtime ã«è¿”ã™
    - `response.create` ã§ä¼šè©±ã‚’ç¶šè¡Œ
- `Resources/Prompts/*`:
  - Talk ã‚»ãƒƒã‚·ãƒ§ãƒ³ã® system promptï¼ˆäººæ ¼ãƒ»çŸ­æ–‡ãƒ†ãƒ³ãƒãƒ»ç¦æ­¢äº‹é …ï¼‰ã‚’è¿½åŠ 
  - Realtime toolsï¼ˆ`get_context_snapshot` ç­‰ï¼‰ã® schema ã‚’è¿½åŠ ï¼ˆ**Realtime API å½¢å¼**ã§è¨˜è¿°ï¼‰

## å®Œå…¨ãƒ‘ãƒƒãƒï¼ˆapply_patch äº’æ›ï¼‰

### 5.1 TalkView / FeelingCardï¼ˆæ–°è¦ï¼‰

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Talk/FeelingTopic.swift
+import Foundation
+
+/// Talk/Session å…±é€šã®ãƒˆãƒ”ãƒƒã‚¯IDï¼ˆv3-ui ã® topic åã«åˆã‚ã›ã¦å›ºå®šï¼‰
+enum FeelingTopic: String, CaseIterable, Hashable, Identifiable {
+    case selfLoathing = "self_loathing"
+    case anxiety = "anxiety"
+    case irritation = "irritation"
+    case freeConversation = "free_conversation"
+
+    var id: String { rawValue }
+}
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Talk/FeelingCard.swift
+import SwiftUI
+
+struct FeelingCard: View {
+    let emoji: String
+    let title: LocalizedStringKey
+    let subtitle: LocalizedStringKey
+
+    var body: some View {
+        HStack(spacing: AppTheme.Spacing.lg) {
+            Text(emoji)
+                .font(.system(size: 28))
+                .frame(width: 36, height: 36, alignment: .center)
+
+            VStack(alignment: .leading, spacing: 6) {
+                Text(title)
+                    .font(AppTheme.Typography.headlineDynamic)
+                    .foregroundStyle(AppTheme.Colors.label)
+
+                Text(subtitle)
+                    .font(AppTheme.Typography.subheadlineDynamic)
+                    .foregroundStyle(AppTheme.Colors.secondaryLabel)
+                    .fixedSize(horizontal: false, vertical: true)
+            }
+
+            Spacer(minLength: 0)
+        }
+        .padding(AppTheme.Spacing.lg)
+        .frame(maxWidth: .infinity, alignment: .leading)
+        .background(
+            RoundedRectangle(cornerRadius: AppTheme.Radius.card, style: .continuous)
+                .fill(AppTheme.Colors.cardBackground)
+                .shadow(color: .black.opacity(0.05), radius: 8, x: 0, y: 2)
+        )
+        .overlay(
+            RoundedRectangle(cornerRadius: AppTheme.Radius.card, style: .continuous)
+                .stroke(AppTheme.Colors.borderLight, lineWidth: 1)
+        )
+        .contentShape(RoundedRectangle(cornerRadius: AppTheme.Radius.card, style: .continuous))
+    }
+}
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Talk/QuoteCard.swift
+import SwiftUI
+
+struct QuoteCard: View {
+    let quote: String
+
+    var body: some View {
+        Text(quote)
+            .font(AppTheme.Typography.bodyDynamic)
+            .foregroundStyle(AppTheme.Colors.label)
+            .multilineTextAlignment(.center)
+            .padding(AppTheme.Spacing.xl)
+            .frame(maxWidth: .infinity)
+            .background(
+                RoundedRectangle(cornerRadius: AppTheme.Radius.card, style: .continuous)
+                    .fill(AppTheme.Colors.cardBackground)
+                    .shadow(color: .black.opacity(0.05), radius: 8, x: 0, y: 2)
+            )
+            .overlay(
+                RoundedRectangle(cornerRadius: AppTheme.Radius.card, style: .continuous)
+                    .stroke(AppTheme.Colors.borderLight, lineWidth: 1)
+            )
+    }
+}
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Talk/TalkView.swift
+import SwiftUI
+
+struct TalkView: View {
+    @EnvironmentObject private var appState: AppState
+
+    // v3-ux: ä¸Š3ã¤ã¯å‹•çš„ã€‚v0.3 ã§ã¯ã¾ãšã€Œå›ºå®š + è»½ã„ä¸¦ã¹æ›¿ãˆã€â†’ tool/context å°å…¥å¾Œã«å·®ã—æ›¿ãˆã€‚
+    private var topics: [FeelingTopic] {
+        // æœ€ä½é™: Something else ã¯å¸¸ã«æœ«å°¾å›ºå®š
+        let base: [FeelingTopic] = [.selfLoathing, .anxiety, .irritation]
+
+        // æ—¢å­˜ UserProfile.problemsï¼ˆä¾‹: rumination/self_criticism/anxietyï¼‰ã‚’è»½ãåæ˜ ã—ã€ä¸Šã«å¯„ã›ã‚‹
+        // â€»å³å¯†ãªé¸åˆ¥ã¯ v3 ã® context_snapshot/mem0 é€£æºå¾Œã«ç½®ãæ›ãˆã‚‹ï¼ˆæœ¬ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯UIè¦ä»¶ã‚’æº€ãŸã™ãŸã‚ã®æœ€å°å®Ÿè£…ï¼‰
+        let problems = Set(appState.userProfile.problems)
+        var prioritized: [FeelingTopic] = []
+        if problems.contains("self_criticism") || problems.contains("rumination") { prioritized.append(.selfLoathing) }
+        if problems.contains("anxiety") { prioritized.append(.anxiety) }
+        // irritation ã¯ç¾çŠ¶ profile ã‹ã‚‰ã®ç¢ºå®šã‚­ãƒ¼ãŒç„¡ã„ã®ã§ã€æ®‹ã‚Šæ ã§è£œå®Œ
+
+        let merged = (prioritized + base).removingDuplicates()
+        return Array(merged.prefix(3)) + [.freeConversation]
+    }
+
+    var body: some View {
+        NavigationStack {
+            ScrollView {
+                VStack(spacing: AppTheme.Spacing.xl) {
+                    QuoteCard(quote: QuoteProvider.shared.todayQuote())
+
+                    VStack(spacing: AppTheme.Spacing.lg) {
+                        ForEach(topics, id: \\.self) { topic in
+                            NavigationLink(value: topic) {
+                                feelingCard(for: topic)
+                            }
+                            .buttonStyle(.plain)
+                        }
+                    }
+                }
+                .padding(.horizontal, AppTheme.Spacing.lg)
+                .padding(.top, AppTheme.Spacing.lg)
+                .padding(.bottom, AppTheme.Spacing.xxl)
+            }
+            .background(AppBackground())
+            .navigationTitle(String(localized: "talk_nav_title"))
+            .navigationBarTitleDisplayMode(.large)
+            .navigationDestination(for: FeelingTopic.self) { topic in
+                SessionView(topic: topic)
+                    .environmentObject(appState)
+            }
+        }
+    }
+
+    @ViewBuilder
+    private func feelingCard(for topic: FeelingTopic) -> some View {
+        switch topic {
+        case .selfLoathing:
+            FeelingCard(
+                emoji: "ğŸ˜”",
+                title: "talk_feeling_self_loathing_title",
+                subtitle: "talk_feeling_self_loathing_subtitle"
+            )
+        case .anxiety:
+            FeelingCard(
+                emoji: "ğŸ˜¨",
+                title: "talk_feeling_anxiety_title",
+                subtitle: "talk_feeling_anxiety_subtitle"
+            )
+        case .irritation:
+            FeelingCard(
+                emoji: "ğŸ˜¡",
+                title: "talk_feeling_irritation_title",
+                subtitle: "talk_feeling_irritation_subtitle"
+            )
+        case .freeConversation:
+            FeelingCard(
+                emoji: "ğŸ’¬",
+                title: "talk_feeling_something_else_title",
+                subtitle: "talk_feeling_something_else_subtitle"
+            )
+        }
+    }
+}
+
+private extension Array where Element: Hashable {
+    func removingDuplicates() -> [Element] {
+        var seen = Set<Element>()
+        return self.filter { seen.insert($0).inserted }
+    }
+}
+
*** End Patch
```

### 5.1 æ—¢å­˜ `SessionView.swift` ã¯ã€Œæ—§Talkç›¸å½“ã€ãªã®ã§é€€é¿ï¼ˆè¡çªå›é¿ï¼‰
> ç¾çŠ¶ `MainTabView` ãŒ `typealias TalkTabView = SessionView` ã§ `SessionView.swift` ã‚’Talkãƒ«ãƒ¼ãƒˆã«ã—ã¦ã„ã‚‹ã€‚  
> v3 ã§ã¯ Talk ãƒ«ãƒ¼ãƒˆã¯ `TalkView`ã€Sessionã¯ `Views/Session/SessionView` ã«åˆ†é›¢ã™ã‚‹ãŸã‚ã€æ—§ `SessionView` ã¯å‹åã‚’å¤‰æ›´ã—ã¦é€€é¿ã™ã‚‹ã€‚

```text
*** Begin Patch
*** Update File: aniccaios/aniccaios/SessionView.swift
@@
-struct SessionView: View {
+/// v0.2/ç¾è¡Œã®ã€ŒTalkã‚¿ãƒ–ç›¸å½“ã€ç”»é¢ï¼ˆãƒ•ã‚§ãƒ¼ã‚º5ä»¥é™ã¯ TalkView ã«ç½®ãæ›ãˆï¼‰
+struct LegacyTalkRootView: View {
@@
     @ViewBuilder
     var body: some View {
@@
     }
@@
 }
*** End Patch
```

```text
*** Begin Patch
*** Update File: aniccaios/aniccaios/MainTabView.swift
@@
 struct MainTabView: View {
@@
     var body: some View {
         TabView(selection: $appState.selectedRootTab) {
-            TalkTabView()
+            TalkView()
                 .tabItem {
                     Label(String(localized: "tab_talk"), systemImage: "message")
                 }
                 .tag(AppState.RootTab.talk)
@@
         .background(AppBackground())
     }
 }
 
-// SessionViewã‚’TalkTabViewã«ãƒªãƒãƒ¼ãƒ 
-typealias TalkTabView = SessionView
+// v3: Talk ã®ãƒ«ãƒ¼ãƒˆã¯ TalkViewï¼ˆSessionã¯ push é·ç§»ï¼‰
 
*** End Patch
```

### 5.2 QuoteCard é€£æºï¼ˆä¾å­˜: QuoteProviderï¼‰
> `QuoteProvider.shared.todayQuote()` ã¯ãƒ•ã‚§ãƒ¼ã‚º3.5ã§è¿½åŠ æ¸ˆã¿å‰æï¼ˆæœ¬ãƒ•ã‚§ãƒ¼ã‚ºã§ã¯ UI é€£æºã®ã¿ï¼‰ã€‚

---

### 5.3 SessionView / Orb / EMAï¼ˆæ–°è¦ï¼‰

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Session/OrbView.swift
+import SwiftUI
+import AVFoundation
+import Accelerate
+
+/// v3-ui å¿…é ˆ: é’ã„ã‚ªãƒ¼ãƒ–ï¼ˆbreath + ãƒã‚¤ã‚¯RMSé€£å‹•ï¼‰
+struct OrbView: View {
+    @StateObject private var meter = MicLevelMeter()
+    @State private var breathe = false
+
+    var body: some View {
+        let base = breathe ? 1.05 : 0.95
+        let mic = 0.9 + 0.2 * meter.smoothedLevel // 0.9â€“1.1
+        let scale = base * mic
+
+        Circle()
+            .fill(
+                RadialGradient(
+                    colors: [
+                        Color(red: 0.22, green: 0.50, blue: 0.95).opacity(0.95),
+                        Color(red: 0.10, green: 0.32, blue: 0.85).opacity(0.95)
+                    ],
+                    center: .center,
+                    startRadius: 10,
+                    endRadius: 160
+                )
+            )
+            .frame(width: 190, height: 190)
+            .scaleEffect(scale)
+            .animation(.easeInOut(duration: 2.8), value: breathe)          // breath
+            .animation(.easeOut(duration: 0.08), value: meter.smoothedLevel) // mic follow
+            .onAppear {
+                breathe = true
+                meter.start()
+            }
+            .onDisappear {
+                meter.stop()
+            }
+    }
+}
+
+/// AVAudioEngine ã§ RMS ã‚’æ¸¬ã£ã¦ 0â€“1 ã«æ­£è¦åŒ–ã—ã€å¹³æ»‘åŒ–ï¼ˆ0.7:0.3ï¼‰ã—ã¦å…¬é–‹ã™ã‚‹
+@MainActor
+final class MicLevelMeter: ObservableObject {
+    @Published private(set) var smoothedLevel: CGFloat = 0
+
+    private let engine = AVAudioEngine()
+    private var isRunning = false
+
+    func start() {
+        guard !isRunning else { return }
+        isRunning = true
+
+        let input = engine.inputNode
+        let format = input.outputFormat(forBus: 0)
+        input.removeTap(onBus: 0)
+
+        input.installTap(onBus: 0, bufferSize: 1024, format: format) { [weak self] buffer, _ in
+            guard let self else { return }
+            let normalized = self.normalizedRMS(from: buffer)
+            Task { @MainActor in
+                // v3-ui: å¹³æ»‘åŒ– 0.7:0.3ï¼ˆå¿…é ˆï¼‰
+                self.smoothedLevel = 0.7 * self.smoothedLevel + 0.3 * normalized
+            }
+        }
+
+        do {
+            try engine.start()
+        } catch {
+            // è¨ˆæ¸¬å¤±æ•—æ™‚ã‚‚UIã¯å£Šã•ãªã„ï¼ˆsmoothedLevel=0 ã®ã¾ã¾ï¼‰
+            isRunning = false
+        }
+    }
+
+    func stop() {
+        guard isRunning else { return }
+        engine.inputNode.removeTap(onBus: 0)
+        engine.stop()
+        isRunning = false
+        smoothedLevel = 0
+    }
+
+    private func normalizedRMS(from buffer: AVAudioPCMBuffer) -> CGFloat {
+        guard let channelData = buffer.floatChannelData?[0] else { return 0 }
+        let frameLength = Int(buffer.frameLength)
+        guard frameLength > 0 else { return 0 }
+
+        var rms: Float = 0
+        vDSP_rmsqv(channelData, 1, &rms, vDSP_Length(frameLength))
+
+        // 20*log10(rms) ã‚’ [-80,0] â†’ [0,1] ã«æ­£è¦åŒ–
+        let levelDb = 20 * log10f(max(rms, 0.000_001))
+        let minDb: Float = -80
+        let clamped = max(levelDb, minDb)
+        let normalized = (clamped - minDb) / -minDb
+        return CGFloat(min(max(normalized, 0), 1))
+    }
+}
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Session/EMAModal.swift
+import SwiftUI
+import UIKit
+
+/// tech-ema-v3 æº–æ‹ : ã€Œæ¥½ã«ãªã£ãŸï¼Ÿã€Yes/No/Skipï¼ˆdismissã¯Skipæ‰±ã„ï¼‰
+struct EMAModal: View {
+    let onAnswer: (Bool?) -> Void
+
+    var body: some View {
+        VStack(spacing: AppTheme.Spacing.xl) {
+            Text(String(localized: "ema_question"))
+                .font(.system(size: 20, weight: .semibold))
+                .multilineTextAlignment(.center)
+                .foregroundStyle(AppTheme.Colors.label)
+                .padding(.top, AppTheme.Spacing.lg)
+
+            HStack(spacing: AppTheme.Spacing.lg) {
+                PrimaryButton(
+                    title: String(localized: "ema_yes"),
+                    isEnabled: true,
+                    isLoading: false,
+                    style: .primary,
+                    action: { haptic(); onAnswer(true) }
+                )
+                PrimaryButton(
+                    title: String(localized: "ema_no"),
+                    isEnabled: true,
+                    isLoading: false,
+                    style: .unselected,
+                    action: { haptic(); onAnswer(false) }
+                )
+            }
+            .padding(.horizontal, AppTheme.Spacing.xl)
+
+            Button {
+                haptic()
+                onAnswer(nil)
+            } label: {
+                Text(String(localized: "ema_skip"))
+                    .font(AppTheme.Typography.caption1Dynamic)
+                    .foregroundStyle(AppTheme.Colors.secondaryLabel)
+            }
+            .padding(.top, AppTheme.Spacing.lg)
+
+            Spacer(minLength: 0)
+        }
+        .padding(.bottom, AppTheme.Spacing.xxl)
+        .presentationDetents([.medium])
+        .presentationDragIndicator(.visible)
+    }
+
+    private func haptic() {
+        UIImpactFeedbackGenerator(style: .light).impactOccurred()
+    }
+}
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Views/Session/SessionView.swift
+import SwiftUI
+import AVFoundation
+
+struct SessionView: View {
+    @EnvironmentObject private var appState: AppState
+    @Environment(\\.dismiss) private var dismiss
+    @ObservedObject private var controller = VoiceSessionController.shared
+
+    let topic: FeelingTopic
+
+    @State private var showMicAlert = false
+    @State private var isShowingEMA = false
+    @State private var pendingDismissAfterEMA = false
+
+    var body: some View {
+        VStack(spacing: AppTheme.Spacing.xl) {
+            topicPill
+
+            Spacer(minLength: AppTheme.Spacing.xl)
+
+            OrbView()
+
+            Text(statusText)
+                .font(AppTheme.Typography.bodyDynamic)
+                .foregroundStyle(AppTheme.Colors.secondaryLabel)
+
+            Spacer(minLength: AppTheme.Spacing.xl)
+
+            controlsRow
+        }
+        .padding(.horizontal, AppTheme.Spacing.lg)
+        .padding(.top, AppTheme.Spacing.lg)
+        .padding(.bottom, AppTheme.Spacing.xxl)
+        .background(AppBackground())
+        .navigationBarBackButtonHidden(true)
+        .toolbar {
+            ToolbarItem(placement: .navigationBarLeading) {
+                Button {
+                    endSessionAndMaybeAskEMA()
+                } label: {
+                    HStack(spacing: 6) {
+                        Image(systemName: "chevron.left")
+                        Text(String(localized: "common_back"))
+                    }
+                }
+            }
+        }
+        .onAppear {
+            ensureMicrophonePermissionAndStart()
+        }
+        .onDisappear {
+            // ç”»é¢ãŒé–‰ã˜ãŸã‚‰ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¯çµ‚äº†ã—ã¦ãŠãï¼ˆå¤šé‡æ¥ç¶šé˜²æ­¢ï¼‰
+            if controller.connectionStatus != .disconnected {
+                controller.stop()
+            }
+        }
+        .sheet(isPresented: $isShowingEMA) {
+            EMAModal { answer in
+                Task { @MainActor in
+                    await controller.submitFeelingEMA(emaBetter: answer)
+                    isShowingEMA = false
+                    dismiss()
+                }
+            }
+        }
+        .alert(String(localized: "session_mic_permission_title"), isPresented: $showMicAlert) {
+            Button(String(localized: "common_open_settings")) {
+                if let url = URL(string: UIApplication.openSettingsURLString) {
+                    UIApplication.shared.open(url)
+                }
+            }
+            Button(String(localized: "common_cancel"), role: .cancel) {}
+        } message: {
+            Text(String(localized: "session_mic_permission_message"))
+        }
+    }
+
+    private var topicPill: some View {
+        Text(topicLabel)
+            .font(AppTheme.Typography.caption1Dynamic)
+            .foregroundStyle(AppTheme.Colors.secondaryLabel)
+            .padding(.horizontal, AppTheme.Spacing.lg)
+            .padding(.vertical, AppTheme.Spacing.sm)
+            .background(
+                RoundedRectangle(cornerRadius: AppTheme.Radius.xl, style: .continuous)
+                    .fill(AppTheme.Colors.buttonUnselected)
+            )
+    }
+
+    private var topicLabel: String {
+        switch topic {
+        case .selfLoathing: return String(localized: "session_topic_self_loathing")
+        case .anxiety: return String(localized: "session_topic_anxiety")
+        case .irritation: return String(localized: "session_topic_irritation")
+        case .freeConversation: return String(localized: "session_topic_free_conversation")
+        }
+    }
+
+    private var statusText: String {
+        if controller.connectionStatus == .connecting { return String(localized: "session_status_connecting") }
+        if controller.isModelSpeaking { return String(localized: "session_status_speaking") }
+        if controller.connectionStatus == .connected { return String(localized: "session_status_listening") }
+        return String(localized: "session_status_disconnected")
+    }
+
+    private var controlsRow: some View {
+        HStack {
+            Button {
+                controller.toggleMicMuted()
+            } label: {
+                Image(systemName: controller.isMicMuted ? "mic.slash.fill" : "mic.fill")
+                    .font(.system(size: 18, weight: .semibold))
+                    .foregroundStyle(AppTheme.Colors.label)
+                    .frame(width: 56, height: 56)
+                    .background(Circle().fill(AppTheme.Colors.cardBackground))
+                    .overlay(Circle().stroke(AppTheme.Colors.borderLight, lineWidth: 1))
+            }
+
+            Spacer()
+
+            Button {
+                endSessionAndMaybeAskEMA()
+            } label: {
+                Image(systemName: "xmark")
+                    .font(.system(size: 18, weight: .semibold))
+                    .foregroundStyle(Color.white)
+                    .frame(width: 56, height: 56)
+                    .background(Circle().fill(Color.red))
+            }
+        }
+        .padding(.horizontal, AppTheme.Spacing.lg)
+    }
+
+    private func endSessionAndMaybeAskEMA() {
+        let shouldAsk = controller.shouldAskFeelingEMA
+        controller.stop()
+        if shouldAsk {
+            isShowingEMA = true
+        } else {
+            Task { @MainActor in
+                await controller.submitFeelingEMA(emaBetter: nil)
+                dismiss()
+            }
+        }
+    }
+
+    private func ensureMicrophonePermissionAndStart() {
+        if #available(iOS 17.0, *) {
+            switch AVAudioApplication.shared.recordPermission {
+            case .granted:
+                controller.startFeeling(topic: topic)
+            case .undetermined:
+                AVAudioApplication.requestRecordPermission { granted in
+                    DispatchQueue.main.async {
+                        granted ? controller.startFeeling(topic: topic) : (showMicAlert = true)
+                    }
+                }
+            default:
+                showMicAlert = true
+            }
+        } else {
+            switch AVAudioSession.sharedInstance().recordPermission {
+            case .granted:
+                controller.startFeeling(topic: topic)
+            case .undetermined:
+                AVAudioSession.sharedInstance().requestRecordPermission { granted in
+                    DispatchQueue.main.async {
+                        granted ? controller.startFeeling(topic: topic) : (showMicAlert = true)
+                    }
+                }
+            default:
+                showMicAlert = true
+            }
+        }
+    }
+}
+
*** End Patch
```

> `common_back` ã¯æ—¢å­˜ã‚­ãƒ¼ãŒç„¡ã„ãŸã‚ã€Localizable ã«è¿½åŠ ã™ã‚‹ï¼ˆä¸‹è¨˜ï¼‰ã€‚

### 5.3 æ–‡è¨€è¿½åŠ ï¼ˆTalk/Session/EMAï¼‰

```text
*** Begin Patch
*** Update File: aniccaios/aniccaios/Resources/en.lproj/Localizable.strings
@@
 "common_cancel" = "Cancel";
+"common_back" = "Back";
@@
 "tab_talk" = "Talk";
@@
+"talk_nav_title" = "How are you feeling now?";
+"talk_feeling_self_loathing_title" = "Self-Loathing";
+"talk_feeling_self_loathing_subtitle" = "When youâ€™re being hard on yourself.";
+"talk_feeling_anxiety_title" = "Anxiety & Worry";
+"talk_feeling_anxiety_subtitle" = "When your mind wonâ€™t stop spinning.";
+"talk_feeling_irritation_title" = "Irritation";
+"talk_feeling_irritation_subtitle" = "When tension is rising in you.";
+"talk_feeling_something_else_title" = "Something else";
+"talk_feeling_something_else_subtitle" = "Start a free conversation.";
+
+"session_topic_self_loathing" = "Talking about self-loathing";
+"session_topic_anxiety" = "Talking about anxiety";
+"session_topic_irritation" = "Talking about irritation";
+"session_topic_free_conversation" = "Talking about something else";
+
+"session_status_connecting" = "Connectingâ€¦";
+"session_status_listening" = "Anicca is listeningâ€¦";
+"session_status_speaking" = "Anicca is speakingâ€¦";
+"session_status_disconnected" = "Session ended";
+
+"ema_question" = "Did you feel a bit better?";
+"ema_yes" = "Yes";
+"ema_no" = "No";
+"ema_skip" = "Skip";
*** End Patch
```

```text
*** Begin Patch
*** Update File: aniccaios/aniccaios/Resources/ja.lproj/Localizable.strings
@@
 "common_cancel" = "ã‚­ãƒ£ãƒ³ã‚»ãƒ«";
+"common_back" = "æˆ»ã‚‹";
@@
 "tab_talk" = "ä¼šè©±";
@@
+"talk_nav_title" = "ä»Šã©ã‚“ãªæ„Ÿã˜ï¼Ÿ";
+"talk_feeling_self_loathing_title" = "è‡ªå·±å«Œæ‚ª";
+"talk_feeling_self_loathing_subtitle" = "è‡ªåˆ†ã‚’è²¬ã‚ã™ãã¦ã„ã‚‹ã¨ãã€‚";
+"talk_feeling_anxiety_title" = "ä¸å®‰";
+"talk_feeling_anxiety_subtitle" = "é ­ãŒæ­¢ã¾ã‚‰ãªã„ã¨ãã€‚";
+"talk_feeling_irritation_title" = "è‹›ç«‹ã¡";
+"talk_feeling_irritation_subtitle" = "ç·Šå¼µãŒé«˜ã¾ã£ã¦ã„ã‚‹ã¨ãã€‚";
+"talk_feeling_something_else_title" = "ãã®ä»–";
+"talk_feeling_something_else_subtitle" = "è‡ªç”±ã«è©±ã™ã€‚";
+
+"session_topic_self_loathing" = "è‡ªå·±å«Œæ‚ªã«ã¤ã„ã¦";
+"session_topic_anxiety" = "ä¸å®‰ã«ã¤ã„ã¦";
+"session_topic_irritation" = "è‹›ç«‹ã¡ã«ã¤ã„ã¦";
+"session_topic_free_conversation" = "è‡ªç”±ã«è©±ã™";
+
+"session_status_connecting" = "æ¥ç¶šä¸­â€¦";
+"session_status_listening" = "AniccaãŒèã„ã¦ã„ã¾ã™â€¦";
+"session_status_speaking" = "AniccaãŒè©±ã—ã¦ã„ã¾ã™â€¦";
+"session_status_disconnected" = "ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¾ã—ãŸ";
+
+"ema_question" = "ã•ã£ãã‚ˆã‚Šæ¥½ã«ãªã£ãŸï¼Ÿ";
+"ema_yes" = "ã¯ã„";
+"ema_no" = "ã„ã„ãˆ";
+"ema_skip" = "ã‚¹ã‚­ãƒƒãƒ—";
*** End Patch
```

---

### 5.4 VoiceSessionController æ‹¡å¼µï¼ˆå…¬å¼ Realtime ã‚¤ãƒ™ãƒ³ãƒˆ/å½¢å¼ã¸ï¼‰
> æ ¹æ‹ : `session.update` ã¯ Realtime API reference ã® `audio.input/output` æ§‹é€ ã¸ï¼ˆ`https://platform.openai.com/docs/api-reference/realtime-client-events/session/update`ï¼‰ã€‚  
> speaking/listening ã®åˆ¤å®šã¯ `output_audio_buffer.started/stopped` ã¨ `input_audio_buffer.speech_started/stopped`ï¼ˆ`https://platform.openai.com/docs/api-reference/realtime-server-events`ï¼‰ã€‚

```text
*** Begin Patch
*** Update File: aniccaios/aniccaios/VoiceSessionController.swift
@@
 final class VoiceSessionController: NSObject, ObservableObject {
@@
     @Published private(set) var connectionStatus: ConnectionState = .disconnected
+    @Published private(set) var isModelSpeaking: Bool = false
+    @Published private(set) var isUserSpeaking: Bool = false
+    @Published private(set) var isMicMuted: Bool = false
+
+    /// tech-ema-v3: 5ç§’ä»¥ä¸Šã®ã¿ EMA ã‚’èã
+    var shouldAskFeelingEMA: Bool {
+        guard let start = sessionStartTime else { return false }
+        return Date().timeIntervalSince(start) >= 5
+    }
+
+    // Feeling ã‚»ãƒƒã‚·ãƒ§ãƒ³è­˜åˆ¥ï¼ˆ/api/mobile/feeling/end ã§ä½¿ç”¨ï¼‰
+    private var activeFeelingSessionId: String?
+    private var activeFeelingTopic: FeelingTopic?
@@
     func start(shouldResumeImmediately: Bool = false) {
@@
     }
+
+    /// v3: Talk/Feeling ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ï¼ˆTalkViewâ†’SessionView ã‹ã‚‰å‘¼ã¶ï¼‰
+    func startFeeling(topic: FeelingTopic) {
+        guard connectionStatus != .connecting else { return }
+        setStatus(.connecting)
+        activeFeelingTopic = topic
+        currentHabitType = nil
+        stickyActive = AppState.shared.userProfile.stickyModeEnabled
+        stickyUserReplyCount = 0
+        stickyReady = false
+        Task { [weak self] in
+            await self?.establishSession(resumeImmediately: false)
+        }
+    }
@@
     func stop() {
@@
         sessionStartTime = nil
@@
         cachedSecret = nil
         setStatus(.disconnected)
         deactivateAudioSession()
         // stop()æ™‚ã«ã¯markQuotaHoldã‚’å‘¼ã°ãªã„ï¼ˆã‚¨ãƒ³ãƒ‰ã‚»ãƒƒã‚·ãƒ§ãƒ³æŠ¼ä¸‹æ™‚ã®èª¤è¡¨ç¤ºã‚’é˜²ãï¼‰
     }
+
+    /// tech-ema-v3: Feeling ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã® EMA ã‚’ã‚µãƒ¼ãƒã¸é€ä¿¡ï¼ˆtrue/false/nullï¼‰
+    @MainActor
+    func submitFeelingEMA(emaBetter: Bool?) async {
+        guard let feelingSessionId = activeFeelingSessionId,
+              case .signedIn(let credentials) = AppState.shared.authStatus else {
+            // ã¾ã  start ãŒèµ°ã£ã¦ã„ãªã„ or æœªãƒ­ã‚°ã‚¤ãƒ³ãªã‚‰ä½•ã‚‚ã—ãªã„
+            activeFeelingTopic = nil
+            activeFeelingSessionId = nil
+            return
+        }
+        var request = URLRequest(url: AppConfig.proxyBaseURL.appendingPathComponent("mobile/feeling/end"))
+        request.httpMethod = "POST"
+        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
+        request.setValue(AppState.shared.resolveDeviceId(), forHTTPHeaderField: "device-id")
+        request.setValue(credentials.userId, forHTTPHeaderField: "user-id")
+
+        let payload: [String: Any] = [
+            "session_id": feelingSessionId,
+            "emaBetter": emaBetter as Any
+        ]
+        request.httpBody = try? JSONSerialization.data(withJSONObject: payload, options: [])
+
+        do {
+            _ = try await NetworkSessionManager.shared.session.data(for: request)
+        } catch {
+            logger.error("Failed to submit EMA: \(error.localizedDescription, privacy: .public)")
+        }
+        activeFeelingTopic = nil
+        activeFeelingSessionId = nil
+    }
@@
     func sendSessionUpdate() {
@@
-        var sessionPayload: [String: Any] = [
-            "modalities": ["text", "audio"],
-            "voice": "alloy",
-            "input_audio_format": "pcm16",
-            "output_audio_format": "pcm16",
-            "input_audio_noise_reduction": [
-                "type": "near_field"
-            ],
-            "max_response_output_tokens": "inf"
-        ]
+        // OpenAI Realtime å…¬å¼: session.update ã¯ audio.{input,output} / output_modalities å½¢å¼
+        // refs:
+        // - https://platform.openai.com/docs/api-reference/realtime-client-events/session/update
+        // - https://platform.openai.com/docs/guides/realtime-conversations
+        var sessionPayload: [String: Any] = [
+            "type": "realtime",
+            "output_modalities": ["audio", "text"],
+            "max_output_tokens": "inf",
+            "audio": [
+                "input": [
+                    "format": [
+                        "type": "audio/pcm",
+                        "rate": 24000
+                    ]
+                ],
+                "output": [
+                    "format": [
+                        "type": "audio/pcm",
+                        "rate": 24000
+                    ],
+                    "voice": "alloy",
+                    "speed": 1.0
+                ]
+            ],
+            "tool_choice": "auto",
+            "tools": RealtimeTools.defaultTools
+        ]
@@
-        // ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã¯ turn_detection ã‚’ null ã«è¨­å®šã—ã¦ãƒã‚¤ã‚¯å…¥åŠ›ã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–
-        if isTrainingMode {
-            // ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚: ãƒã‚¤ã‚¯å…¥åŠ›ã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–ï¼ˆä¸€æ–¹å‘ãƒ¢ãƒ¼ãƒ‰ï¼‰
-            sessionPayload["turn_detection"] = NSNull()
-            logger.info("Training mode: turn_detection disabled for one-way audio")
-        } else {
-            // ãã®ä»–ã®ç¿’æ…£: åŒæ–¹å‘å¯¾è©±ã‚’ç¶­æŒ
-            sessionPayload["turn_detection"] = [
-                "type": "semantic_vad",
-                "eagerness": "low",
-                "interrupt_response": true,
-                "create_response": true
-            ]
-        }
+        // Realtime: audio.input.turn_detection
+        if isTrainingMode {
+            // ä¸€æ–¹å‘ï¼ˆå…¥åŠ›ãªã—ï¼‰
+            (sessionPayload["audio"] as? [String: Any])?["input"] = [
+                "format": ["type": "audio/pcm", "rate": 24000],
+                "turn_detection": NSNull()
+            ]
+            logger.info("Training mode: turn_detection disabled for one-way audio")
+        } else {
+            (sessionPayload["audio"] as? [String: Any])?["input"] = [
+                "format": ["type": "audio/pcm", "rate": 24000],
+                "turn_detection": [
+                    "type": "server_vad",
+                    "create_response": true,
+                    "interrupt_response": true
+                ]
+            ]
+        }
@@
-        var shouldTriggerHabitResponse = false
-        var instructions: String?
-        if let prompt = AppState.shared.consumePendingPrompt() {
-            instructions = prompt
-            shouldTriggerHabitResponse = true   // habit ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€ä¿¡ã‚’è¨˜éŒ²
-        } else if let consultPrompt = AppState.shared.consumePendingConsultPrompt() {
-            instructions = consultPrompt
-        }
+        var shouldTriggerImmediateResponse = false
+        var instructions: String?
+        if let prompt = AppState.shared.consumePendingPrompt() {
+            instructions = prompt
+            shouldTriggerImmediateResponse = true   // habit: èµ·å‹•æ™‚ã«è©±ã—å§‹ã‚ã‚‹
+        } else if let consultPrompt = AppState.shared.consumePendingConsultPrompt() {
+            instructions = consultPrompt
+            shouldTriggerImmediateResponse = true   // consult: v3 ã§ã¯ã€Œãƒ¢ãƒ‡ãƒ«ãŒå…ˆã«è©±ã™ã€å‰æ
+        } else if let feeling = activeFeelingTopic {
+            instructions = RealtimePromptBuilder.buildFeelingInstructions(topic: feeling, profile: AppState.shared.userProfile)
+            shouldTriggerImmediateResponse = true
+        }
@@
         if let instructions {
             sessionPayload["instructions"] = instructions
         }
@@
         if shouldTriggerHabitResponse {
-            sendWakeResponseCreate()
+            sendWakeResponseCreate()
             Task { @MainActor in
                 AppState.shared.clearPendingHabitTrigger()
             }
         }
     }
@@
     private func handleRealtimeEvent(_ event: [String: Any]) {
         guard let type = event["type"] as? String else { return }
         switch type {
-        case "output_audio_buffer.started":
+        case "output_audio_buffer.started":
             logger.info("output_audio_buffer.started: stickyActive=\(self.stickyActive), stickyReady=\(self.stickyReady)")
             print("output_audio_buffer.started: stickyActive=\(stickyActive), stickyReady=\(stickyReady)")
+            isModelSpeaking = true
             if stickyActive && !stickyReady {
                 stickyReady = true
                 logger.info("Sticky ready: first audio started â†’ stickyReady=true")
                 print("Sticky ready: first audio started â†’ stickyReady=true")
             }
+
+        case "output_audio_buffer.stopped", "output_audio_buffer.cleared":
+            isModelSpeaking = false
         
+        case "input_audio_buffer.speech_started":
+            isUserSpeaking = true
+
         case "input_audio_buffer.speech_stopped":
             // â˜…â˜…â˜… ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±çµ‚äº†ã‚’æ¤œçŸ¥ï¼ˆWebRTCã§ã®æ­£ã—ã„ã‚¤ãƒ™ãƒ³ãƒˆï¼‰â˜…â˜…â˜…
             logger.info("input_audio_buffer.speech_stopped: stickyActive=\(self.stickyActive), stickyReady=\(self.stickyReady)")
             print("input_audio_buffer.speech_stopped: stickyActive=\(stickyActive), stickyReady=\(stickyReady)")
+            isUserSpeaking = false
             guard stickyActive && stickyReady else { return }
@@
         case "response.done":
+            // Function calling: response.done å†…ã® function_call item ã‚’æ¤œå‡ºã—ã€HTTP tool ã«è»¢é€ã—ã¦æˆ»ã™
+            // refs:
+            // - https://platform.openai.com/docs/guides/realtime-conversations#function-calling
+            // - https://platform.openai.com/docs/api-reference/realtime-server-events
+            if let response = event["response"] as? [String: Any],
+               let output = response["output"] as? [[String: Any]] {
+                Task { @MainActor in
+                    await self.handleFunctionCallsIfNeeded(outputItems: output)
+                }
+            }
             if stickyActive {
                 logger.info("Sticky \(self.stickyUserReplyCount)/\(self.stickyReleaseThreshold): response.done â†’ scheduling next in 5s")
                 print("Sticky \(self.stickyUserReplyCount)/\(self.stickyReleaseThreshold): response.done â†’ scheduling next in 5s")
                 Task { @MainActor in
                     try? await Task.sleep(nanoseconds: 5_000_000_000)
                     guard self.stickyActive else {
                         self.logger.info("Sticky: cancelled during 5s delay (stickyActive=false)")
                         return
                     }
                     self.sendWakeResponseCreate()
                 }
             }
         
         default:
             break
         }
     }
+
+    @MainActor
+    private func handleFunctionCallsIfNeeded(outputItems: [[String: Any]]) async {
+        let functionCalls = outputItems.filter { ($0["type"] as? String) == "function_call" }
+        guard !functionCalls.isEmpty else { return }
+
+        for call in functionCalls {
+            guard let name = call["name"] as? String,
+                  let callId = call["call_id"] as? String,
+                  let arguments = call["arguments"] as? String else { continue }
+            let result = await RealtimeToolRouter.callTool(name: name, argumentsJSON: arguments)
+            sendFunctionCallOutput(callId: callId, output: result)
+        }
+        // ãƒ„ãƒ¼ãƒ«å‡ºåŠ›ã‚’è¶³ã—ãŸå¾Œã€ãƒ¢ãƒ‡ãƒ«ã«ç¶šãã®å¿œç­”ã‚’ä½œã‚‰ã›ã‚‹
+        sendResponseCreate()
+    }
+
+    private func sendFunctionCallOutput(callId: String, output: String) {
+        let payload: [String: Any] = [
+            "type": "conversation.item.create",
+            "item": [
+                "type": "function_call_output",
+                "call_id": callId,
+                "output": output
+            ]
+        ]
+        sendEvent(payload)
+    }
+
+    private func sendResponseCreate() {
+        sendEvent(["type": "response.create"])
+    }
+
+    private func sendEvent(_ payload: [String: Any]) {
+        guard let channel = dataChannel, channel.readyState == .open else { return }
+        do {
+            let data = try JSONSerialization.data(withJSONObject: payload, options: [.fragmentsAllowed])
+            channel.sendData(RTCDataBuffer(data: data, isBinary: false))
+        } catch {
+            logger.error("Failed to send event \(payload["type"] as? String ?? "unknown"): \(error.localizedDescription, privacy: .public)")
+        }
+    }
 }
+
+/// Realtime toolsï¼ˆv3-stack: /tools/*ï¼‰ã®å®šç¾©ã‚’ Swift å´ã«å›ºå®šï¼ˆPrompts/Tools ã¨åŒä¸€ï¼‰
+private enum RealtimeTools {
+    static var defaultTools: [[String: Any]] {
+        // Realtime API ã® tools å½¢ï¼ˆname/description/parameters ãŒãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ï¼‰
+        // refs: https://platform.openai.com/docs/guides/realtime-conversations#configure-callable-functions
+        [
+            [
+                "type": "function",
+                "name": "get_context_snapshot",
+                "description": "Get the user's current context including recent behavior, feelings, and patterns",
+                "parameters": [
+                    "type": "object",
+                    "strict": true,
+                    "additionalProperties": false,
+                    "properties": [
+                        "userId": ["type": "string"],
+                        "includeDailyMetrics": ["type": "boolean"]
+                    ],
+                    "required": ["userId"]
+                ]
+            ],
+            [
+                "type": "function",
+                "name": "choose_nudge",
+                "description": "Choose the best nudge template for a target behavior",
+                "parameters": [
+                    "type": "object",
+                    "strict": true,
+                    "additionalProperties": false,
+                    "properties": [
+                        "userId": ["type": "string"],
+                        "targetBehavior": ["type": "string"]
+                    ],
+                    "required": ["userId", "targetBehavior"]
+                ]
+            ],
+            [
+                "type": "function",
+                "name": "log_nudge",
+                "description": "Log a nudge that was delivered and its metadata",
+                "parameters": [
+                    "type": "object",
+                    "strict": true,
+                    "additionalProperties": false,
+                    "properties": [
+                        "userId": ["type": "string"],
+                        "templateId": ["type": "string"],
+                        "channel": ["type": "string"]
+                    ],
+                    "required": ["userId", "templateId", "channel"]
+                ]
+            ],
+            [
+                "type": "function",
+                "name": "get_behavior_summary",
+                "description": "Get today's behavior summary for the Behavior tab",
+                "parameters": [
+                    "type": "object",
+                    "strict": true,
+                    "additionalProperties": false,
+                    "properties": [
+                        "userId": ["type": "string"]
+                    ],
+                    "required": ["userId"]
+                ]
+            ]
+        ]
+    }
+}
+
+/// tools å‘¼ã³å‡ºã—ã‚’ iOSâ†’Backend ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã—ã¦ JSON æ–‡å­—åˆ—ã§è¿”ã™
+private enum RealtimeToolRouter {
+    @MainActor
+    static func callTool(name: String, argumentsJSON: String) async -> String {
+        guard case .signedIn(let credentials) = AppState.shared.authStatus else {
+            return "{\"error\":{\"code\":\"UNAUTHORIZED\",\"message\":\"Not signed in\"}}"
+        }
+        var request = URLRequest(url: AppConfig.proxyBaseURL.appendingPathComponent("tools/\\(name)"))
+        request.httpMethod = "POST"
+        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
+        request.setValue(AppState.shared.resolveDeviceId(), forHTTPHeaderField: "device-id")
+        request.setValue(credentials.userId, forHTTPHeaderField: "user-id")
+        request.httpBody = argumentsJSON.data(using: .utf8)
+
+        do {
+            let (data, _) = try await NetworkSessionManager.shared.session.data(for: request)
+            return String(data: data, encoding: .utf8) ?? "{}"
+        } catch {
+            return "{\"error\":{\"code\":\"NETWORK_ERROR\",\"message\":\"\\(error.localizedDescription)\"}}"
+        }
+    }
+}
+
+/// Talk/Feeling ç”¨ã® Realtime instructions ã‚’ Resources/Prompts ã‹ã‚‰æ§‹ç¯‰
+private enum RealtimePromptBuilder {
+    static func buildFeelingInstructions(topic: FeelingTopic, profile: UserProfile) -> String {
+        // common.txt ã¯ HabitPromptBuilder ã¨åŒã˜è¨€èªãƒ­ãƒƒã‚¯ã‚’æµç”¨ï¼ˆLANGUAGE_LINE ã‚’åŸ‹ã‚ã‚‹ï¼‰
+        let common = (load(name: "common", ext: "txt") ?? "").trimmingCharacters(in: .whitespacesAndNewlines)
+        let talkSystem = (load(name: "talk_session", ext: "txt") ?? "").trimmingCharacters(in: .whitespacesAndNewlines)
+        let openerName: String = {
+            switch topic {
+            case .selfLoathing: return "feeling_self_loathing"
+            case .anxiety: return "feeling_anxiety"
+            case .irritation: return "feeling_irritation"
+            case .freeConversation: return "feeling_free_conversation"
+            }
+        }()
+        let opener = (load(name: openerName, ext: "txt") ?? "").trimmingCharacters(in: .whitespacesAndNewlines)
+        // æ—¢å­˜ã®ç½®æ›ãƒ­ã‚¸ãƒƒã‚¯ã‚’æœ€å°é™ã§è¤‡è£½ï¼ˆLANGUAGE_LINE/USER_NAME ç­‰ï¼‰
+        let rendered = HabitPromptBuilder().buildPrompt(for: .custom, scheduledTime: nil, now: Date(), profile: profile)
+        return [common, talkSystem, opener, "\\n\\n[Profile]\\n\\(rendered)"].joined(separator: "\\n\\n")
+    }
+
+    private static func load(name: String, ext: String) -> String? {
+        guard let url = Bundle.main.url(forResource: name, withExtension: ext) else { return nil }
+        return try? String(contentsOf: url, encoding: .utf8)
+    }
+}
*** End Patch
```

### 5.4 è£œè¶³ï¼ˆVoiceSessionController ã®è¨­è¨ˆåˆ¤æ–­ï¼‰
- `session.update` ã® payload ã¯ **å…¬å¼ã® `audio.input/output` æ§‹é€ ã¸çµ±ä¸€**ï¼ˆç¾çŠ¶ã‚³ãƒ¼ãƒ‰ã® `modalities/input_audio_format/...` ã¯æ—§å½¢å¼ï¼‰
- speaking/listening ã® UI ã¯ Realtime server event ã§åˆ¤å®š:
  - `output_audio_buffer.started` â†’ speaking
  - `output_audio_buffer.stopped|cleared` â†’ listening
  - `input_audio_buffer.speech_started|stopped` â†’ ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ä¸­UIãªã©ã«æ‹¡å¼µå¯èƒ½
- ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã¯ `response.done` ã® `output[]` ã« `function_call` ãŒå…¥ã‚‹å…¬å¼ãƒ•ãƒ­ãƒ¼ã«åˆã‚ã›ã‚‹ï¼ˆRealtime conversations ã® function calling ç¯€ï¼‰

---

### 5.5 Prompts / Tools æ›´æ–°ï¼ˆResources/Promptsï¼‰
> `prompts-v3.md` ã® tools å®šç¾©ï¼ˆChat Completions é¢¨ã® `function:{...}` ãƒã‚¹ãƒˆï¼‰ã¯ **Realtime ã§ã¯å½¢ãŒç•°ãªã‚‹**ãŸã‚ã€iOS å®Ÿè£…å´ï¼ˆæœ¬ãƒ‘ãƒƒãƒï¼‰ã§ã¯ Realtimeå…¬å¼ã® `tools: [{type,name,description,parameters}]` å½¢å¼ã‚’æ¡ç”¨ã™ã‚‹ã€‚  
> æ ¹æ‹ : `https://platform.openai.com/docs/guides/realtime-conversations#configure-callable-functions`

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Resources/Prompts/talk_session.txt
+ã‚ãªãŸã¯ Aniccaã€‚éŸ³å£°ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è‹¦ã—ã¿ã‚’å’Œã‚‰ã’ã€è¡Œå‹•ã¨å¿ƒã‚’æ•´ãˆã‚‹å°å¸«ã€‚
+
+Core Principles
+- Warm and compassionate, never judgmental.
+- Feeling ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚ˆã‚Šå…ˆã«çŸ­ã„ opener ã‚’è©±ã—å§‹ã‚ã‚‹ã€‚
+- Realtime ã§ã¯ 1â€“2 æ–‡ã§çŸ­ãã€‚é•·ã„ç‹¬ç™½ã¯ç¦æ­¢ã€‚
+- è‹¦ã—ã¿ã‚’èªã‚ã¦ã‹ã‚‰ã€æ¬¡ã®ä¸€æ­©ã‚’é™ã‹ã«æŒ‡ã—ç¤ºã™ï¼ˆå‘½ä»¤ã§ã¯ãªãç¤ºã™ï¼‰ã€‚
+
+Prohibited
+- è¨ºæ–­/åŒ»ç™‚åŠ©è¨€/æ³•çš„åŠ©è¨€
+- æ¥è¾±åŒ–/æ–­ç½ª/èª¬æ•™èª¿
+
+Operational
+- æ–‡è„ˆãŒä¸è¶³ã—ã¦ã„ã‚‹æ™‚ã¯ tools ã‚’ä½¿ã£ã¦ç¢ºèªã™ã‚‹ï¼ˆæ¨æ¸¬ã§æ–­å®šã—ãªã„ï¼‰ã€‚
+- ${LANGUAGE_LINE} ä»¥å¤–ã§è©±ã•ãªã„ï¼ˆcommon.txt ã® LANGUAGE LOCK ã«å¾“ã†ï¼‰ã€‚
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Resources/Prompts/feeling_self_loathing.txt
+[Feeling: self_loathing]
+çŸ­ã„ opener ã‚’ 2â€“3 æ–‡ã§ã€‚ç—›ã¿ã®æ‰¿èªâ†’äº‹å®Ÿã¨è§£é‡ˆã®åˆ†é›¢â†’å„ªã—ã•ã®è¶³å ´ã€‚
+è³ªå•æ”»ã‚ã«ã—ãªã„ã€‚
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Resources/Prompts/feeling_anxiety.txt
+[Feeling: anxiety]
+çŸ­ã„ opener ã‚’ 2â€“3 æ–‡ã§ã€‚èº«ä½“/ç¾åœ¨ã¸ã®ã‚°ãƒ©ã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°â†’å—å®¹â†’æœ€å°ã®ä¸€æ­©ã€‚
+è³ªå•æ”»ã‚ã«ã—ãªã„ã€‚
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Resources/Prompts/feeling_irritation.txt
+[Feeling: irritation]
+çŸ­ã„ opener ã‚’ 2â€“3 æ–‡ã§ã€‚åå¿œã®å‰ã« 1 å‘¼å¸â†’è©•ä¾¡èªã‚’é¿ã‘ã‚‹â†’ä¾¡å€¤ã«æ²¿ã†ä¸€æ­©ã€‚
+è³ªå•æ”»ã‚ã«ã—ãªã„ã€‚
+
*** End Patch
```

```text
*** Begin Patch
*** Add File: aniccaios/aniccaios/Resources/Prompts/feeling_free_conversation.txt
+[Feeling: free_conversation]
+çŸ­ã„ opener ã‚’ 2â€“3 æ–‡ã§ã€‚å®‰å…¨ã®å®£è¨€â†’ä¸»å°æ¨©ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼â†’æ²ˆé»™ã‚‚è¨±å®¹ã€‚
+å¿…è¦ãªã‚‰ tool ã§ context ã‚’å–ã£ã¦ã‹ã‚‰è©±ã—å§‹ã‚ã‚‹ã€‚
+
*** End Patch
```

---

## èª²é¡Œå¯¾å¿œï¼ˆè©²å½“ã™ã‚‹å ´åˆï¼‰
- **prompts-v3.md ã® tool schema å½¢å¼å·®**:
  - æœ¬ãƒ‘ãƒƒãƒã¯ **Realtime API ã® tools å½¢å¼**ï¼ˆ`type/name/description/parameters`ï¼‰ã«åˆã‚ã›ã‚‹ï¼ˆå…¬å¼æ ¹æ‹ URLä¸Šè¨˜ï¼‰
  - `prompts-v3.md` è‡ªä½“ã®æ›´æ–°ã¯ãƒ•ã‚§ãƒ¼ã‚º5ã®å¯¾è±¡å¤–ã ãŒã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¨å®Ÿè£…ã®é½Ÿé½¬ãŒæ®‹ã‚‹ãŸã‚ v0.3 æœŸé–“ä¸­ã«è¿½éšä¿®æ­£æ¨å¥¨

## æ³¨æ„ç‚¹ãƒ»æ”¹å–„ææ¡ˆ
- `OrbView` ã® AVAudioEngine tap ãŒ WebRTC éŸ³å£°å…¥åŠ›ã¨ç«¶åˆã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€å®Ÿè£…å¾Œã¯å®Ÿæ©Ÿã§ã€ŒWebRTCéŸ³å£°ãŒé€”åˆ‡ã‚Œãªã„ã€ã“ã¨ã‚’æœ€å„ªå…ˆã§ç¢ºèªã™ã‚‹ï¼ˆç«¶åˆã™ã‚‹å ´åˆã¯è¨ˆæ¸¬çµŒè·¯ã‚’ `AVAudioRecorder` ãƒ¡ãƒ¼ã‚¿ãƒªãƒ³ã‚°ã¸åˆ‡ã‚Šæ›¿ãˆã‚‹ãŒã€ä»•æ§˜å¤‰æ›´ãŒå¿…è¦ãªã®ã§åˆ¥é€”æ ¹æ‹ æç¤ºï¼‰ã€‚









