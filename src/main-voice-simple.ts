import { app, Tray, Menu, nativeImage, BrowserWindow } from 'electron';
import * as path from 'path';
import * as dotenv from 'dotenv';
import { VoiceServerService } from './services/voiceServer';

// ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
dotenv.config();

// ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
let tray: Tray | null = null;
let hiddenWindow: BrowserWindow | null = null;
let voiceServer: VoiceServerService | null = null;
let isListening = false;

// ã‚¢ãƒ—ãƒªã®åˆæœŸåŒ–
async function initializeApp() {
  console.log('ğŸ© Anicca Voice Assistant Starting...');
  
  try {
    // ãƒã‚¤ã‚¯æ¨©é™ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    const { systemPreferences } = require('electron');
    
    if (process.platform === 'darwin') {
      const microphoneAccess = systemPreferences.getMediaAccessStatus('microphone');
      console.log('ğŸ¤ Microphone access status:', microphoneAccess);
      
      if (microphoneAccess === 'not-determined' || microphoneAccess === 'denied') {
        const granted = await systemPreferences.askForMediaAccess('microphone');
        console.log('ğŸ¤ Microphone permission:', granted ? 'âœ… Granted' : 'âŒ Denied');
        
        if (!granted) {
          throw new Error('Microphone permission is required for voice commands');
        }
      }
    }
    
    // ãƒ—ãƒ­ã‚­ã‚·ãƒ¢ãƒ¼ãƒ‰ã§ã¯APIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
    if (process.env.OPENAI_API_KEY) {
      console.log('âœ… OpenAI API key found (local mode)');
    } else {
      console.log('ğŸŒ Using proxy mode for OpenAI API');
    }
    
    // VoiceServerServiceã‚’èµ·å‹•
    voiceServer = new VoiceServerService();
    await voiceServer.start(8085);
    console.log('âœ… Voice server started');
    
    // å°‘ã—å¾…ã£ã¦ã‹ã‚‰BrowserWindowã‚’ä½œæˆ
    setTimeout(() => {
      createHiddenWindow();
      console.log('âœ… Hidden browser window created');
    }, 3000);
    
    // ã‚·ã‚¹ãƒ†ãƒ ãƒˆãƒ¬ã‚¤ã®åˆæœŸåŒ–
    createSystemTray();
    console.log('âœ… System tray created');
    
    // é€šçŸ¥
    // showNotification('Anicca Started', 'Say "ã‚¢ãƒ‹ãƒƒãƒãƒ£" to begin!');
    
  } catch (error) {
    console.error('âŒ Initialization error:', error);
    
    if (app.isPackaged) {
      const { dialog } = require('electron');
      dialog.showErrorBox('Anicca Startup Error', 
        `Failed to start Anicca:\n\n${error}`);
    }
    
    app.quit();
  }
}


// éè¡¨ç¤ºã®BrowserWindowã‚’ä½œæˆ
function createHiddenWindow() {
  hiddenWindow = new BrowserWindow({
    show: false,  // éè¡¨ç¤º
    width: 800,
    height: 600,
    webPreferences: {
      nodeIntegration: false,
      contextIsolation: true,
    }
  });
  
  // voice-demoã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã‚’é–‹ãï¼ˆãƒãƒ¼ãƒˆ8085ï¼‰
  hiddenWindow.loadURL('http://localhost:8085');
  
  // ãƒ‡ãƒãƒƒã‚°ç”¨ - é–‹ç™ºç’°å¢ƒã§ã®ã¿é–‹ã
  if (!app.isPackaged) {
    hiddenWindow.webContents.openDevTools({ mode: 'detach' });
  }
  
  // ãƒšãƒ¼ã‚¸ãƒ­ãƒ¼ãƒ‰å®Œäº†å¾Œã€è‡ªå‹•çš„ã«éŸ³å£°èªè­˜ã‚’é–‹å§‹
  hiddenWindow.webContents.on('did-finish-load', () => {
    // ãƒšãƒ¼ã‚¸ãŒå®Œå…¨ã«èª­ã¿è¾¼ã¾ã‚Œã‚‹ã¾ã§å°‘ã—å¾…ã¤
    const isDev = process.env.NODE_ENV === 'development';
    setTimeout(() => {
      hiddenWindow?.webContents.executeJavaScript(`
        console.log('ğŸ¤ Starting voice assistant...');
        
        let pc = null;
        let dataChannel = null;
        let audioElement = null;
        
        // WebRTCã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’è‡ªå‹•çš„ã«é–‹å§‹ã™ã‚‹é–¢æ•°
        async function startVoiceSession() {
          try {
            console.log('ğŸš€ Starting voice session...');
            
            // Get session from server
            const sessionUrl = ${isDev} 
              ? '/session'
              : 'https://anicca-proxy-ten.vercel.app/api/openai-proxy/session';
            const sessionResponse = await fetch(sessionUrl);
            const session = await sessionResponse.json();
            console.log('ğŸ“¡ Session received:', session);
            
            // Set up WebRTC
            pc = new RTCPeerConnection();
            
            // Audio element for playback
            audioElement = document.createElement('audio');
            audioElement.autoplay = true;
            pc.ontrack = e => audioElement.srcObject = e.streams[0];
            
            // Data channel for communication
            dataChannel = pc.createDataChannel('oai-events');
            dataChannel.onopen = () => {
              console.log('âœ… Data channel opened!');
              
              // Send session config
              dataChannel.send(JSON.stringify({
                type: 'session.update',
                session: {
                  instructions: session.instructions,
                  voice: session.voice,
                  input_audio_format: session.input_audio_format,
                  output_audio_format: session.output_audio_format,
                  input_audio_transcription: { model: 'whisper-1' },
                  turn_detection: session.turn_detection,
                  tools: session.tools,
                  tool_choice: 'auto',
                  temperature: session.temperature,
                  max_response_output_tokens: session.max_response_output_tokens
                }
              }));
            };
            
            dataChannel.onmessage = (event) => {
              try {
                const data = JSON.parse(event.data);
                console.log('ğŸ“¨ Message:', data.type);
                
                if (data.type === 'response.function_call_arguments.done') {
                  handleFunctionCall(data);
                }
              } catch (error) {
                console.error('Message handling error:', error);
              }
            };
            
            // Get user media
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            pc.addTrack(stream.getTracks()[0]);
            
            // Create offer
            const offer = await pc.createOffer();
            await pc.setLocalDescription(offer);
            
            // Connect to OpenAI
            const response = await fetch('https://api.openai.com/v1/realtime?model=gpt-4o-realtime-preview-2024-12-17', {
              method: 'POST',
              body: offer.sdp,
              headers: {
                Authorization: \`Bearer \${session.client_secret.value}\`,
                'Content-Type': 'application/sdp'
              }
            });
            
            const answerSdp = await response.text();
            await pc.setRemoteDescription({ type: 'answer', sdp: answerSdp });
            
            console.log('âœ… Voice session started successfully!');
            return true;
            
          } catch (error) {
            console.error('âŒ Failed to start voice session:', error);
            return false;
          }
        }
        
        // Function to handle tool calls
        async function handleFunctionCall(data) {
          const { call_id, name, arguments: args } = data;
          
          try {
            console.log(\`ğŸ”§ Tool call: \${name}\`);
            
            // Call our server which proxies to appropriate API
            const toolsUrl = ${isDev}
              ? \`/tools/\${name}\`
              : \`https://anicca-proxy-ten.vercel.app/api/tools/\${name}\`;
            const response = await fetch(toolsUrl, {
              method: 'POST',
              headers: { 'Content-Type': 'application/json' },
              body: JSON.stringify({
                arguments: JSON.parse(args)
              })
            });
            
            const result = await response.json();
            
            // Send result back to OpenAI
            dataChannel.send(JSON.stringify({
              type: 'conversation.item.create',
              item: {
                type: 'function_call_output',
                call_id: call_id,
                output: JSON.stringify(result.result || result.stories || result.results || result.response || result)
              }
            }));
            
            // Trigger response
            setTimeout(() => {
              dataChannel.send(JSON.stringify({
                type: 'response.create',
                response: { modalities: ['text', 'audio'] }
              }));
            }, 100);
            
          } catch (error) {
            console.error('Function call error:', error);
          }
        }
        
        // è‡ªå‹•çš„ã«WebRTCæ¥ç¶šã‚’é–‹å§‹
        setTimeout(() => {
          console.log('ğŸš€ Auto-starting voice session...');
          startVoiceSession();
        }, 2000);
      `);
    }, 2000);
  });
}

// ã‚·ã‚¹ãƒ†ãƒ ãƒˆãƒ¬ã‚¤ã®ä½œæˆ
function createSystemTray() {
  const iconPath = app.isPackaged 
    ? path.join(process.resourcesPath, 'assets', 'tray-icon-gpt.png')
    : path.join(__dirname, '../assets/tray-icon-gpt.png');
  
  let trayIcon;
  try {
    trayIcon = nativeImage.createFromPath(iconPath);
    if (trayIcon.isEmpty()) {
      trayIcon = nativeImage.createEmpty();
    }
  } catch (error) {
    console.warn('âš ï¸ Tray icon not found, using default');
    trayIcon = nativeImage.createEmpty();
  }
  
  tray = new Tray(trayIcon);
  updateTrayMenu();
  tray.setToolTip('Anicca - Say "ã‚¢ãƒ‹ãƒƒãƒãƒ£" to begin');
}

// ãƒˆãƒ¬ã‚¤ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’æ›´æ–°
function updateTrayMenu() {
  const contextMenu = Menu.buildFromTemplate([
    {
      label: isListening ? 'ğŸ™ï¸ Listening...' : 'ğŸ”‡ Ready',
      enabled: false
    },
    { type: 'separator' },
    {
      label: 'Connect Slack',
      click: async () => {
        const { shell } = require('electron');
        shell.openExternal('https://anicca-proxy-ten.vercel.app/api/slack-oauth');
      }
    },
    {
      label: 'Show Demo Page',
      click: () => {
        if (hiddenWindow) {
          hiddenWindow.show();
        }
      }
    },
    {
      label: 'Toggle Developer Tools',
      click: () => {
        if (hiddenWindow) {
          if (hiddenWindow.webContents.isDevToolsOpened()) {
            hiddenWindow.webContents.closeDevTools();
          } else {
            hiddenWindow.webContents.openDevTools({ mode: 'detach' });
          }
        }
      }
    },
    { type: 'separator' },
    {
      label: 'About Anicca',
      click: () => {
        showNotification('Anicca v0.6.0', 'Voice AI Assistant\nSay "ã‚¢ãƒ‹ãƒƒãƒãƒ£" to start!');
      }
    },
    { type: 'separator' },
    {
      label: 'Quit',
      click: () => {
        app.quit();
      }
    }
  ]);
  
  if (tray) {
    tray.setContextMenu(contextMenu);
  }
}

// é€šçŸ¥è¡¨ç¤º
function showNotification(title: string, body: string) {
  const { Notification } = require('electron');
  new Notification({ title, body }).show();
}

// ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆ
app.whenReady().then(initializeApp);

app.on('window-all-closed', () => {
  // ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒãªãã¦ã‚‚çµ‚äº†ã—ãªã„
});

app.on('before-quit', async () => {
  console.log('ğŸ‘‹ Anicca shutting down...');
  
  if (voiceServer) {
    voiceServer.stop();
  }
  
  if (hiddenWindow) {
    hiddenWindow.close();
  }
  
  if (tray) {
    tray.destroy();
  }
});

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
process.on('uncaughtException', (error) => {
  console.error('âŒ Uncaught exception:', error);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error('âŒ Unhandled rejection at:', promise, 'reason:', reason);
});